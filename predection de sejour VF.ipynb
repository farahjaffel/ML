{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b450bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b89bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>HeightInMeters</th>\n",
       "      <th>WeightInKilograms</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SmokerStatus</th>\n",
       "      <th>ECigaretteUsage</th>\n",
       "      <th>AlcoholDrinkers</th>\n",
       "      <th>...</th>\n",
       "      <th>AdmissionDayOfWeek</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>facility_cost</th>\n",
       "      <th>procedure_cost</th>\n",
       "      <th>medication_cost</th>\n",
       "      <th>lab_test_cost</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>1,77999997138977</td>\n",
       "      <td>95,25</td>\n",
       "      <td>30,1299991607666</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>8</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>47700.0</td>\n",
       "      <td>100700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>1,77999997138977</td>\n",
       "      <td>71,2099990844727</td>\n",
       "      <td>22,5300006866455</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>21900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>1,60000002384186</td>\n",
       "      <td>71,6699981689453</td>\n",
       "      <td>27,9899997711182</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>13</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>86000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>1,62999999523163</td>\n",
       "      <td>84,8199996948242</td>\n",
       "      <td>32,0999984741211</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>8</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>196300.0</td>\n",
       "      <td>236400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>1,67999994754791</td>\n",
       "      <td>78,0199966430664</td>\n",
       "      <td>27,7600002288818</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>34700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  HADM_ID gender                  dob    HeightInMeters  \\\n",
       "0       10017   199207      F  2075-09-21 00:00:00  1,77999997138977   \n",
       "1       10013   165520      F  2038-09-03 00:00:00  1,77999997138977   \n",
       "2       10011   105331      F  2090-06-05 00:00:00  1,60000002384186   \n",
       "3       10006   142345      F  2094-03-05 00:00:00  1,62999999523163   \n",
       "4       10019   177759      M  2114-06-20 00:00:00  1,67999994754791   \n",
       "\n",
       "  WeightInKilograms               BMI   SmokerStatus  \\\n",
       "0             95,25  30,1299991607666  Former smoker   \n",
       "1  71,2099990844727  22,5300006866455   Never smoked   \n",
       "2  71,6699981689453  27,9899997711182  Former smoker   \n",
       "3  84,8199996948242  32,0999984741211  Former smoker   \n",
       "4  78,0199966430664  27,7600002288818   Never smoked   \n",
       "\n",
       "                             ECigaretteUsage  AlcoholDrinkers  ...  \\\n",
       "0  Never used e-cigarettes in my entire life                0  ...   \n",
       "1  Never used e-cigarettes in my entire life                1  ...   \n",
       "2  Never used e-cigarettes in my entire life                0  ...   \n",
       "3  Never used e-cigarettes in my entire life                0  ...   \n",
       "4  Never used e-cigarettes in my entire life                0  ...   \n",
       "\n",
       "   AdmissionDayOfWeek            DIAGNOSIS         ADMISSION_LOCATION  \\\n",
       "0                   2     HUMERAL FRACTURE       EMERGENCY ROOM ADMIT   \n",
       "1                   5               SEPSIS  TRANSFER FROM HOSP/EXTRAM   \n",
       "2                   4          HEPATITIS B  TRANSFER FROM HOSP/EXTRAM   \n",
       "3                   3               SEPSIS       EMERGENCY ROOM ADMIT   \n",
       "4                   7  ALCOHOLIC HEPATITIS  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "  ADMISSION_TYPE  length_of_stay  facility_cost  procedure_cost  \\\n",
       "0      EMERGENCY               8         8000.0          3000.0   \n",
       "1      EMERGENCY               2         2000.0          1500.0   \n",
       "2      EMERGENCY              13        13000.0          3000.0   \n",
       "3      EMERGENCY               8         8000.0         10500.0   \n",
       "4      EMERGENCY               0            0.0          6000.0   \n",
       "\n",
       "   medication_cost  lab_test_cost  total_cost  \n",
       "0          42000.0        47700.0    100700.0  \n",
       "1           3600.0        14800.0     21900.0  \n",
       "2              0.0        70000.0     86000.0  \n",
       "3          21600.0       196300.0    236400.0  \n",
       "4              0.0        28700.0     34700.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des données depuis un fichier CSV\n",
    "data = pd.read_csv(\"readmission_des_patients.csv\")\n",
    "\n",
    "# Affichage des premières lignes pour vérification\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a348b888",
   "metadata": {},
   "source": [
    "b. Traitement des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc84bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'HADM_ID', 'gender', 'dob', 'HeightInMeters',\n",
      "       'WeightInKilograms', 'BMI', 'SmokerStatus', 'ECigaretteUsage',\n",
      "       'AlcoholDrinkers', 'CovidPos', 'LANGUAGE', 'ETHNICITY',\n",
      "       'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke',\n",
      "       'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder',\n",
      "       'HadKidneyDisease', 'HadArthritis', 'HadDiabetes',\n",
      "       'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
      "       'DifficultyConcentrating', 'DifficultyWalking',\n",
      "       'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan',\n",
      "       'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap',\n",
      "       'AdmissionDate', 'AdmissionYear', 'AdmissionDayOfWeek', 'DIAGNOSIS',\n",
      "       'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'length_of_stay',\n",
      "       'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost',\n",
      "       'total_cost'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Afficher les noms des colonnes du DataFrame\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70ef122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 501.85889903115464\n",
      "R-squared: 0.07116092149700881\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Sélection des colonnes pour l'encodage\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "\n",
    "# Encoder les variables catégorielles (True -> 1, False -> 0)\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# Sélectionner les variables d'entrée (X) et la variable cible (y)\n",
    "X = data[['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']]  # Exemple d'entrée\n",
    "y = data['length_of_stay']  # Durée du séjour\n",
    "\n",
    "# Séparation des données en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Entraîner un modèle de régression linéaire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions sur les données de test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Évaluer le modèle\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4552648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 484.07\n",
      "R-squared Score: 0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encodage des colonnes catégorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# Sélection des features (vous pouvez en ajouter selon votre dataset)\n",
    "features = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "            'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "X = data[features]\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# Séparation des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Modèle : Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Prédictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Évaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des résultats\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe98e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Mean Squared Error: 454.20\n",
      "R-squared Score: 0.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Encodage des colonnes catégorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# Définir les features\n",
    "features = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "            'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "X = data[features]\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# GridSearchCV pour le fine-tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid,\n",
    "                           cv=5, scoring='r2', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# Prédiction\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Évaluation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Résultats\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb123b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "✅ Best parameters found: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "📉 Mean Squared Error: 281.53845518822624\n",
      "📈 R-squared Score: 0.4789293967188296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# 2. Encoder les colonnes booléennes (True/False)\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# 3. Encoder automatiquement les colonnes catégorielles (type object)\n",
    "object_cols = data.select_dtypes(include='object').columns\n",
    "data = pd.get_dummies(data, columns=object_cols, drop_first=True)\n",
    "\n",
    "# 4. Définir les features et la target\n",
    "X = data.drop(columns=['length_of_stay'])  # Variable cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# 5. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 7. GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8. Évaluation\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"✅ Best parameters found:\", grid_search.best_params_)\n",
    "print(\"📉 Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R-squared Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a4ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Best params: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "📉 MSE: 85.98860516306071\n",
      "📈 R²: 0.8408525246127863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"✅ Best params:\", random_search.best_params_)\n",
    "print(\"📉 MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6b4e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "📉 Mean Squared Error : 85.98860516306071\n",
      "📈 R² Score: 0.8408525246127863\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# 🔄 Chargement des données (ajoute ton propre chemin si nécessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# ✅ 1. Encodage des booléens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# Encodage des colonnes catégorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# ✅ 3. Features et Target\n",
    "X = data.drop(columns=['length_of_stay'])\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# ✅ 4. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ 5. Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ✅ 6. Modèle de base\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# ✅ 8. RandomizedSearchCV (plus puissant)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ✅ 9. Évaluation finale\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"✅ Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"📉 Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dd4096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "📉 Mean Squared Error : 85.98860516306071\n",
      "📈 R² Score: 0.8408525246127863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# 🔄 Charger les données (ajoute ton propre chemin si nécessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# ✅ 1. Encodage des booléens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# ✅ 2. Encodage des colonnes booléennes (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# ✅ 3. Sélection des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])  # On exclut la colonne 'length_of_stay' qui est notre cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# ✅ 4. Split des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ 5. Normalisation uniquement sur les features (X)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Normalisation de l'ensemble d'entraînement\n",
    "X_test_scaled = scaler.transform(X_test)  # Utilisation du même scaler pour l'ensemble de test\n",
    "\n",
    "# ✅ 6. Modèle de base - RandomForest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# ✅ 7. Paramètres de recherche pour RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# ✅ 8. Recherche aléatoire des meilleurs paramètres\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ✅ 9. Évaluation du modèle\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# ✅ 10. Résultats de l'évaluation\n",
    "print(\"✅ Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"📉 Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ✅ 11. Sauvegarde du modèle et du scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00d69316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "📉 Mean Squared Error : 85.98860516306071\n",
      "📈 R² Score: 0.8408525246127863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# 🔄 Charger les données (ajoute ton propre chemin si nécessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# ✅ 1. Encodage des booléens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# ✅ 2. Encodage des colonnes catégorielles (avec LabelEncoder)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# ✅ 3. Sélection des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])  # On exclut la colonne 'length_of_stay' qui est notre cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# ✅ 4. Split des données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ 5. Normalisation uniquement sur les features (X)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Normalisation de l'ensemble d'entraînement\n",
    "X_test_scaled = scaler.transform(X_test)  # Utilisation du même scaler pour l'ensemble de test\n",
    "\n",
    "# ✅ 6. Modèle de base - RandomForest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# ✅ 7. Paramètres de recherche pour RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# ✅ 8. Recherche aléatoire des meilleurs paramètres\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# ✅ 9. Évaluation du modèle\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# ✅ 10. Résultats de l'évaluation\n",
    "print(\"✅ Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"📉 Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# ✅ 11. Sauvegarde du modèle et du scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c197943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "✅ Best params from RandomizedSearchCV: {'model__max_depth': 26, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 223}\n",
      "📉 Mean Squared Error: 84.86472527251551\n",
      "📈 R² Score: 0.8429325984420983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# 🔄 Charger les données\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# ✅ Liste des colonnes booléennes à encoder\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "\n",
    "# ✅ 1. Séparation des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# ✅ 2. Pipeline pour l'encodage booléen (True/False → int)\n",
    "bool_encoder = FunctionTransformer(lambda x: x.astype(int))\n",
    "\n",
    "# ✅ 3. Préprocesseur : encodage + standardisation\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('bool', bool_encoder, bool_cols),\n",
    "    ('num', StandardScaler(), [col for col in X.columns if col not in bool_cols])\n",
    "])\n",
    "\n",
    "# ✅ 4. Pipeline complet avec RandomForest\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# ✅ 5. Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# ✅ 6. Recherche aléatoire de paramètres\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 500),\n",
    "    'model__max_depth': randint(5, 30),\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 10),\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "\n",
    "# ✅ 7. Entraînement\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# ✅ 8. Évaluation\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"✅ Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"📉 Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"📈 R² Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f60647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "📋 Liste des attributs utilisés dans le modèle :\n",
      " - subject_id\n",
      " - HADM_ID\n",
      " - AlcoholDrinkers\n",
      " - CovidPos\n",
      " - HadHeartAttack\n",
      " - HadAngina\n",
      " - HadStroke\n",
      " - HadAsthma\n",
      " - HadSkinCancer\n",
      " - HadCOPD\n",
      " - HadDepressiveDisorder\n",
      " - HadKidneyDisease\n",
      " - HadArthritis\n",
      " - DeafOrHardOfHearing\n",
      " - BlindOrVisionDifficulty\n",
      " - DifficultyConcentrating\n",
      " - DifficultyWalking\n",
      " - DifficultyDressingBathing\n",
      " - DifficultyErrands\n",
      " - ChestScan\n",
      " - HIVTesting\n",
      " - FluVaxLast12\n",
      " - PneumoVaxEver\n",
      " - AdmissionYear\n",
      " - AdmissionDayOfWeek\n",
      " - facility_cost\n",
      " - procedure_cost\n",
      " - medication_cost\n",
      " - lab_test_cost\n",
      " - total_cost\n",
      " - gender_M\n",
      " - dob_1846-07-21 00:00:00\n",
      " - dob_1851-09-12 00:00:00\n",
      " - dob_1876-07-14 00:00:00\n",
      " - dob_1878-05-14 00:00:00\n",
      " - dob_1880-02-29 00:00:00\n",
      " - dob_1885-03-24 00:00:00\n",
      " - dob_1895-05-17 00:00:00\n",
      " - dob_2016-12-05 00:00:00\n",
      " - dob_2029-07-09 00:00:00\n",
      " - dob_2029-12-07 00:00:00\n",
      " - dob_2031-05-19 00:00:00\n",
      " - dob_2031-08-12 00:00:00\n",
      " - dob_2035-04-13 00:00:00\n",
      " - dob_2036-03-10 00:00:00\n",
      " - dob_2038-05-10 00:00:00\n",
      " - dob_2038-09-03 00:00:00\n",
      " - dob_2041-05-16 00:00:00\n",
      " - dob_2044-06-27 00:00:00\n",
      " - dob_2045-10-07 00:00:00\n",
      " - dob_2046-02-27 00:00:00\n",
      " - dob_2046-04-18 00:00:00\n",
      " - dob_2046-07-05 00:00:00\n",
      " - dob_2050-02-16 00:00:00\n",
      " - dob_2050-03-29 00:00:00\n",
      " - dob_2051-03-23 00:00:00\n",
      " - dob_2051-03-24 00:00:00\n",
      " - dob_2051-04-21 00:00:00\n",
      " - dob_2051-07-25 00:00:00\n",
      " - dob_2053-04-13 00:00:00\n",
      " - dob_2053-09-08 00:00:00\n",
      " - dob_2055-07-18 00:00:00\n",
      " - dob_2056-01-27 00:00:00\n",
      " - dob_2057-11-15 00:00:00\n",
      " - dob_2058-04-23 00:00:00\n",
      " - dob_2058-08-04 00:00:00\n",
      " - dob_2060-02-12 00:00:00\n",
      " - dob_2061-03-25 00:00:00\n",
      " - dob_2061-04-10 00:00:00\n",
      " - dob_2061-06-13 00:00:00\n",
      " - dob_2061-10-23 00:00:00\n",
      " - dob_2061-12-10 00:00:00\n",
      " - dob_2063-07-05 00:00:00\n",
      " - dob_2068-03-04 00:00:00\n",
      " - dob_2069-05-05 00:00:00\n",
      " - dob_2070-10-11 00:00:00\n",
      " - dob_2071-02-11 00:00:00\n",
      " - dob_2072-05-05 00:00:00\n",
      " - dob_2072-12-03 00:00:00\n",
      " - dob_2073-06-05 00:00:00\n",
      " - dob_2073-08-13 00:00:00\n",
      " - dob_2073-11-22 00:00:00\n",
      " - dob_2074-09-29 00:00:00\n",
      " - dob_2075-09-21 00:00:00\n",
      " - dob_2076-05-06 00:00:00\n",
      " - dob_2078-06-16 00:00:00\n",
      " - dob_2079-01-29 00:00:00\n",
      " - dob_2079-08-17 00:00:00\n",
      " - dob_2081-01-03 00:00:00\n",
      " - dob_2081-12-26 00:00:00\n",
      " - dob_2082-06-27 00:00:00\n",
      " - dob_2083-09-20 00:00:00\n",
      " - dob_2086-02-04 00:00:00\n",
      " - dob_2086-12-16 00:00:00\n",
      " - dob_2088-05-05 00:00:00\n",
      " - dob_2090-06-05 00:00:00\n",
      " - dob_2090-11-16 00:00:00\n",
      " - dob_2094-03-05 00:00:00\n",
      " - dob_2096-02-27 00:00:00\n",
      " - dob_2096-07-25 00:00:00\n",
      " - dob_2097-01-07 00:00:00\n",
      " - dob_2097-01-16 00:00:00\n",
      " - dob_2097-05-16 00:00:00\n",
      " - dob_2097-11-14 00:00:00\n",
      " - dob_2097-12-16 00:00:00\n",
      " - dob_2098-04-29 00:00:00\n",
      " - dob_2099-03-17 00:00:00\n",
      " - dob_2099-09-02 00:00:00\n",
      " - dob_2101-06-10 00:00:00\n",
      " - dob_2103-12-05 00:00:00\n",
      " - dob_2104-02-12 00:00:00\n",
      " - dob_2107-06-27 00:00:00\n",
      " - dob_2108-01-15 00:00:00\n",
      " - dob_2108-12-20 00:00:00\n",
      " - dob_2109-04-07 00:00:00\n",
      " - dob_2109-07-08 00:00:00\n",
      " - dob_2110-03-25 00:00:00\n",
      " - dob_2110-04-02 00:00:00\n",
      " - dob_2111-07-18 00:00:00\n",
      " - dob_2112-01-20 00:00:00\n",
      " - dob_2112-10-22 00:00:00\n",
      " - dob_2114-06-20 00:00:00\n",
      " - dob_2127-06-04 00:00:00\n",
      " - dob_2136-07-28 00:00:00\n",
      " - dob_2136-07-29 00:00:00\n",
      " - dob_2141-03-15 00:00:00\n",
      " - dob_2146-10-23 00:00:00\n",
      " - dob_2150-12-07 00:00:00\n",
      " - dob_2181-04-19 00:00:00\n",
      " - HeightInMeters_1,5\n",
      " - HeightInMeters_1,51999998092651\n",
      " - HeightInMeters_1,54999995231628\n",
      " - HeightInMeters_1,57000005245209\n",
      " - HeightInMeters_1,60000002384186\n",
      " - HeightInMeters_1,62999999523163\n",
      " - HeightInMeters_1,64999997615814\n",
      " - HeightInMeters_1,67999994754791\n",
      " - HeightInMeters_1,70000004768372\n",
      " - HeightInMeters_1,73000001907349\n",
      " - HeightInMeters_1,75\n",
      " - HeightInMeters_1,77999997138977\n",
      " - HeightInMeters_1,79999995231628\n",
      " - HeightInMeters_1,83000004291534\n",
      " - HeightInMeters_1,85000002384186\n",
      " - HeightInMeters_1,87999999523163\n",
      " - HeightInMeters_1,9099999666214\n",
      " - HeightInMeters_1,92999994754791\n",
      " - HeightInMeters_1,98000001907349\n",
      " - WeightInKilograms_104,330001831055\n",
      " - WeightInKilograms_106,589996337891\n",
      " - WeightInKilograms_108,860000610352\n",
      " - WeightInKilograms_113,400001525879\n",
      " - WeightInKilograms_115,669998168945\n",
      " - WeightInKilograms_120,199996948242\n",
      " - WeightInKilograms_122,470001220703\n",
      " - WeightInKilograms_129,270004272461\n",
      " - WeightInKilograms_129,729995727539\n",
      " - WeightInKilograms_204,119995117188\n",
      " - WeightInKilograms_49,9000015258789\n",
      " - WeightInKilograms_52,1599998474121\n",
      " - WeightInKilograms_54,4300003051758\n",
      " - WeightInKilograms_54,8800010681152\n",
      " - WeightInKilograms_57,6100006103516\n",
      " - WeightInKilograms_58,060001373291\n",
      " - WeightInKilograms_58,9700012207031\n",
      " - WeightInKilograms_59,8699989318848\n",
      " - WeightInKilograms_61,2299995422363\n",
      " - WeightInKilograms_62,5999984741211\n",
      " - WeightInKilograms_63,5\n",
      " - WeightInKilograms_64,4100036621094\n",
      " - WeightInKilograms_65,7699966430664\n",
      " - WeightInKilograms_66,2200012207031\n",
      " - WeightInKilograms_67,129997253418\n",
      " - WeightInKilograms_68,0400009155273\n",
      " - WeightInKilograms_69,4000015258789\n",
      " - WeightInKilograms_69,8499984741211\n",
      " - WeightInKilograms_71,2099990844727\n",
      " - WeightInKilograms_71,6699981689453\n",
      " - WeightInKilograms_72,5699996948242\n",
      " - WeightInKilograms_73,4800033569336\n",
      " - WeightInKilograms_74,8399963378906\n",
      " - WeightInKilograms_76,1999969482422\n",
      " - WeightInKilograms_76,6600036621094\n",
      " - WeightInKilograms_78,0199966430664\n",
      " - WeightInKilograms_78,4700012207031\n",
      " - WeightInKilograms_79,379997253418\n",
      " - WeightInKilograms_79,8300018310547\n",
      " - WeightInKilograms_81,6500015258789\n",
      " - WeightInKilograms_83,4599990844727\n",
      " - WeightInKilograms_83,9100036621094\n",
      " - WeightInKilograms_84,8199996948242\n",
      " - WeightInKilograms_86,1800003051758\n",
      " - WeightInKilograms_87,5400009155273\n",
      " - WeightInKilograms_88\n",
      " - WeightInKilograms_88,4499969482422\n",
      " - WeightInKilograms_90,7200012207031\n",
      " - WeightInKilograms_91,1699981689453\n",
      " - WeightInKilograms_92,0800018310547\n",
      " - WeightInKilograms_94,8000030517578\n",
      " - WeightInKilograms_95,25\n",
      " - WeightInKilograms_97,0699996948242\n",
      " - WeightInKilograms_97,5199966430664\n",
      " - WeightInKilograms_99,7900009155273\n",
      " - BMI_19,7900009155273\n",
      " - BMI_19,9699993133545\n",
      " - BMI_20,1399993896484\n",
      " - BMI_20,8099994659424\n",
      " - BMI_20,9200000762939\n",
      " - BMI_20,9799995422363\n",
      " - BMI_21,0300006866455\n",
      " - BMI_21,0599994659424\n",
      " - BMI_21,1299991607666\n",
      " - BMI_21,7700004577637\n",
      " - BMI_22,5300006866455\n",
      " - BMI_22,6000003814697\n",
      " - BMI_22,6700000762939\n",
      " - BMI_23,0100002288818\n",
      " - BMI_23,4400005340576\n",
      " - BMI_23,6299991607666\n",
      " - BMI_23,6900005340576\n",
      " - BMI_24,3299999237061\n",
      " - BMI_24,3700008392334\n",
      " - BMI_24,4500007629395\n",
      " - BMI_24,5499992370605\n",
      " - BMI_24,6900005340576\n",
      " - BMI_24,9400005340576\n",
      " - BMI_25,0599994659424\n",
      " - BMI_25,0900001525879\n",
      " - BMI_25,1100006103516\n",
      " - BMI_25,1499996185303\n",
      " - BMI_25,3700008392334\n",
      " - BMI_25,5400009155273\n",
      " - BMI_25,8400001525879\n",
      " - BMI_26,4300003051758\n",
      " - BMI_26,7000007629395\n",
      " - BMI_26,9400005340576\n",
      " - BMI_27,0699996948242\n",
      " - BMI_27,1200008392334\n",
      " - BMI_27,2000007629395\n",
      " - BMI_27,2600002288818\n",
      " - BMI_27,3400001525879\n",
      " - BMI_27,3899993896484\n",
      " - BMI_27,7600002288818\n",
      " - BMI_27,8099994659424\n",
      " - BMI_27,8899993896484\n",
      " - BMI_27,9899997711182\n",
      " - BMI_28,2800006866455\n",
      " - BMI_28,8400001525879\n",
      " - BMI_28,8899993896484\n",
      " - BMI_29,0499992370605\n",
      " - BMI_29,1499996185303\n",
      " - BMI_29,8400001525879\n",
      " - BMI_29,8600006103516\n",
      " - BMI_29,8799991607666\n",
      " - BMI_30,1299991607666\n",
      " - BMI_30,1800003051758\n",
      " - BMI_30,2299995422363\n",
      " - BMI_30,3400001525879\n",
      " - BMI_30,4099998474121\n",
      " - BMI_30,5599994659424\n",
      " - BMI_30,6800003051758\n",
      " - BMI_31,0100002288818\n",
      " - BMI_31,3199996948242\n",
      " - BMI_31,3799991607666\n",
      " - BMI_31,6599998474121\n",
      " - BMI_31,75\n",
      " - BMI_31,8700008392334\n",
      " - BMI_31,8899993896484\n",
      " - BMI_31,9300003051758\n",
      " - BMI_32,0800018310547\n",
      " - BMI_32,0999984741211\n",
      " - BMI_32,4900016784668\n",
      " - BMI_32,7400016784668\n",
      " - BMI_32,9199981689453\n",
      " - BMI_32,9300003051758\n",
      " - BMI_33,0699996948242\n",
      " - BMI_33,2999992370605\n",
      " - BMI_33,439998626709\n",
      " - BMI_33,8899993896484\n",
      " - BMI_34,7700004577637\n",
      " - BMI_34,9599990844727\n",
      " - BMI_35,1500015258789\n",
      " - BMI_35,7799987792969\n",
      " - BMI_35,8699989318848\n",
      " - BMI_36,6199989318848\n",
      " - BMI_36,7299995422363\n",
      " - BMI_37,7299995422363\n",
      " - BMI_41,1599998474121\n",
      " - BMI_44,2900009155273\n",
      " - BMI_44,9199981689453\n",
      " - BMI_46,8699989318848\n",
      " - BMI_52,1300010681152\n",
      " - BMI_61,0299987792969\n",
      " - SmokerStatus_Current smoker - now smokes some days\n",
      " - SmokerStatus_Former smoker\n",
      " - SmokerStatus_Never smoked\n",
      " - ECigaretteUsage_Not at all (right now)\n",
      " - ECigaretteUsage_Use them every day\n",
      " - ECigaretteUsage_Use them some days\n",
      " - LANGUAGE_MAND\n",
      " - LANGUAGE_POLI\n",
      " - LANGUAGE_RUSS\n",
      " - LANGUAGE_SPAN\n",
      " - ETHNICITY_ASIAN\n",
      " - ETHNICITY_BLACK/AFRICAN AMERICAN\n",
      " - ETHNICITY_HISPANIC OR LATINO\n",
      " - ETHNICITY_HISPANIC/LATINO - PUERTO RICAN\n",
      " - ETHNICITY_OTHER\n",
      " - ETHNICITY_UNABLE TO OBTAIN\n",
      " - ETHNICITY_UNKNOWN/NOT SPECIFIED\n",
      " - ETHNICITY_WHITE\n",
      " - MARITAL_STATUS_MARRIED\n",
      " - MARITAL_STATUS_SEPARATED\n",
      " - MARITAL_STATUS_SINGLE\n",
      " - MARITAL_STATUS_UNKNOWN (DEFAULT)\n",
      " - MARITAL_STATUS_WIDOWED\n",
      " - HadDiabetes_No, pre-diabetes or borderline diabetes\n",
      " - HadDiabetes_Yes\n",
      " - HadDiabetes_Yes, but only during pregnancy (female)\n",
      " - TetanusLast10Tdap_Yes, received Tdap\n",
      " - TetanusLast10Tdap_Yes, received tetanus shot but not sure what type\n",
      " - TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap\n",
      " - AdmissionDate_2104-09-24\n",
      " - AdmissionDate_2104-10-24\n",
      " - AdmissionDate_2105-05-29\n",
      " - AdmissionDate_2106-08-30\n",
      " - AdmissionDate_2107-01-04\n",
      " - AdmissionDate_2107-01-16\n",
      " - AdmissionDate_2107-01-29\n",
      " - AdmissionDate_2107-03-21\n",
      " - AdmissionDate_2107-05-12\n",
      " - AdmissionDate_2110-12-29\n",
      " - AdmissionDate_2112-02-04\n",
      " - AdmissionDate_2112-05-04\n",
      " - AdmissionDate_2112-05-22\n",
      " - AdmissionDate_2112-05-28\n",
      " - AdmissionDate_2115-05-12\n",
      " - AdmissionDate_2117-03-21\n",
      " - AdmissionDate_2117-08-05\n",
      " - AdmissionDate_2117-08-21\n",
      " - AdmissionDate_2118-10-06\n",
      " - AdmissionDate_2119-10-17\n",
      " - AdmissionDate_2120-08-24\n",
      " - AdmissionDate_2121-12-07\n",
      " - AdmissionDate_2123-08-23\n",
      " - AdmissionDate_2123-11-24\n",
      " - AdmissionDate_2124-01-12\n",
      " - AdmissionDate_2125-10-04\n",
      " - AdmissionDate_2126-08-14\n",
      " - AdmissionDate_2127-03-19\n",
      " - AdmissionDate_2127-07-23\n",
      " - AdmissionDate_2127-10-06\n",
      " - AdmissionDate_2128-03-22\n",
      " - AdmissionDate_2128-11-04\n",
      " - AdmissionDate_2129-03-03\n",
      " - AdmissionDate_2129-05-01\n",
      " - AdmissionDate_2129-11-23\n",
      " - AdmissionDate_2130-02-04\n",
      " - AdmissionDate_2130-08-12\n",
      " - AdmissionDate_2130-10-06\n",
      " - AdmissionDate_2131-07-26\n",
      " - AdmissionDate_2132-08-05\n",
      " - AdmissionDate_2132-12-05\n",
      " - AdmissionDate_2135-10-24\n",
      " - AdmissionDate_2138-04-02\n",
      " - AdmissionDate_2138-06-05\n",
      " - AdmissionDate_2138-11-09\n",
      " - AdmissionDate_2139-09-22\n",
      " - AdmissionDate_2141-01-25\n",
      " - AdmissionDate_2142-11-26\n",
      " - AdmissionDate_2144-02-09\n",
      " - AdmissionDate_2144-07-11\n",
      " - AdmissionDate_2144-07-18\n",
      " - AdmissionDate_2144-10-15\n",
      " - AdmissionDate_2144-12-24\n",
      " - AdmissionDate_2145-07-07\n",
      " - AdmissionDate_2145-09-06\n",
      " - AdmissionDate_2145-12-01\n",
      " - AdmissionDate_2146-07-21\n",
      " - AdmissionDate_2147-02-06\n",
      " - AdmissionDate_2147-02-23\n",
      " - AdmissionDate_2147-10-03\n",
      " - AdmissionDate_2148-01-13\n",
      " - AdmissionDate_2149-05-26\n",
      " - AdmissionDate_2150-08-07\n",
      " - AdmissionDate_2150-08-22\n",
      " - AdmissionDate_2151-08-13\n",
      " - AdmissionDate_2151-09-12\n",
      " - AdmissionDate_2152-10-02\n",
      " - AdmissionDate_2152-10-09\n",
      " - AdmissionDate_2155-03-08\n",
      " - AdmissionDate_2155-12-16\n",
      " - AdmissionDate_2159-11-17\n",
      " - AdmissionDate_2160-05-04\n",
      " - AdmissionDate_2160-12-16\n",
      " - AdmissionDate_2160-12-26\n",
      " - AdmissionDate_2161-01-30\n",
      " - AdmissionDate_2161-09-14\n",
      " - AdmissionDate_2162-01-16\n",
      " - AdmissionDate_2163-05-14\n",
      " - AdmissionDate_2163-11-21\n",
      " - AdmissionDate_2164-10-23\n",
      " - AdmissionDate_2165-12-19\n",
      " - AdmissionDate_2166-02-12\n",
      " - AdmissionDate_2167-02-11\n",
      " - AdmissionDate_2169-05-06\n",
      " - AdmissionDate_2170-12-02\n",
      " - AdmissionDate_2170-12-15\n",
      " - AdmissionDate_2171-07-12\n",
      " - AdmissionDate_2171-10-30\n",
      " - AdmissionDate_2173-11-27\n",
      " - AdmissionDate_2175-10-02\n",
      " - AdmissionDate_2176-07-14\n",
      " - AdmissionDate_2178-05-14\n",
      " - AdmissionDate_2179-04-17\n",
      " - AdmissionDate_2180-01-14\n",
      " - AdmissionDate_2180-02-29\n",
      " - AdmissionDate_2180-03-15\n",
      " - AdmissionDate_2180-07-19\n",
      " - AdmissionDate_2184-08-04\n",
      " - AdmissionDate_2185-03-24\n",
      " - AdmissionDate_2185-04-13\n",
      " - AdmissionDate_2186-02-09\n",
      " - AdmissionDate_2186-07-06\n",
      " - AdmissionDate_2188-02-08\n",
      " - AdmissionDate_2189-09-08\n",
      " - AdmissionDate_2190-07-13\n",
      " - AdmissionDate_2192-03-26\n",
      " - AdmissionDate_2192-04-16\n",
      " - AdmissionDate_2192-11-20\n",
      " - AdmissionDate_2193-10-15\n",
      " - AdmissionDate_2194-07-26\n",
      " - AdmissionDate_2195-05-17\n",
      " - AdmissionDate_2198-06-28\n",
      " - AdmissionDate_2198-06-29\n",
      " - AdmissionDate_2198-10-29\n",
      " - AdmissionDate_2199-01-13\n",
      " - AdmissionDate_2199-01-31\n",
      " - AdmissionDate_2200-03-17\n",
      " - AdmissionDate_2200-06-09\n",
      " - AdmissionDate_2200-10-29\n",
      " - AdmissionDate_2201-05-12\n",
      " - AdmissionDate_2201-08-10\n",
      " - AdmissionDate_2201-09-28\n",
      " - AdmissionDate_2201-11-16\n",
      " - AdmissionDate_2201-12-31\n",
      " - AdmissionDate_2202-02-15\n",
      " - AdmissionDate_2202-05-01\n",
      " - AdmissionDate_2202-09-16\n",
      " - AdmissionDate_2202-10-03\n",
      " - DIAGNOSIS_ABDOMINAL PAIN\n",
      " - DIAGNOSIS_ABSCESS\n",
      " - DIAGNOSIS_ACUTE CHOLANGITIS\n",
      " - DIAGNOSIS_ACUTE CHOLECYSTITIS\n",
      " - DIAGNOSIS_ACUTE PULMONARY EMBOLISM\n",
      " - DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE\n",
      " - DIAGNOSIS_ACUTE SUBDURAL HEMATOMA\n",
      " - DIAGNOSIS_ALCOHOLIC HEPATITIS\n",
      " - DIAGNOSIS_ALTERED MENTAL STATUS\n",
      " - DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA\n",
      " - DIAGNOSIS_ASTHMA/COPD FLARE\n",
      " - DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE\n",
      " - DIAGNOSIS_BASAL GANGLIN BLEED\n",
      " - DIAGNOSIS_BRADYCARDIA\n",
      " - DIAGNOSIS_BRAIN METASTASES\n",
      " - DIAGNOSIS_CELLULITIS\n",
      " - DIAGNOSIS_CEREBROVASCULAR ACCIDENT\n",
      " - DIAGNOSIS_CHEST PAIN\n",
      " - DIAGNOSIS_CHEST PAIN/ CATH\n",
      " - DIAGNOSIS_CHOLANGITIS\n",
      " - DIAGNOSIS_CHOLECYSTITIS\n",
      " - DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION\n",
      " - DIAGNOSIS_CONGESTIVE HEART FAILURE\n",
      " - DIAGNOSIS_CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS GRAFT /SDA\n",
      " - DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION\n",
      " - DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT\n",
      " - DIAGNOSIS_ESOPHAGEAL CA/SDA\n",
      " - DIAGNOSIS_ESOPHAGEAL CANCER/SDA\n",
      " - DIAGNOSIS_FACIAL NUMBNESS\n",
      " - DIAGNOSIS_FAILURE TO THRIVE\n",
      " - DIAGNOSIS_FEVER\n",
      " - DIAGNOSIS_FEVER;URINARY TRACT INFECTION\n",
      " - DIAGNOSIS_GASTROINTESTINAL BLEED\n",
      " - DIAGNOSIS_HEADACHE\n",
      " - DIAGNOSIS_HEPATIC ENCEP\n",
      " - DIAGNOSIS_HEPATITIS B\n",
      " - DIAGNOSIS_HUMERAL FRACTURE\n",
      " - DIAGNOSIS_HYPOGLYCEMIA\n",
      " - DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION\n",
      " - DIAGNOSIS_HYPOTENSION\n",
      " - DIAGNOSIS_HYPOTENSION, RENAL FAILURE\n",
      " - DIAGNOSIS_HYPOTENSION;TELEMETRY\n",
      " - DIAGNOSIS_HYPOTENSION;UNRESPONSIVE\n",
      " - DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\CATH\n",
      " - DIAGNOSIS_LEFT HIP FRACTURE\n",
      " - DIAGNOSIS_LEFT HIP OA/SDA\n",
      " - DIAGNOSIS_LIVER FAILURE\n",
      " - DIAGNOSIS_LOWER GI BLEED\n",
      " - DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH\n",
      " - DIAGNOSIS_MEDIASTINAL ADENOPATHY\n",
      " - DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS\n",
      " - DIAGNOSIS_METASTIC MELANOMA;ANEMIA\n",
      " - DIAGNOSIS_MI CHF\n",
      " - DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA\n",
      " - DIAGNOSIS_OVERDOSE\n",
      " - DIAGNOSIS_PERICARDIAL EFFUSION\n",
      " - DIAGNOSIS_PLEURAL EFFUSION\n",
      " - DIAGNOSIS_PNEUMONIA\n",
      " - DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE\n",
      " - DIAGNOSIS_PNEUMONIA;TELEMETRY\n",
      " - DIAGNOSIS_PULMONARY EDEMA, MI\n",
      " - DIAGNOSIS_PULMONARY EDEMA\\CATH\n",
      " - DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION\n",
      " - DIAGNOSIS_RENAL CANCER/SDA\n",
      " - DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA\n",
      " - DIAGNOSIS_RESPIRATORY DISTRESS\n",
      " - DIAGNOSIS_RIGHT HUMEROUS FRACTURE\n",
      " - DIAGNOSIS_S/P FALL\n",
      " - DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT\n",
      " - DIAGNOSIS_S/P MOTORCYCLE ACCIDENT\n",
      " - DIAGNOSIS_SEIZURE\n",
      " - DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS\n",
      " - DIAGNOSIS_SEPSIS\n",
      " - DIAGNOSIS_SEPSIS; UTI\n",
      " - DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY\n",
      " - DIAGNOSIS_SEPSIS;TELEMETRY\n",
      " - DIAGNOSIS_SHORTNESS OF BREATH\n",
      " - DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES\n",
      " - DIAGNOSIS_STEMI;\n",
      " - DIAGNOSIS_STROKE/TIA\n",
      " - DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL\n",
      " - DIAGNOSIS_SYNCOPE;TELEMETRY\n",
      " - DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE\n",
      " - DIAGNOSIS_TACHYPNEA;TELEMETRY\n",
      " - DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA\n",
      " - DIAGNOSIS_TRACHEAL STENOSIS\n",
      " - DIAGNOSIS_UNSTABLE ANGINA\n",
      " - DIAGNOSIS_UPPER GI BLEED\n",
      " - DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS\n",
      " - DIAGNOSIS_UROSEPSIS\n",
      " - DIAGNOSIS_UTI/PYELONEPHRITIS\n",
      " - DIAGNOSIS_VARICEAL BLEED\n",
      " - DIAGNOSIS_VF ARREST \n",
      " - DIAGNOSIS_VOLVULUS\n",
      " - ADMISSION_LOCATION_EMERGENCY ROOM ADMIT\n",
      " - ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI\n",
      " - ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM\n",
      " - ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR\n",
      " - ADMISSION_TYPE_EMERGENCY\n",
      " - ADMISSION_TYPE_URGENT\n"
     ]
    }
   ],
   "source": [
    "# ✅ 9. Affichage des attributs utilisés\n",
    "print(\"\\n📋 Liste des attributs utilisés dans le modèle :\")\n",
    "for feature in X.columns:\n",
    "    print(f\" - {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ada14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ✅ 9. Sauvegarde du modèle\n",
    "joblib.dump(best_model, 'best_rf_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9f2814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ✅ 10. Exporter le modèle et le scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Sauvegarde du scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49a1f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de X_train: Index(['subject_id', 'HADM_ID', 'AlcoholDrinkers', 'CovidPos',\n",
      "       'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma',\n",
      "       'HadSkinCancer', 'HadCOPD',\n",
      "       ...\n",
      "       'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED',\n",
      "       'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS',\n",
      "       'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT',\n",
      "       'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR',\n",
      "       'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT'],\n",
      "      dtype='object', length=550)\n",
      "Colonnes de X_test: Index(['subject_id', 'HADM_ID', 'AlcoholDrinkers', 'CovidPos',\n",
      "       'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma',\n",
      "       'HadSkinCancer', 'HadCOPD',\n",
      "       ...\n",
      "       'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED',\n",
      "       'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS',\n",
      "       'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT',\n",
      "       'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR',\n",
      "       'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT'],\n",
      "      dtype='object', length=550)\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes de X_train:\", X_train.columns)\n",
    "print(\"Colonnes de X_test:\", X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1302a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "835e94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📌 Observation 1\n",
      "🔮 Prédiction : 6.01\n",
      "✅ Intervalle de confiance à 95% : [5.37, 6.65]\n",
      "🎯 Valeur réelle : 6\n",
      "\n",
      "📌 Observation 2\n",
      "🔮 Prédiction : 16.63\n",
      "✅ Intervalle de confiance à 95% : [9.90, 23.36]\n",
      "🎯 Valeur réelle : 17\n",
      "\n",
      "📌 Observation 3\n",
      "🔮 Prédiction : 9.73\n",
      "✅ Intervalle de confiance à 95% : [7.93, 11.53]\n",
      "🎯 Valeur réelle : 10\n",
      "\n",
      "📌 Observation 4\n",
      "🔮 Prédiction : 7.92\n",
      "✅ Intervalle de confiance à 95% : [6.93, 8.92]\n",
      "🎯 Valeur réelle : 8\n",
      "\n",
      "📌 Observation 5\n",
      "🔮 Prédiction : 0.27\n",
      "✅ Intervalle de confiance à 95% : [-0.89, 1.43]\n",
      "🎯 Valeur réelle : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ 12. Prédictions avec estimation de l'incertitude (intervalle de confiance)\n",
    "import numpy as np\n",
    "\n",
    "# Obtenir les prédictions de chaque arbre\n",
    "all_tree_predictions = np.stack([tree.predict(X_test_scaled) for tree in loaded_model.estimators_], axis=0)\n",
    "\n",
    "# Moyenne des prédictions (prédiction finale)\n",
    "mean_predictions = np.mean(all_tree_predictions, axis=0)\n",
    "\n",
    "# Écart-type (incertitude)\n",
    "std_predictions = np.std(all_tree_predictions, axis=0)\n",
    "\n",
    "# Calcul de l'intervalle de confiance à 95%\n",
    "lower_bound = mean_predictions - 1.96 * std_predictions\n",
    "upper_bound = mean_predictions + 1.96 * std_predictions\n",
    "\n",
    "# Affichage pour les 5 premières instances\n",
    "for i in range(5):\n",
    "    print(f\"📌 Observation {i+1}\")\n",
    "    print(f\"🔮 Prédiction : {mean_predictions[i]:.2f}\")\n",
    "    print(f\"✅ Intervalle de confiance à 95% : [{lower_bound[i]:.2f}, {upper_bound[i]:.2f}]\")\n",
    "    print(f\"🎯 Valeur réelle : {y_test.iloc[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35ed32ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation des données pré-chargées.\n",
      "Colonne 'AlcoholDrinkers' convertie en booléen.\n",
      "Colonne 'CovidPos' convertie en booléen.\n",
      "Colonne 'HadHeartAttack' convertie en booléen.\n",
      "Colonne 'HadAngina' convertie en booléen.\n",
      "Colonne 'HadStroke' convertie en booléen.\n",
      "Colonne 'HadAsthma' convertie en booléen.\n",
      "Colonne 'HadSkinCancer' convertie en booléen.\n",
      "Colonne 'HadCOPD' convertie en booléen.\n",
      "Colonnes booléennes utilisées : ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
      "Colonnes numériques utilisées : ['HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'AdmissionYear', 'AdmissionDayOfWeek', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost', 'gender_M', 'dob_1846-07-21 00:00:00', 'dob_1851-09-12 00:00:00', 'dob_1876-07-14 00:00:00', 'dob_1878-05-14 00:00:00', 'dob_1880-02-29 00:00:00', 'dob_1885-03-24 00:00:00', 'dob_1895-05-17 00:00:00', 'dob_2016-12-05 00:00:00', 'dob_2029-07-09 00:00:00', 'dob_2029-12-07 00:00:00', 'dob_2031-05-19 00:00:00', 'dob_2031-08-12 00:00:00', 'dob_2035-04-13 00:00:00', 'dob_2036-03-10 00:00:00', 'dob_2038-05-10 00:00:00', 'dob_2038-09-03 00:00:00', 'dob_2041-05-16 00:00:00', 'dob_2044-06-27 00:00:00', 'dob_2045-10-07 00:00:00', 'dob_2046-02-27 00:00:00', 'dob_2046-04-18 00:00:00', 'dob_2046-07-05 00:00:00', 'dob_2050-02-16 00:00:00', 'dob_2050-03-29 00:00:00', 'dob_2051-03-23 00:00:00', 'dob_2051-03-24 00:00:00', 'dob_2051-04-21 00:00:00', 'dob_2051-07-25 00:00:00', 'dob_2053-04-13 00:00:00', 'dob_2053-09-08 00:00:00', 'dob_2055-07-18 00:00:00', 'dob_2056-01-27 00:00:00', 'dob_2057-11-15 00:00:00', 'dob_2058-04-23 00:00:00', 'dob_2058-08-04 00:00:00', 'dob_2060-02-12 00:00:00', 'dob_2061-03-25 00:00:00', 'dob_2061-04-10 00:00:00', 'dob_2061-06-13 00:00:00', 'dob_2061-10-23 00:00:00', 'dob_2061-12-10 00:00:00', 'dob_2063-07-05 00:00:00', 'dob_2068-03-04 00:00:00', 'dob_2069-05-05 00:00:00', 'dob_2070-10-11 00:00:00', 'dob_2071-02-11 00:00:00', 'dob_2072-05-05 00:00:00', 'dob_2072-12-03 00:00:00', 'dob_2073-06-05 00:00:00', 'dob_2073-08-13 00:00:00', 'dob_2073-11-22 00:00:00', 'dob_2074-09-29 00:00:00', 'dob_2075-09-21 00:00:00', 'dob_2076-05-06 00:00:00', 'dob_2078-06-16 00:00:00', 'dob_2079-01-29 00:00:00', 'dob_2079-08-17 00:00:00', 'dob_2081-01-03 00:00:00', 'dob_2081-12-26 00:00:00', 'dob_2082-06-27 00:00:00', 'dob_2083-09-20 00:00:00', 'dob_2086-02-04 00:00:00', 'dob_2086-12-16 00:00:00', 'dob_2088-05-05 00:00:00', 'dob_2090-06-05 00:00:00', 'dob_2090-11-16 00:00:00', 'dob_2094-03-05 00:00:00', 'dob_2096-02-27 00:00:00', 'dob_2096-07-25 00:00:00', 'dob_2097-01-07 00:00:00', 'dob_2097-01-16 00:00:00', 'dob_2097-05-16 00:00:00', 'dob_2097-11-14 00:00:00', 'dob_2097-12-16 00:00:00', 'dob_2098-04-29 00:00:00', 'dob_2099-03-17 00:00:00', 'dob_2099-09-02 00:00:00', 'dob_2101-06-10 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2104-02-12 00:00:00', 'dob_2107-06-27 00:00:00', 'dob_2108-01-15 00:00:00', 'dob_2108-12-20 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_2109-07-08 00:00:00', 'dob_2110-03-25 00:00:00', 'dob_2110-04-02 00:00:00', 'dob_2111-07-18 00:00:00', 'dob_2112-01-20 00:00:00', 'dob_2112-10-22 00:00:00', 'dob_2114-06-20 00:00:00', 'dob_2127-06-04 00:00:00', 'dob_2136-07-28 00:00:00', 'dob_2136-07-29 00:00:00', 'dob_2141-03-15 00:00:00', 'dob_2146-10-23 00:00:00', 'dob_2150-12-07 00:00:00', 'dob_2181-04-19 00:00:00', 'HeightInMeters_1,5', 'HeightInMeters_1,51999998092651', 'HeightInMeters_1,54999995231628', 'HeightInMeters_1,57000005245209', 'HeightInMeters_1,60000002384186', 'HeightInMeters_1,62999999523163', 'HeightInMeters_1,64999997615814', 'HeightInMeters_1,67999994754791', 'HeightInMeters_1,70000004768372', 'HeightInMeters_1,73000001907349', 'HeightInMeters_1,75', 'HeightInMeters_1,77999997138977', 'HeightInMeters_1,79999995231628', 'HeightInMeters_1,83000004291534', 'HeightInMeters_1,85000002384186', 'HeightInMeters_1,87999999523163', 'HeightInMeters_1,9099999666214', 'HeightInMeters_1,92999994754791', 'HeightInMeters_1,98000001907349', 'WeightInKilograms_104,330001831055', 'WeightInKilograms_106,589996337891', 'WeightInKilograms_108,860000610352', 'WeightInKilograms_113,400001525879', 'WeightInKilograms_115,669998168945', 'WeightInKilograms_120,199996948242', 'WeightInKilograms_122,470001220703', 'WeightInKilograms_129,270004272461', 'WeightInKilograms_129,729995727539', 'WeightInKilograms_204,119995117188', 'WeightInKilograms_49,9000015258789', 'WeightInKilograms_52,1599998474121', 'WeightInKilograms_54,4300003051758', 'WeightInKilograms_54,8800010681152', 'WeightInKilograms_57,6100006103516', 'WeightInKilograms_58,060001373291', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_59,8699989318848', 'WeightInKilograms_61,2299995422363', 'WeightInKilograms_62,5999984741211', 'WeightInKilograms_63,5', 'WeightInKilograms_64,4100036621094', 'WeightInKilograms_65,7699966430664', 'WeightInKilograms_66,2200012207031', 'WeightInKilograms_67,129997253418', 'WeightInKilograms_68,0400009155273', 'WeightInKilograms_69,4000015258789', 'WeightInKilograms_69,8499984741211', 'WeightInKilograms_71,2099990844727', 'WeightInKilograms_71,6699981689453', 'WeightInKilograms_72,5699996948242', 'WeightInKilograms_73,4800033569336', 'WeightInKilograms_74,8399963378906', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_76,6600036621094', 'WeightInKilograms_78,0199966430664', 'WeightInKilograms_78,4700012207031', 'WeightInKilograms_79,379997253418', 'WeightInKilograms_79,8300018310547', 'WeightInKilograms_81,6500015258789', 'WeightInKilograms_83,4599990844727', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_84,8199996948242', 'WeightInKilograms_86,1800003051758', 'WeightInKilograms_87,5400009155273', 'WeightInKilograms_88', 'WeightInKilograms_88,4499969482422', 'WeightInKilograms_90,7200012207031', 'WeightInKilograms_91,1699981689453', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_94,8000030517578', 'WeightInKilograms_95,25', 'WeightInKilograms_97,0699996948242', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_99,7900009155273', 'BMI_19,7900009155273', 'BMI_19,9699993133545', 'BMI_20,1399993896484', 'BMI_20,8099994659424', 'BMI_20,9200000762939', 'BMI_20,9799995422363', 'BMI_21,0300006866455', 'BMI_21,0599994659424', 'BMI_21,1299991607666', 'BMI_21,7700004577637', 'BMI_22,5300006866455', 'BMI_22,6000003814697', 'BMI_22,6700000762939', 'BMI_23,0100002288818', 'BMI_23,4400005340576', 'BMI_23,6299991607666', 'BMI_23,6900005340576', 'BMI_24,3299999237061', 'BMI_24,3700008392334', 'BMI_24,4500007629395', 'BMI_24,5499992370605', 'BMI_24,6900005340576', 'BMI_24,9400005340576', 'BMI_25,0599994659424', 'BMI_25,0900001525879', 'BMI_25,1100006103516', 'BMI_25,1499996185303', 'BMI_25,3700008392334', 'BMI_25,5400009155273', 'BMI_25,8400001525879', 'BMI_26,4300003051758', 'BMI_26,7000007629395', 'BMI_26,9400005340576', 'BMI_27,0699996948242', 'BMI_27,1200008392334', 'BMI_27,2000007629395', 'BMI_27,2600002288818', 'BMI_27,3400001525879', 'BMI_27,3899993896484', 'BMI_27,7600002288818', 'BMI_27,8099994659424', 'BMI_27,8899993896484', 'BMI_27,9899997711182', 'BMI_28,2800006866455', 'BMI_28,8400001525879', 'BMI_28,8899993896484', 'BMI_29,0499992370605', 'BMI_29,1499996185303', 'BMI_29,8400001525879', 'BMI_29,8600006103516', 'BMI_29,8799991607666', 'BMI_30,1299991607666', 'BMI_30,1800003051758', 'BMI_30,2299995422363', 'BMI_30,3400001525879', 'BMI_30,4099998474121', 'BMI_30,5599994659424', 'BMI_30,6800003051758', 'BMI_31,0100002288818', 'BMI_31,3199996948242', 'BMI_31,3799991607666', 'BMI_31,6599998474121', 'BMI_31,75', 'BMI_31,8700008392334', 'BMI_31,8899993896484', 'BMI_31,9300003051758', 'BMI_32,0800018310547', 'BMI_32,0999984741211', 'BMI_32,4900016784668', 'BMI_32,7400016784668', 'BMI_32,9199981689453', 'BMI_32,9300003051758', 'BMI_33,0699996948242', 'BMI_33,2999992370605', 'BMI_33,439998626709', 'BMI_33,8899993896484', 'BMI_34,7700004577637', 'BMI_34,9599990844727', 'BMI_35,1500015258789', 'BMI_35,7799987792969', 'BMI_35,8699989318848', 'BMI_36,6199989318848', 'BMI_36,7299995422363', 'BMI_37,7299995422363', 'BMI_41,1599998474121', 'BMI_44,2900009155273', 'BMI_44,9199981689453', 'BMI_46,8699989318848', 'BMI_52,1300010681152', 'BMI_61,0299987792969', 'SmokerStatus_Current smoker - now smokes some days', 'SmokerStatus_Former smoker', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Not at all (right now)', 'ECigaretteUsage_Use them every day', 'ECigaretteUsage_Use them some days', 'LANGUAGE_MAND', 'LANGUAGE_POLI', 'LANGUAGE_RUSS', 'LANGUAGE_SPAN', 'ETHNICITY_ASIAN', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'ETHNICITY_HISPANIC OR LATINO', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'ETHNICITY_OTHER', 'ETHNICITY_UNABLE TO OBTAIN', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'ETHNICITY_WHITE', 'MARITAL_STATUS_MARRIED', 'MARITAL_STATUS_SEPARATED', 'MARITAL_STATUS_SINGLE', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'MARITAL_STATUS_WIDOWED', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'HadDiabetes_Yes', 'HadDiabetes_Yes, but only during pregnancy (female)', 'TetanusLast10Tdap_Yes, received Tdap', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'AdmissionDate_2104-09-24', 'AdmissionDate_2104-10-24', 'AdmissionDate_2105-05-29', 'AdmissionDate_2106-08-30', 'AdmissionDate_2107-01-04', 'AdmissionDate_2107-01-16', 'AdmissionDate_2107-01-29', 'AdmissionDate_2107-03-21', 'AdmissionDate_2107-05-12', 'AdmissionDate_2110-12-29', 'AdmissionDate_2112-02-04', 'AdmissionDate_2112-05-04', 'AdmissionDate_2112-05-22', 'AdmissionDate_2112-05-28', 'AdmissionDate_2115-05-12', 'AdmissionDate_2117-03-21', 'AdmissionDate_2117-08-05', 'AdmissionDate_2117-08-21', 'AdmissionDate_2118-10-06', 'AdmissionDate_2119-10-17', 'AdmissionDate_2120-08-24', 'AdmissionDate_2121-12-07', 'AdmissionDate_2123-08-23', 'AdmissionDate_2123-11-24', 'AdmissionDate_2124-01-12', 'AdmissionDate_2125-10-04', 'AdmissionDate_2126-08-14', 'AdmissionDate_2127-03-19', 'AdmissionDate_2127-07-23', 'AdmissionDate_2127-10-06', 'AdmissionDate_2128-03-22', 'AdmissionDate_2128-11-04', 'AdmissionDate_2129-03-03', 'AdmissionDate_2129-05-01', 'AdmissionDate_2129-11-23', 'AdmissionDate_2130-02-04', 'AdmissionDate_2130-08-12', 'AdmissionDate_2130-10-06', 'AdmissionDate_2131-07-26', 'AdmissionDate_2132-08-05', 'AdmissionDate_2132-12-05', 'AdmissionDate_2135-10-24', 'AdmissionDate_2138-04-02', 'AdmissionDate_2138-06-05', 'AdmissionDate_2138-11-09', 'AdmissionDate_2139-09-22', 'AdmissionDate_2141-01-25', 'AdmissionDate_2142-11-26', 'AdmissionDate_2144-02-09', 'AdmissionDate_2144-07-11', 'AdmissionDate_2144-07-18', 'AdmissionDate_2144-10-15', 'AdmissionDate_2144-12-24', 'AdmissionDate_2145-07-07', 'AdmissionDate_2145-09-06', 'AdmissionDate_2145-12-01', 'AdmissionDate_2146-07-21', 'AdmissionDate_2147-02-06', 'AdmissionDate_2147-02-23', 'AdmissionDate_2147-10-03', 'AdmissionDate_2148-01-13', 'AdmissionDate_2149-05-26', 'AdmissionDate_2150-08-07', 'AdmissionDate_2150-08-22', 'AdmissionDate_2151-08-13', 'AdmissionDate_2151-09-12', 'AdmissionDate_2152-10-02', 'AdmissionDate_2152-10-09', 'AdmissionDate_2155-03-08', 'AdmissionDate_2155-12-16', 'AdmissionDate_2159-11-17', 'AdmissionDate_2160-05-04', 'AdmissionDate_2160-12-16', 'AdmissionDate_2160-12-26', 'AdmissionDate_2161-01-30', 'AdmissionDate_2161-09-14', 'AdmissionDate_2162-01-16', 'AdmissionDate_2163-05-14', 'AdmissionDate_2163-11-21', 'AdmissionDate_2164-10-23', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'AdmissionDate_2167-02-11', 'AdmissionDate_2169-05-06', 'AdmissionDate_2170-12-02', 'AdmissionDate_2170-12-15', 'AdmissionDate_2171-07-12', 'AdmissionDate_2171-10-30', 'AdmissionDate_2173-11-27', 'AdmissionDate_2175-10-02', 'AdmissionDate_2176-07-14', 'AdmissionDate_2178-05-14', 'AdmissionDate_2179-04-17', 'AdmissionDate_2180-01-14', 'AdmissionDate_2180-02-29', 'AdmissionDate_2180-03-15', 'AdmissionDate_2180-07-19', 'AdmissionDate_2184-08-04', 'AdmissionDate_2185-03-24', 'AdmissionDate_2185-04-13', 'AdmissionDate_2186-02-09', 'AdmissionDate_2186-07-06', 'AdmissionDate_2188-02-08', 'AdmissionDate_2189-09-08', 'AdmissionDate_2190-07-13', 'AdmissionDate_2192-03-26', 'AdmissionDate_2192-04-16', 'AdmissionDate_2192-11-20', 'AdmissionDate_2193-10-15', 'AdmissionDate_2194-07-26', 'AdmissionDate_2195-05-17', 'AdmissionDate_2198-06-28', 'AdmissionDate_2198-06-29', 'AdmissionDate_2198-10-29', 'AdmissionDate_2199-01-13', 'AdmissionDate_2199-01-31', 'AdmissionDate_2200-03-17', 'AdmissionDate_2200-06-09', 'AdmissionDate_2200-10-29', 'AdmissionDate_2201-05-12', 'AdmissionDate_2201-08-10', 'AdmissionDate_2201-09-28', 'AdmissionDate_2201-11-16', 'AdmissionDate_2201-12-31', 'AdmissionDate_2202-02-15', 'AdmissionDate_2202-05-01', 'AdmissionDate_2202-09-16', 'AdmissionDate_2202-10-03', 'DIAGNOSIS_ABDOMINAL PAIN', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_BRAIN METASTASES', 'DIAGNOSIS_CELLULITIS', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'DIAGNOSIS_CHEST PAIN', 'DIAGNOSIS_CHEST PAIN/ CATH', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'DIAGNOSIS_FACIAL NUMBNESS', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'DIAGNOSIS_HEADACHE', 'DIAGNOSIS_HEPATIC ENCEP', 'DIAGNOSIS_HEPATITIS B', 'DIAGNOSIS_HUMERAL FRACTURE', 'DIAGNOSIS_HYPOGLYCEMIA', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_HYPOTENSION', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_LEFT HIP FRACTURE', 'DIAGNOSIS_LEFT HIP OA/SDA', 'DIAGNOSIS_LIVER FAILURE', 'DIAGNOSIS_LOWER GI BLEED', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'DIAGNOSIS_MI CHF', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'DIAGNOSIS_OVERDOSE', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'DIAGNOSIS_RENAL CANCER/SDA', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'DIAGNOSIS_S/P FALL', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_SEIZURE', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'DIAGNOSIS_SEPSIS', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'DIAGNOSIS_SHORTNESS OF BREATH', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'DIAGNOSIS_STEMI;', 'DIAGNOSIS_STROKE/TIA', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'DIAGNOSIS_TRACHEAL STENOSIS', 'DIAGNOSIS_UNSTABLE ANGINA', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT']\n",
      "\n",
      "Types de données dans X_train AVANT le pipeline :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 103 entries, 70 to 102\n",
      "Columns: 548 entries, AlcoholDrinkers to ADMISSION_TYPE_URGENT\n",
      "dtypes: bool(528), float64(5), int64(15)\n",
      "memory usage: 70.0 KB\n",
      "None\n",
      "\n",
      "🚀 Début de l'entraînement et de la recherche d'hyperparamètres...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "✅ Entraînement terminé.\n",
      "\n",
      "--- Évaluation du Meilleur Modèle ---\n",
      "Meilleurs paramètres trouvés : {'model__max_depth': 8, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 2, 'model__min_samples_split': 3, 'model__n_estimators': 364}\n",
      "📉 Erreur Quadratique Moyenne Racine (RMSE) : 16.2090\n",
      "📈 Score R² : 0.5137\n",
      "\n",
      "✅ Pipeline complet sauvegardé sous : random_forest_length_stay_pipeline.joblib\n",
      "\n",
      "--- Simulation de Déploiement ---\n",
      "Pipeline chargé.\n",
      "\n",
      "Nouvelles données brutes (format entrée attendu) :\n",
      "   AlcoholDrinkers  CovidPos  HadHeartAttack  HadAngina  HadStroke  HadAsthma  \\\n",
      "0             True      True            True       True       True       True   \n",
      "1            False     False           False      False      False      False   \n",
      "\n",
      "   HadSkinCancer  HadCOPD  HadDepressiveDisorder  HadKidneyDisease  ...  \\\n",
      "0           True     True               0.139535          0.162791  ...   \n",
      "1          False    False               0.000000          0.000000  ...   \n",
      "\n",
      "   HIVTesting  FluVaxLast12  PneumoVaxEver  AdmissionYear  AdmissionDayOfWeek  \\\n",
      "0    0.232558      0.612403       0.472868    2153.744186            3.968992   \n",
      "1    0.000000      1.000000       0.000000    2150.000000            4.000000   \n",
      "\n",
      "   facility_cost  procedure_cost  medication_cost  lab_test_cost  \\\n",
      "0    9837.209302     15232.55814    181448.062016  125726.356589   \n",
      "1    7000.000000      6000.00000     30400.000000   61600.000000   \n",
      "\n",
      "      total_cost  \n",
      "0  332244.186047  \n",
      "1  116050.000000  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'BMI_30,1800003051758', 'dob_2068-03-04 00:00:00', 'dob_2150-12-07 00:00:00', 'BMI_19,9699993133545', 'AdmissionDate_2185-04-13', 'AdmissionDate_2198-06-28', 'AdmissionDate_2127-07-23', 'AdmissionDate_2201-12-31', 'dob_2046-07-05 00:00:00', 'HeightInMeters_1,79999995231628', 'AdmissionDate_2115-05-12', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'WeightInKilograms_63,5', 'AdmissionDate_2170-12-02', 'AdmissionDate_2105-05-29', 'ETHNICITY_UNABLE TO OBTAIN', 'dob_2111-07-18 00:00:00', 'dob_2061-06-13 00:00:00', 'BMI_21,0599994659424', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'BMI_21,0300006866455', 'AdmissionDate_2194-07-26', 'BMI_25,0599994659424', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'BMI_25,1100006103516', 'dob_2114-06-20 00:00:00', 'dob_2098-04-29 00:00:00', 'BMI_23,6299991607666', 'BMI_32,7400016784668', 'WeightInKilograms_78,0199966430664', 'dob_2071-02-11 00:00:00', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'MARITAL_STATUS_SINGLE', 'DIAGNOSIS_SEIZURE', 'dob_2090-06-05 00:00:00', 'BMI_35,7799987792969', 'AdmissionDate_2152-10-02', 'WeightInKilograms_69,4000015258789', 'BMI_35,8699989318848', 'BMI_30,1299991607666', 'AdmissionDate_2198-06-29', 'ECigaretteUsage_Use them every day', 'WeightInKilograms_91,1699981689453', 'BMI_27,3400001525879', 'HeightInMeters_1,85000002384186', 'dob_2031-05-19 00:00:00', 'AdmissionDate_2127-10-06', 'WeightInKilograms_90,7200012207031', 'ETHNICITY_WHITE', 'dob_2094-03-05 00:00:00', 'AdmissionDate_2147-10-03', 'BMI_34,9599990844727', 'dob_2061-10-23 00:00:00', 'AdmissionDate_2200-06-09', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'HeightInMeters_1,64999997615814', 'AdmissionDate_2135-10-24', 'AdmissionDate_2201-11-16', 'WeightInKilograms_106,589996337891', 'dob_2053-09-08 00:00:00', 'AdmissionDate_2126-08-14', 'AdmissionDate_2144-07-18', 'dob_2016-12-05 00:00:00', 'AdmissionDate_2163-11-21', 'BMI_33,439998626709', 'AdmissionDate_2141-01-25', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'BMI_27,8099994659424', 'DIAGNOSIS_TRACHEAL STENOSIS', 'dob_2097-05-16 00:00:00', 'dob_2090-11-16 00:00:00', 'AdmissionDate_2129-11-23', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'AdmissionDate_2160-12-16', 'dob_2104-02-12 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_1878-05-14 00:00:00', 'AdmissionDate_2163-05-14', 'BMI_31,9300003051758', 'AdmissionDate_2144-10-15', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Use them some days', 'dob_2081-12-26 00:00:00', 'LANGUAGE_SPAN', 'dob_2073-08-13 00:00:00', 'BMI_24,6900005340576', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'AdmissionDate_2180-03-15', 'WeightInKilograms_62,5999984741211', 'AdmissionDate_2117-03-21', 'HeightInMeters_1,75', 'BMI_32,0800018310547', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CELLULITIS', 'WeightInKilograms_129,270004272461', 'BMI_24,5499992370605', 'BMI_26,9400005340576', 'AdmissionDate_2107-03-21', 'AdmissionDate_2119-10-17', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'dob_2029-12-07 00:00:00', 'DIAGNOSIS_STEMI;', 'dob_2107-06-27 00:00:00', 'BMI_24,9400005340576', 'DIAGNOSIS_STROKE/TIA', 'HeightInMeters_1,83000004291534', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'BMI_27,9899997711182', 'AdmissionDate_2112-05-22', 'dob_2069-05-05 00:00:00', 'MARITAL_STATUS_SEPARATED', 'dob_2075-09-21 00:00:00', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'AdmissionDate_2193-10-15', 'AdmissionDate_2129-03-03', 'DIAGNOSIS_LOWER GI BLEED', 'dob_2051-03-24 00:00:00', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_73,4800033569336', 'dob_1885-03-24 00:00:00', 'AdmissionDate_2201-09-28', 'BMI_29,8600006103516', 'AdmissionDate_2164-10-23', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'BMI_32,9300003051758', 'BMI_27,2600002288818', 'BMI_34,7700004577637', 'AdmissionDate_2123-11-24', 'AdmissionDate_2150-08-07', 'AdmissionDate_2132-12-05', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'BMI_27,7600002288818', 'DIAGNOSIS_SHORTNESS OF BREATH', 'AdmissionDate_2192-04-16', 'AdmissionDate_2161-01-30', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'BMI_30,5599994659424', 'AdmissionDate_2152-10-09', 'AdmissionDate_2138-11-09', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'WeightInKilograms_94,8000030517578', 'dob_2046-02-27 00:00:00', 'BMI_26,7000007629395', 'AdmissionDate_2176-07-14', 'dob_2097-01-16 00:00:00', 'AdmissionDate_2171-10-30', 'AdmissionDate_2171-07-12', 'DIAGNOSIS_HUMERAL FRACTURE', 'dob_2072-05-05 00:00:00', 'dob_2050-03-29 00:00:00', 'AdmissionDate_2161-09-14', 'AdmissionDate_2138-04-02', 'HeightInMeters_1,5', 'WeightInKilograms_97,0699996948242', 'BMI_33,8899993896484', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'WeightInKilograms_86,1800003051758', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_VOLVULUS', 'AdmissionDate_2195-05-17', 'BMI_23,6900005340576', 'ADMISSION_TYPE_URGENT', 'dob_2058-04-23 00:00:00', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'BMI_25,8400001525879', 'BMI_61,0299987792969', 'AdmissionDate_2192-03-26', 'dob_2112-01-20 00:00:00', 'dob_2181-04-19 00:00:00', 'AdmissionDate_2120-08-24', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'dob_2109-07-08 00:00:00', 'dob_2036-03-10 00:00:00', 'AdmissionDate_2199-01-13', 'BMI_29,8400001525879', 'AdmissionDate_2162-01-16', 'DIAGNOSIS_MI CHF', 'dob_2096-02-27 00:00:00', 'WeightInKilograms_87,5400009155273', 'AdmissionDate_2147-02-06', 'WeightInKilograms_74,8399963378906', 'AdmissionDate_2170-12-15', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'dob_2099-03-17 00:00:00', 'HeightInMeters_1,98000001907349', 'AdmissionDate_2150-08-22', 'dob_2060-02-12 00:00:00', 'BMI_25,5400009155273', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'dob_2141-03-15 00:00:00', 'AdmissionDate_2107-01-16', 'BMI_25,1499996185303', 'MARITAL_STATUS_MARRIED', 'WeightInKilograms_108,860000610352', 'HeightInMeters_1,57000005245209', 'dob_2038-05-10 00:00:00', 'WeightInKilograms_76,6600036621094', 'AdmissionDate_2117-08-05', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'AdmissionDate_2145-09-06', 'AdmissionDate_2151-08-13', 'WeightInKilograms_78,4700012207031', 'dob_2108-01-15 00:00:00', 'WeightInKilograms_66,2200012207031', 'DIAGNOSIS_FACIAL NUMBNESS', 'dob_2044-06-27 00:00:00', 'BMI_30,6800003051758', 'AdmissionDate_2144-07-11', 'AdmissionDate_2147-02-23', 'AdmissionDate_2107-01-29', 'AdmissionDate_2112-05-04', 'AdmissionDate_2179-04-17', 'BMI_29,8799991607666', 'BMI_20,9200000762939', 'AdmissionDate_2173-11-27', 'WeightInKilograms_67,129997253418', 'dob_1876-07-14 00:00:00', 'DIAGNOSIS_CHEST PAIN', 'dob_2136-07-29 00:00:00', 'WeightInKilograms_52,1599998474121', 'AdmissionDate_2129-05-01', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'AdmissionDate_2107-05-12', 'AdmissionDate_2180-01-14', 'HadDiabetes_Yes', 'dob_2050-02-16 00:00:00', 'BMI_32,9199981689453', 'HeightInMeters_1,54999995231628', 'WeightInKilograms_88,4499969482422', 'BMI_41,1599998474121', 'DIAGNOSIS_HEPATIC ENCEP', 'AdmissionDate_2148-01-13', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'AdmissionDate_2125-10-04', 'AdmissionDate_2202-09-16', 'AdmissionDate_2145-07-07', 'AdmissionDate_2186-02-09', 'AdmissionDate_2201-05-12', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_84,8199996948242', 'dob_2057-11-15 00:00:00', 'WeightInKilograms_71,6699981689453', 'HadDiabetes_Yes, but only during pregnancy (female)', 'AdmissionDate_2142-11-26', 'BMI_23,0100002288818', 'HeightInMeters_1,62999999523163', 'dob_2035-04-13 00:00:00', 'dob_1851-09-12 00:00:00', 'AdmissionDate_2104-09-24', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_BRAIN METASTASES', 'AdmissionDate_2184-08-04', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'WeightInKilograms_79,8300018310547', 'DIAGNOSIS_LEFT HIP FRACTURE', 'dob_2136-07-28 00:00:00', 'AdmissionDate_2107-01-04', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'HeightInMeters_1,73000001907349', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'BMI_36,6199989318848', 'WeightInKilograms_72,5699996948242', 'dob_1846-07-21 00:00:00', 'TetanusLast10Tdap_Yes, received Tdap', 'AdmissionDate_2198-10-29', 'DIAGNOSIS_OVERDOSE', 'dob_2051-04-21 00:00:00', 'AdmissionDate_2149-05-26', 'BMI_24,3299999237061', 'BMI_44,9199981689453', 'AdmissionDate_2180-07-19', 'DIAGNOSIS_LIVER FAILURE', 'WeightInKilograms_58,060001373291', 'AdmissionDate_2199-01-31', 'DIAGNOSIS_LEFT HIP OA/SDA', 'dob_2079-01-29 00:00:00', 'BMI_26,4300003051758', 'AdmissionDate_2106-08-30', 'AdmissionDate_2130-08-12', 'dob_2099-09-02 00:00:00', 'BMI_31,3799991607666', 'BMI_28,8400001525879', 'WeightInKilograms_129,729995727539', 'DIAGNOSIS_HEPATITIS B', 'dob_2086-12-16 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2074-09-29 00:00:00', 'BMI_22,5300006866455', 'dob_2051-07-25 00:00:00', 'LANGUAGE_POLI', 'AdmissionDate_2112-02-04', 'dob_2110-03-25 00:00:00', 'BMI_27,1200008392334', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'dob_2086-02-04 00:00:00', 'WeightInKilograms_68,0400009155273', 'BMI_31,8700008392334', 'SmokerStatus_Former smoker', 'LANGUAGE_RUSS', 'dob_2051-03-23 00:00:00', 'AdmissionDate_2121-12-07', 'AdmissionDate_2104-10-24', 'BMI_33,2999992370605', 'WeightInKilograms_65,7699966430664', 'AdmissionDate_2144-12-24', 'ADMISSION_TYPE_EMERGENCY', 'AdmissionDate_2190-07-13', 'AdmissionDate_2139-09-22', 'BMI_32,4900016784668', 'AdmissionDate_2202-10-03', 'dob_2046-04-18 00:00:00', 'dob_2061-12-10 00:00:00', 'WeightInKilograms_64,4100036621094', 'AdmissionDate_2160-12-26', 'DIAGNOSIS_ABDOMINAL PAIN', 'HeightInMeters_1,77999997138977', 'BMI_31,0100002288818', 'BMI_30,3400001525879', 'WeightInKilograms_113,400001525879', 'BMI_30,2299995422363', 'dob_2058-08-04 00:00:00', 'dob_2045-10-07 00:00:00', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'WeightInKilograms_59,8699989318848', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'BMI_30,4099998474121', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'AdmissionDate_2159-11-17', 'dob_2070-10-11 00:00:00', 'dob_2146-10-23 00:00:00', 'BMI_20,1399993896484', 'dob_2076-05-06 00:00:00', 'BMI_27,8899993896484', 'WeightInKilograms_88', 'WeightInKilograms_54,8800010681152', 'BMI_44,2900009155273', 'WeightInKilograms_122,470001220703', 'dob_2031-08-12 00:00:00', 'dob_2029-07-09 00:00:00', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'HeightInMeters_1,67999994754791', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_104,330001831055', 'dob_1895-05-17 00:00:00', 'AdmissionDate_2202-05-01', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'dob_2112-10-22 00:00:00', 'WeightInKilograms_69,8499984741211', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'AdmissionDate_2167-02-11', 'ETHNICITY_OTHER', 'AdmissionDate_2155-03-08', 'DIAGNOSIS_SEPSIS', 'dob_2061-03-25 00:00:00', 'BMI_28,8899993896484', 'BMI_20,9799995422363', 'BMI_27,2000007629395', 'dob_2101-06-10 00:00:00', 'dob_2078-06-16 00:00:00', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'BMI_52,1300010681152', 'BMI_19,7900009155273', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'BMI_33,0699996948242', 'AdmissionDate_2117-08-21', 'BMI_20,8099994659424', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'dob_2096-07-25 00:00:00', 'BMI_25,3700008392334', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'WeightInKilograms_79,379997253418', 'BMI_32,0999984741211', 'AdmissionDate_2138-06-05', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'AdmissionDate_2155-12-16', 'AdmissionDate_2192-11-20', 'BMI_21,7700004577637', 'BMI_31,8899993896484', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'AdmissionDate_2128-03-22', 'AdmissionDate_2127-03-19', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'AdmissionDate_2151-09-12', 'ECigaretteUsage_Not at all (right now)', 'BMI_37,7299995422363', 'dob_2072-12-03 00:00:00', 'AdmissionDate_2128-11-04', 'AdmissionDate_2146-07-21', 'WeightInKilograms_57,6100006103516', 'BMI_24,4500007629395', 'HeightInMeters_1,51999998092651', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_RENAL CANCER/SDA', 'AdmissionDate_2130-10-06', 'ETHNICITY_ASIAN', 'AdmissionDate_2169-05-06', 'dob_2088-05-05 00:00:00', 'dob_2056-01-27 00:00:00', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_61,2299995422363', 'BMI_21,1299991607666', 'dob_2053-04-13 00:00:00', 'dob_2041-05-16 00:00:00', 'HeightInMeters_1,92999994754791', 'AdmissionDate_2131-07-26', 'AdmissionDate_2200-03-17', 'dob_2061-04-10 00:00:00', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'BMI_46,8699989318848', 'dob_2082-06-27 00:00:00', 'HeightInMeters_1,60000002384186', 'dob_2097-01-07 00:00:00', 'AdmissionDate_2118-10-06', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'WeightInKilograms_71,2099990844727', 'DIAGNOSIS_UNSTABLE ANGINA', 'dob_2079-08-17 00:00:00', 'AdmissionDate_2188-02-08', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'WeightInKilograms_99,7900009155273', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'dob_2127-06-04 00:00:00', 'dob_2097-11-14 00:00:00', 'DIAGNOSIS_VARICEAL BLEED', 'dob_2081-01-03 00:00:00', 'WeightInKilograms_95,25', 'BMI_35,1500015258789', 'AdmissionDate_2185-03-24', 'DIAGNOSIS_S/P FALL', 'dob_2110-04-02 00:00:00', 'AdmissionDate_2201-08-10', 'AdmissionDate_2145-12-01', 'AdmissionDate_2130-02-04', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_HYPOTENSION', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'WeightInKilograms_204,119995117188', 'BMI_31,6599998474121', 'WeightInKilograms_49,9000015258789', 'BMI_25,0900001525879', 'SmokerStatus_Current smoker - now smokes some days', 'AdmissionDate_2132-08-05', 'AdmissionDate_2202-02-15', 'dob_2073-11-22 00:00:00', 'AdmissionDate_2189-09-08', 'BMI_28,2800006866455', 'AdmissionDate_2178-05-14', 'AdmissionDate_2186-07-06', 'dob_2055-07-18 00:00:00', 'BMI_29,1499996185303', 'dob_2073-06-05 00:00:00', 'BMI_36,7299995422363', 'WeightInKilograms_120,199996948242', 'BMI_31,3199996948242', 'BMI_27,3899993896484', 'dob_2097-12-16 00:00:00', 'dob_2108-12-20 00:00:00', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_HYPOGLYCEMIA', 'AdmissionDate_2180-02-29', 'BMI_29,0499992370605', 'AdmissionDate_2123-08-23', 'DIAGNOSIS_CHEST PAIN/ CATH', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ETHNICITY_HISPANIC OR LATINO', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'BMI_31,75', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'dob_2083-09-20 00:00:00', 'BMI_22,6000003814697', 'BMI_23,4400005340576', 'AdmissionDate_2144-02-09', 'BMI_22,6700000762939', 'WeightInKilograms_81,6500015258789', 'gender_M', 'AdmissionDate_2112-05-28', 'BMI_24,3700008392334', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'HeightInMeters_1,87999999523163', 'DIAGNOSIS_HEADACHE', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'AdmissionDate_2175-10-02', 'HeightInMeters_1,70000004768372', 'dob_1880-02-29 00:00:00', 'WeightInKilograms_54,4300003051758', 'MARITAL_STATUS_WIDOWED', 'AdmissionDate_2200-10-29', 'WeightInKilograms_115,669998168945', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'LANGUAGE_MAND', 'AdmissionDate_2110-12-29', 'dob_2063-07-05 00:00:00', 'HeightInMeters_1,9099999666214', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_83,4599990844727', 'BMI_27,0699996948242', 'AdmissionDate_2124-01-12', 'dob_2038-09-03 00:00:00', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'AdmissionDate_2160-05-04'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 235\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mprint\u001b[39m(new_data)\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#print(\"\\nTypes de données des nouvelles données:\")\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#print(new_data.info())\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# Faire des prédictions avec le pipeline chargé\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# Le pipeline gère l'encodage et la standardisation automatiquement !\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     new_predictions \u001b[38;5;241m=\u001b[39m loaded_pipeline\u001b[38;5;241m.\u001b[39mpredict(new_data)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrédictions pour les nouvelles données : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_predictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\pipeline.py:787\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 787\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:1090\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m-> 1090\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: columns are missing: {'BMI_30,1800003051758', 'dob_2068-03-04 00:00:00', 'dob_2150-12-07 00:00:00', 'BMI_19,9699993133545', 'AdmissionDate_2185-04-13', 'AdmissionDate_2198-06-28', 'AdmissionDate_2127-07-23', 'AdmissionDate_2201-12-31', 'dob_2046-07-05 00:00:00', 'HeightInMeters_1,79999995231628', 'AdmissionDate_2115-05-12', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'WeightInKilograms_63,5', 'AdmissionDate_2170-12-02', 'AdmissionDate_2105-05-29', 'ETHNICITY_UNABLE TO OBTAIN', 'dob_2111-07-18 00:00:00', 'dob_2061-06-13 00:00:00', 'BMI_21,0599994659424', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'BMI_21,0300006866455', 'AdmissionDate_2194-07-26', 'BMI_25,0599994659424', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'BMI_25,1100006103516', 'dob_2114-06-20 00:00:00', 'dob_2098-04-29 00:00:00', 'BMI_23,6299991607666', 'BMI_32,7400016784668', 'WeightInKilograms_78,0199966430664', 'dob_2071-02-11 00:00:00', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'MARITAL_STATUS_SINGLE', 'DIAGNOSIS_SEIZURE', 'dob_2090-06-05 00:00:00', 'BMI_35,7799987792969', 'AdmissionDate_2152-10-02', 'WeightInKilograms_69,4000015258789', 'BMI_35,8699989318848', 'BMI_30,1299991607666', 'AdmissionDate_2198-06-29', 'ECigaretteUsage_Use them every day', 'WeightInKilograms_91,1699981689453', 'BMI_27,3400001525879', 'HeightInMeters_1,85000002384186', 'dob_2031-05-19 00:00:00', 'AdmissionDate_2127-10-06', 'WeightInKilograms_90,7200012207031', 'ETHNICITY_WHITE', 'dob_2094-03-05 00:00:00', 'AdmissionDate_2147-10-03', 'BMI_34,9599990844727', 'dob_2061-10-23 00:00:00', 'AdmissionDate_2200-06-09', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'HeightInMeters_1,64999997615814', 'AdmissionDate_2135-10-24', 'AdmissionDate_2201-11-16', 'WeightInKilograms_106,589996337891', 'dob_2053-09-08 00:00:00', 'AdmissionDate_2126-08-14', 'AdmissionDate_2144-07-18', 'dob_2016-12-05 00:00:00', 'AdmissionDate_2163-11-21', 'BMI_33,439998626709', 'AdmissionDate_2141-01-25', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'BMI_27,8099994659424', 'DIAGNOSIS_TRACHEAL STENOSIS', 'dob_2097-05-16 00:00:00', 'dob_2090-11-16 00:00:00', 'AdmissionDate_2129-11-23', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'AdmissionDate_2160-12-16', 'dob_2104-02-12 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_1878-05-14 00:00:00', 'AdmissionDate_2163-05-14', 'BMI_31,9300003051758', 'AdmissionDate_2144-10-15', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Use them some days', 'dob_2081-12-26 00:00:00', 'LANGUAGE_SPAN', 'dob_2073-08-13 00:00:00', 'BMI_24,6900005340576', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'AdmissionDate_2180-03-15', 'WeightInKilograms_62,5999984741211', 'AdmissionDate_2117-03-21', 'HeightInMeters_1,75', 'BMI_32,0800018310547', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CELLULITIS', 'WeightInKilograms_129,270004272461', 'BMI_24,5499992370605', 'BMI_26,9400005340576', 'AdmissionDate_2107-03-21', 'AdmissionDate_2119-10-17', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'dob_2029-12-07 00:00:00', 'DIAGNOSIS_STEMI;', 'dob_2107-06-27 00:00:00', 'BMI_24,9400005340576', 'DIAGNOSIS_STROKE/TIA', 'HeightInMeters_1,83000004291534', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'BMI_27,9899997711182', 'AdmissionDate_2112-05-22', 'dob_2069-05-05 00:00:00', 'MARITAL_STATUS_SEPARATED', 'dob_2075-09-21 00:00:00', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'AdmissionDate_2193-10-15', 'AdmissionDate_2129-03-03', 'DIAGNOSIS_LOWER GI BLEED', 'dob_2051-03-24 00:00:00', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_73,4800033569336', 'dob_1885-03-24 00:00:00', 'AdmissionDate_2201-09-28', 'BMI_29,8600006103516', 'AdmissionDate_2164-10-23', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'BMI_32,9300003051758', 'BMI_27,2600002288818', 'BMI_34,7700004577637', 'AdmissionDate_2123-11-24', 'AdmissionDate_2150-08-07', 'AdmissionDate_2132-12-05', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'BMI_27,7600002288818', 'DIAGNOSIS_SHORTNESS OF BREATH', 'AdmissionDate_2192-04-16', 'AdmissionDate_2161-01-30', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'BMI_30,5599994659424', 'AdmissionDate_2152-10-09', 'AdmissionDate_2138-11-09', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'WeightInKilograms_94,8000030517578', 'dob_2046-02-27 00:00:00', 'BMI_26,7000007629395', 'AdmissionDate_2176-07-14', 'dob_2097-01-16 00:00:00', 'AdmissionDate_2171-10-30', 'AdmissionDate_2171-07-12', 'DIAGNOSIS_HUMERAL FRACTURE', 'dob_2072-05-05 00:00:00', 'dob_2050-03-29 00:00:00', 'AdmissionDate_2161-09-14', 'AdmissionDate_2138-04-02', 'HeightInMeters_1,5', 'WeightInKilograms_97,0699996948242', 'BMI_33,8899993896484', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'WeightInKilograms_86,1800003051758', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_VOLVULUS', 'AdmissionDate_2195-05-17', 'BMI_23,6900005340576', 'ADMISSION_TYPE_URGENT', 'dob_2058-04-23 00:00:00', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'BMI_25,8400001525879', 'BMI_61,0299987792969', 'AdmissionDate_2192-03-26', 'dob_2112-01-20 00:00:00', 'dob_2181-04-19 00:00:00', 'AdmissionDate_2120-08-24', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'dob_2109-07-08 00:00:00', 'dob_2036-03-10 00:00:00', 'AdmissionDate_2199-01-13', 'BMI_29,8400001525879', 'AdmissionDate_2162-01-16', 'DIAGNOSIS_MI CHF', 'dob_2096-02-27 00:00:00', 'WeightInKilograms_87,5400009155273', 'AdmissionDate_2147-02-06', 'WeightInKilograms_74,8399963378906', 'AdmissionDate_2170-12-15', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'dob_2099-03-17 00:00:00', 'HeightInMeters_1,98000001907349', 'AdmissionDate_2150-08-22', 'dob_2060-02-12 00:00:00', 'BMI_25,5400009155273', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'dob_2141-03-15 00:00:00', 'AdmissionDate_2107-01-16', 'BMI_25,1499996185303', 'MARITAL_STATUS_MARRIED', 'WeightInKilograms_108,860000610352', 'HeightInMeters_1,57000005245209', 'dob_2038-05-10 00:00:00', 'WeightInKilograms_76,6600036621094', 'AdmissionDate_2117-08-05', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'AdmissionDate_2145-09-06', 'AdmissionDate_2151-08-13', 'WeightInKilograms_78,4700012207031', 'dob_2108-01-15 00:00:00', 'WeightInKilograms_66,2200012207031', 'DIAGNOSIS_FACIAL NUMBNESS', 'dob_2044-06-27 00:00:00', 'BMI_30,6800003051758', 'AdmissionDate_2144-07-11', 'AdmissionDate_2147-02-23', 'AdmissionDate_2107-01-29', 'AdmissionDate_2112-05-04', 'AdmissionDate_2179-04-17', 'BMI_29,8799991607666', 'BMI_20,9200000762939', 'AdmissionDate_2173-11-27', 'WeightInKilograms_67,129997253418', 'dob_1876-07-14 00:00:00', 'DIAGNOSIS_CHEST PAIN', 'dob_2136-07-29 00:00:00', 'WeightInKilograms_52,1599998474121', 'AdmissionDate_2129-05-01', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'AdmissionDate_2107-05-12', 'AdmissionDate_2180-01-14', 'HadDiabetes_Yes', 'dob_2050-02-16 00:00:00', 'BMI_32,9199981689453', 'HeightInMeters_1,54999995231628', 'WeightInKilograms_88,4499969482422', 'BMI_41,1599998474121', 'DIAGNOSIS_HEPATIC ENCEP', 'AdmissionDate_2148-01-13', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'AdmissionDate_2125-10-04', 'AdmissionDate_2202-09-16', 'AdmissionDate_2145-07-07', 'AdmissionDate_2186-02-09', 'AdmissionDate_2201-05-12', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_84,8199996948242', 'dob_2057-11-15 00:00:00', 'WeightInKilograms_71,6699981689453', 'HadDiabetes_Yes, but only during pregnancy (female)', 'AdmissionDate_2142-11-26', 'BMI_23,0100002288818', 'HeightInMeters_1,62999999523163', 'dob_2035-04-13 00:00:00', 'dob_1851-09-12 00:00:00', 'AdmissionDate_2104-09-24', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_BRAIN METASTASES', 'AdmissionDate_2184-08-04', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'WeightInKilograms_79,8300018310547', 'DIAGNOSIS_LEFT HIP FRACTURE', 'dob_2136-07-28 00:00:00', 'AdmissionDate_2107-01-04', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'HeightInMeters_1,73000001907349', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'BMI_36,6199989318848', 'WeightInKilograms_72,5699996948242', 'dob_1846-07-21 00:00:00', 'TetanusLast10Tdap_Yes, received Tdap', 'AdmissionDate_2198-10-29', 'DIAGNOSIS_OVERDOSE', 'dob_2051-04-21 00:00:00', 'AdmissionDate_2149-05-26', 'BMI_24,3299999237061', 'BMI_44,9199981689453', 'AdmissionDate_2180-07-19', 'DIAGNOSIS_LIVER FAILURE', 'WeightInKilograms_58,060001373291', 'AdmissionDate_2199-01-31', 'DIAGNOSIS_LEFT HIP OA/SDA', 'dob_2079-01-29 00:00:00', 'BMI_26,4300003051758', 'AdmissionDate_2106-08-30', 'AdmissionDate_2130-08-12', 'dob_2099-09-02 00:00:00', 'BMI_31,3799991607666', 'BMI_28,8400001525879', 'WeightInKilograms_129,729995727539', 'DIAGNOSIS_HEPATITIS B', 'dob_2086-12-16 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2074-09-29 00:00:00', 'BMI_22,5300006866455', 'dob_2051-07-25 00:00:00', 'LANGUAGE_POLI', 'AdmissionDate_2112-02-04', 'dob_2110-03-25 00:00:00', 'BMI_27,1200008392334', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'dob_2086-02-04 00:00:00', 'WeightInKilograms_68,0400009155273', 'BMI_31,8700008392334', 'SmokerStatus_Former smoker', 'LANGUAGE_RUSS', 'dob_2051-03-23 00:00:00', 'AdmissionDate_2121-12-07', 'AdmissionDate_2104-10-24', 'BMI_33,2999992370605', 'WeightInKilograms_65,7699966430664', 'AdmissionDate_2144-12-24', 'ADMISSION_TYPE_EMERGENCY', 'AdmissionDate_2190-07-13', 'AdmissionDate_2139-09-22', 'BMI_32,4900016784668', 'AdmissionDate_2202-10-03', 'dob_2046-04-18 00:00:00', 'dob_2061-12-10 00:00:00', 'WeightInKilograms_64,4100036621094', 'AdmissionDate_2160-12-26', 'DIAGNOSIS_ABDOMINAL PAIN', 'HeightInMeters_1,77999997138977', 'BMI_31,0100002288818', 'BMI_30,3400001525879', 'WeightInKilograms_113,400001525879', 'BMI_30,2299995422363', 'dob_2058-08-04 00:00:00', 'dob_2045-10-07 00:00:00', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'WeightInKilograms_59,8699989318848', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'BMI_30,4099998474121', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'AdmissionDate_2159-11-17', 'dob_2070-10-11 00:00:00', 'dob_2146-10-23 00:00:00', 'BMI_20,1399993896484', 'dob_2076-05-06 00:00:00', 'BMI_27,8899993896484', 'WeightInKilograms_88', 'WeightInKilograms_54,8800010681152', 'BMI_44,2900009155273', 'WeightInKilograms_122,470001220703', 'dob_2031-08-12 00:00:00', 'dob_2029-07-09 00:00:00', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'HeightInMeters_1,67999994754791', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_104,330001831055', 'dob_1895-05-17 00:00:00', 'AdmissionDate_2202-05-01', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'dob_2112-10-22 00:00:00', 'WeightInKilograms_69,8499984741211', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'AdmissionDate_2167-02-11', 'ETHNICITY_OTHER', 'AdmissionDate_2155-03-08', 'DIAGNOSIS_SEPSIS', 'dob_2061-03-25 00:00:00', 'BMI_28,8899993896484', 'BMI_20,9799995422363', 'BMI_27,2000007629395', 'dob_2101-06-10 00:00:00', 'dob_2078-06-16 00:00:00', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'BMI_52,1300010681152', 'BMI_19,7900009155273', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'BMI_33,0699996948242', 'AdmissionDate_2117-08-21', 'BMI_20,8099994659424', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'dob_2096-07-25 00:00:00', 'BMI_25,3700008392334', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'WeightInKilograms_79,379997253418', 'BMI_32,0999984741211', 'AdmissionDate_2138-06-05', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'AdmissionDate_2155-12-16', 'AdmissionDate_2192-11-20', 'BMI_21,7700004577637', 'BMI_31,8899993896484', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'AdmissionDate_2128-03-22', 'AdmissionDate_2127-03-19', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'AdmissionDate_2151-09-12', 'ECigaretteUsage_Not at all (right now)', 'BMI_37,7299995422363', 'dob_2072-12-03 00:00:00', 'AdmissionDate_2128-11-04', 'AdmissionDate_2146-07-21', 'WeightInKilograms_57,6100006103516', 'BMI_24,4500007629395', 'HeightInMeters_1,51999998092651', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_RENAL CANCER/SDA', 'AdmissionDate_2130-10-06', 'ETHNICITY_ASIAN', 'AdmissionDate_2169-05-06', 'dob_2088-05-05 00:00:00', 'dob_2056-01-27 00:00:00', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_61,2299995422363', 'BMI_21,1299991607666', 'dob_2053-04-13 00:00:00', 'dob_2041-05-16 00:00:00', 'HeightInMeters_1,92999994754791', 'AdmissionDate_2131-07-26', 'AdmissionDate_2200-03-17', 'dob_2061-04-10 00:00:00', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'BMI_46,8699989318848', 'dob_2082-06-27 00:00:00', 'HeightInMeters_1,60000002384186', 'dob_2097-01-07 00:00:00', 'AdmissionDate_2118-10-06', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'WeightInKilograms_71,2099990844727', 'DIAGNOSIS_UNSTABLE ANGINA', 'dob_2079-08-17 00:00:00', 'AdmissionDate_2188-02-08', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'WeightInKilograms_99,7900009155273', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'dob_2127-06-04 00:00:00', 'dob_2097-11-14 00:00:00', 'DIAGNOSIS_VARICEAL BLEED', 'dob_2081-01-03 00:00:00', 'WeightInKilograms_95,25', 'BMI_35,1500015258789', 'AdmissionDate_2185-03-24', 'DIAGNOSIS_S/P FALL', 'dob_2110-04-02 00:00:00', 'AdmissionDate_2201-08-10', 'AdmissionDate_2145-12-01', 'AdmissionDate_2130-02-04', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_HYPOTENSION', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'WeightInKilograms_204,119995117188', 'BMI_31,6599998474121', 'WeightInKilograms_49,9000015258789', 'BMI_25,0900001525879', 'SmokerStatus_Current smoker - now smokes some days', 'AdmissionDate_2132-08-05', 'AdmissionDate_2202-02-15', 'dob_2073-11-22 00:00:00', 'AdmissionDate_2189-09-08', 'BMI_28,2800006866455', 'AdmissionDate_2178-05-14', 'AdmissionDate_2186-07-06', 'dob_2055-07-18 00:00:00', 'BMI_29,1499996185303', 'dob_2073-06-05 00:00:00', 'BMI_36,7299995422363', 'WeightInKilograms_120,199996948242', 'BMI_31,3199996948242', 'BMI_27,3899993896484', 'dob_2097-12-16 00:00:00', 'dob_2108-12-20 00:00:00', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_HYPOGLYCEMIA', 'AdmissionDate_2180-02-29', 'BMI_29,0499992370605', 'AdmissionDate_2123-08-23', 'DIAGNOSIS_CHEST PAIN/ CATH', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ETHNICITY_HISPANIC OR LATINO', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'BMI_31,75', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'dob_2083-09-20 00:00:00', 'BMI_22,6000003814697', 'BMI_23,4400005340576', 'AdmissionDate_2144-02-09', 'BMI_22,6700000762939', 'WeightInKilograms_81,6500015258789', 'gender_M', 'AdmissionDate_2112-05-28', 'BMI_24,3700008392334', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'HeightInMeters_1,87999999523163', 'DIAGNOSIS_HEADACHE', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'AdmissionDate_2175-10-02', 'HeightInMeters_1,70000004768372', 'dob_1880-02-29 00:00:00', 'WeightInKilograms_54,4300003051758', 'MARITAL_STATUS_WIDOWED', 'AdmissionDate_2200-10-29', 'WeightInKilograms_115,669998168945', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'LANGUAGE_MAND', 'AdmissionDate_2110-12-29', 'dob_2063-07-05 00:00:00', 'HeightInMeters_1,9099999666214', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_83,4599990844727', 'BMI_27,0699996948242', 'AdmissionDate_2124-01-12', 'dob_2038-09-03 00:00:00', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'AdmissionDate_2160-05-04'}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propreté de la sortie (optionnel)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Simulation de données si aucun fichier n'est chargé ---\n",
    "# REMPLACE CECI PAR TON CHARGEMENT DE DONNÉES RÉEL\n",
    "try:\n",
    "    # Essaie de charger les données si la variable 'data' existe déjà\n",
    "    # (Adapte cette logique si nécessaire pour recharger à chaque fois)\n",
    "    if 'data' in locals() or 'data' in globals():\n",
    "        print(\"Utilisation des données pré-chargées.\")\n",
    "        # Assure-toi que les booléens sont bien booléens après le chargement initial si besoin\n",
    "        bool_cols_check = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                           'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "        for col in bool_cols_check:\n",
    "             if col in data.columns and data[col].dtype != bool :\n",
    "                 try:\n",
    "                     # Tentative de conversion flexible (gère True/False, 1/0, 'Yes'/'No', etc.)\n",
    "                     map_dict = {True: True, 1: True, 'True': True, 'true': True, 'Yes': True, 'yes': True,\n",
    "                                 False: False, 0: False, 'False': False, 'false': False, 'No': False, 'no': False}\n",
    "                     data[col] = data[col].map(map_dict).fillna(False).astype(bool) # Remplace NaN par False par défaut\n",
    "                     print(f\"Colonne '{col}' convertie en booléen.\")\n",
    "                 except Exception as e:\n",
    "                     print(f\"Attention : impossible de convertir la colonne '{col}' en booléen de manière fiable. Erreur: {e}\")\n",
    "\n",
    "    else:\n",
    "        raise NameError # Force l'exécution du bloc except\n",
    "except NameError:\n",
    "    print(\"Création de données exemples car 'data' n'est pas défini.\")\n",
    "    # ... (garder la création de données exemples si nécessaire) ...\n",
    "    data = pd.DataFrame({ # Version simplifiée pour l'exemple\n",
    "        'Age': np.random.randint(20, 85, size=500),\n",
    "        'BMI': np.random.uniform(18, 40, size=500),\n",
    "        'SeverityScore': np.random.uniform(1, 10, size=500),\n",
    "        'AlcoholDrinkers': np.random.choice([True, False], size=500, p=[0.6, 0.4]),\n",
    "        'CovidPos': np.random.choice([True, False], size=500, p=[0.2, 0.8]),\n",
    "        'HadHeartAttack': np.random.choice([True, False], size=500, p=[0.1, 0.9]),\n",
    "        'HadAngina': np.random.choice([True, False], size=500, p=[0.08, 0.92]),\n",
    "        'HadStroke': np.random.choice([True, False], size=500, p=[0.05, 0.95]),\n",
    "        'HadAsthma': np.random.choice([True, False], size=500, p=[0.15, 0.85]),\n",
    "        'HadSkinCancer': np.random.choice([True, False], size=500, p=[0.07, 0.93]),\n",
    "        'HadCOPD': np.random.choice([True, False], size=500, p=[0.06, 0.94]),\n",
    "        'length_of_stay': np.random.poisson(lam=5, size=500) + 1 # Cible (ex: jours)\n",
    "    })\n",
    "    for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']:\n",
    "        data[col] = data[col].astype(bool)\n",
    "\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\") # Décommente pour charger ton fichier\n",
    "\n",
    "# ========= DÉFINITION DE LA FONCTION POUR L'ENCODAGE =========\n",
    "def bool_to_int(X_bool):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame ou une Série de booléens en entiers (0 ou 1).\n",
    "    Gère les éventuelles valeurs manquantes en les traitant comme False (0).\n",
    "    \"\"\"\n",
    "    # S'assurer que l'entrée est traitée correctement (pourrait être Series ou DataFrame)\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        return X_bool.fillna(False).astype(int)\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        return X_bool.fillna(False).astype(int)\n",
    "    else: # Si c'est déjà un array numpy par exemple\n",
    "        return X_bool.astype(int)\n",
    "# ==============================================================\n",
    "\n",
    "# ✅ Liste des colonnes booléennes à encoder (assure-toi qu'elles existent)\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "# Vérifie que toutes les colonnes booléennes sont présentes dans les données\n",
    "bool_cols = [col for col in bool_cols if col in data.columns]\n",
    "print(f\"Colonnes booléennes utilisées : {bool_cols}\")\n",
    "\n",
    "# == Identification des colonnes numériques et autres ==\n",
    "target_col = 'length_of_stay'\n",
    "if target_col not in data.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' n'est pas dans le DataFrame.\")\n",
    "\n",
    "# Exclure explicitement les identifiants s'ils ne sont pas des features utiles\n",
    "id_cols = ['subject_id', 'HADM_ID'] # Adapte si nécessaire\n",
    "cols_to_drop_from_features = [target_col] + [id for id in id_cols if id in data.columns]\n",
    "\n",
    "X = data.drop(columns=cols_to_drop_from_features)\n",
    "y = data[target_col]\n",
    "\n",
    "# Recalculer les colonnes numériques après avoir potentiellement retiré les IDs\n",
    "numerical_cols = [col for col in X.columns if col not in bool_cols and pd.api.types.is_numeric_dtype(X[col])]\n",
    "print(f\"Colonnes numériques utilisées : {numerical_cols}\")\n",
    "\n",
    "# Vérifier s'il reste des colonnes non traitées\n",
    "processed_cols = set(bool_cols + numerical_cols)\n",
    "other_cols = [col for col in X.columns if col not in processed_cols]\n",
    "if other_cols:\n",
    "    print(f\"⚠️ Attention : Colonnes potentiellement non traitées par le préprocesseur : {other_cols}\")\n",
    "    # Décide quoi faire : les ignorer ('remainder='drop'') ou les passer ('passthrough')\n",
    "    # Si elles sont catégorielles et non booléennes, il faudrait ajouter un OneHotEncoder etc.\n",
    "\n",
    "# ✅ 2. Pipeline pour l'encodage booléen (utilisant la fonction définie)\n",
    "# Utiliser la fonction nommée ici ! validate=False est souvent utile avec pandas\n",
    "bool_encoder = FunctionTransformer(bool_to_int, validate=False)\n",
    "\n",
    "# ✅ 3. Préprocesseur : encodage booléen + standardisation numérique\n",
    "transformers = []\n",
    "if bool_cols:\n",
    "    transformers.append(('bool', bool_encoder, bool_cols))\n",
    "if numerical_cols:\n",
    "    # S'assurer qu'il n'y a pas de booléens par erreur dans les numériques\n",
    "    numerical_cols_strict = [c for c in numerical_cols if X[c].dtype != bool]\n",
    "    if numerical_cols_strict:\n",
    "         transformers.append(('num', StandardScaler(), numerical_cols_strict))\n",
    "    else:\n",
    "        print(\"Aucune colonne numérique stricte trouvée pour StandardScaler.\")\n",
    "else:\n",
    "    print(\"Aucune colonne numérique trouvée pour StandardScaler.\")\n",
    "\n",
    "\n",
    "if not transformers:\n",
    "     raise ValueError(\"Aucune transformation définie (ni booléenne, ni numérique). Vérifiez vos types de colonnes.\")\n",
    "\n",
    "# Choisir comment gérer les colonnes restantes ('other_cols')\n",
    "# 'drop' : les ignorer\n",
    "# 'passthrough' : les garder telles quelles (peut causer des erreurs si le modèle ne les gère pas)\n",
    "remainder_strategy = 'drop' if other_cols else 'passthrough'\n",
    "if other_cols:\n",
    "    print(f\"Les colonnes {other_cols} seront ignorées (remainder='drop').\")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder=remainder_strategy # Ignorer les colonnes non spécifiées\n",
    ")\n",
    "\n",
    "# ✅ 4. Pipeline complet avec RandomForest\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# ✅ 5. Split des données\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Afficher les types de données AVANT l'entraînement pour vérifier\n",
    "print(\"\\nTypes de données dans X_train AVANT le pipeline :\")\n",
    "print(X_train.info()) # Devrait montrer des booléens et des numériques/objets bruts\n",
    "\n",
    "# ✅ 6. Recherche aléatoire de paramètres\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 500),\n",
    "    'model__max_depth': randint(5, 30),\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 10),\n",
    "    # max_features='auto' est obsolète, utiliser 'sqrt' ou None (ou un float)\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
    "                                   n_iter=10, # Réduit pour l'exemple, augmente pour une vraie recherche\n",
    "                                   cv=5,\n",
    "                                   scoring='neg_mean_squared_error', # Métrique pour l'optimisation\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42,\n",
    "                                   verbose=1 # Réduit la verbosité pour l'exemple\n",
    "                                  )\n",
    "\n",
    "print(\"\\n🚀 Début de l'entraînement et de la recherche d'hyperparamètres...\")\n",
    "# ✅ 7. Entraînement\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"✅ Entraînement terminé.\")\n",
    "\n",
    "# ✅ 8. Évaluation\n",
    "best_model = random_search.best_estimator_ # C'est le *pipeline complet* entraîné\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Évaluation du Meilleur Modèle ---\")\n",
    "print(f\"Meilleurs paramètres trouvés : {random_search.best_params_}\")\n",
    "# Utiliser np.sqrt pour obtenir la RMSE (Root Mean Squared Error), souvent plus interprétable\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"📉 Erreur Quadratique Moyenne Racine (RMSE) : {rmse:.4f}\")\n",
    "print(f\"📈 Score R² : {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# ✅ 9. Sauvegarde du pipeline complet pour le déploiement\n",
    "model_filename = 'random_forest_length_stay_pipeline.joblib'\n",
    "try:\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"\\n✅ Pipeline complet sauvegardé sous : {model_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "    print(\"   Vérifiez les étapes du pipeline et les objets qu'il contient.\")\n",
    "\n",
    "\n",
    "# --- Exemple de chargement et prédiction (Simulation de déploiement) ---\n",
    "print(\"\\n--- Simulation de Déploiement ---\")\n",
    "# Charger le pipeline sauvegardé (seulement si la sauvegarde a réussi)\n",
    "if 'model_filename' in locals() and joblib.os.path.exists(model_filename):\n",
    "    loaded_pipeline = joblib.load(model_filename)\n",
    "    print(\"Pipeline chargé.\")\n",
    "\n",
    "    # Créer de nouvelles données brutes (format attendu par le pipeline)\n",
    "    # Doit avoir les MÊMES colonnes que X_train (sauf la cible et les IDs exclus)\n",
    "    # Utilise les colonnes de X pour créer l'exemple\n",
    "    example_data_dict = {}\n",
    "    for col in X.columns:\n",
    "        if col in bool_cols:\n",
    "            example_data_dict[col] = [True, False] # Exemple booléen\n",
    "        elif col in numerical_cols_strict: # Utilise la liste des numériques traités\n",
    "             # Prend des valeurs exemples (moyenne, médiane, ou juste des valeurs plausibles)\n",
    "             example_data_dict[col] = [X[col].mean(), X[col].median()]\n",
    "        # Les colonnes 'other_cols' sont ignorées si remainder='drop'\n",
    "\n",
    "    new_data = pd.DataFrame(example_data_dict)\n",
    "\n",
    "    # Assurer les bons types booléens pour les colonnes booléennes\n",
    "    for col in bool_cols:\n",
    "        if col in new_data.columns:\n",
    "             new_data[col] = new_data[col].astype(bool)\n",
    "\n",
    "    print(\"\\nNouvelles données brutes (format entrée attendu) :\")\n",
    "    print(new_data)\n",
    "    #print(\"\\nTypes de données des nouvelles données:\")\n",
    "    #print(new_data.info())\n",
    "\n",
    "\n",
    "    # Faire des prédictions avec le pipeline chargé\n",
    "    # Le pipeline gère l'encodage et la standardisation automatiquement !\n",
    "    new_predictions = loaded_pipeline.predict(new_data)\n",
    "    print(f\"\\nPrédictions pour les nouvelles données : {new_predictions}\")\n",
    "else:\n",
    "    print(\"Le fichier du pipeline n'a pas été trouvé ou n'a pas pu être sauvegardé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55a923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('best_rf_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a37f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Données chargées depuis 'datasejour.csv'. Shape: (129, 47)\n",
      "✅ Colonne 'Age' créée.\n",
      "✅ Features 'AdmissionYear', 'AdmissionMonth', 'AdmissionDayOfWeek' créées.\n",
      "\n",
      "--- Identification des Colonnes ---\n",
      "Cible: length_of_stay\n",
      "IDs à dropper: ['subject_id', 'HADM_ID']\n",
      "Booléennes traitées: ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
      "Catégorielles traitées: ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE', 'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes', 'TetanusLast10Tdap']\n",
      "Numériques traitées: ['AdmissionYear', 'AdmissionDayOfWeek', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost', 'AdmissionMonth', 'Age']\n",
      "⚠️ Attention : Colonnes non traitées (seront ignorées car remainder='drop'): ['HeightInMeters', 'WeightInKilograms', 'BMI']\n",
      "\n",
      "--- Dimensions des Données ---\n",
      "X_train shape: (103, 41)\n",
      "X_test shape: (26, 41)\n",
      "y_train shape: (103,)\n",
      "y_test shape: (26,)\n",
      "Préprocesseur: Pipeline booléen ajouté.\n",
      "Préprocesseur: Pipeline numérique ajouté.\n",
      "Préprocesseur: Pipeline catégoriel ajouté.\n",
      "\n",
      "--- Structure du Pipeline Complet ---\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('bool',\n",
      "                                                  Pipeline(steps=[('to_int',\n",
      "                                                                   FunctionTransformer(func=<function flexible_bool_to_int at 0x000001F17B74FB00>))]),\n",
      "                                                  ['AlcoholDrinkers',\n",
      "                                                   'CovidPos', 'HadHeartAttack',\n",
      "                                                   'HadAngina', 'HadStroke',\n",
      "                                                   'HadAsthma', 'HadSkinCancer',\n",
      "                                                   'HadCOPD',\n",
      "                                                   'HadDepressiveDisorder',\n",
      "                                                   'HadKidneyDisease',\n",
      "                                                   'HadArthritis',\n",
      "                                                   'Dea...\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['gender', 'ETHNICITY',\n",
      "                                                   'MARITAL_STATUS',\n",
      "                                                   'DIAGNOSIS',\n",
      "                                                   'ADMISSION_LOCATION',\n",
      "                                                   'ADMISSION_TYPE', 'LANGUAGE',\n",
      "                                                   'SmokerStatus',\n",
      "                                                   'ECigaretteUsage',\n",
      "                                                   'HadDiabetes',\n",
      "                                                   'TetanusLast10Tdap'])])),\n",
      "                ('model', RandomForestRegressor(n_jobs=-1, random_state=42))])\n",
      "\n",
      "🚀 Début de RandomizedSearchCV (20 itérations)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "✅ RandomizedSearchCV terminé.\n",
      "\n",
      "🏆 Meilleurs paramètres trouvés : {'model__max_depth': 33, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 426}\n",
      "Meilleur score CV (Negative RMSE) : -5.2588\n",
      "\n",
      "--- Évaluation Finale sur l'Ensemble de Test ---\n",
      "📉 Erreur Quadratique Moyenne Racine (RMSE) : 8.9107\n",
      "📈 Score R² : 0.8508\n",
      "\n",
      "✅ Pipeline complet sauvegardé sous : 'sejour_prediction_pipeline_v1.joblib'\n",
      "\n",
      "--- Simulation de Déploiement ---\n",
      "Pipeline chargé avec succès.\n",
      "\n",
      "Exemple de nouvelles données brutes (2 premières lignes de X_test):\n",
      "    DifficultyConcentrating  HadStroke  BlindOrVisionDifficulty  \\\n",
      "55                        0          0                        0   \n",
      "40                        1          0                        0   \n",
      "\n",
      "    HadSkinCancer  procedure_cost  HIVTesting  HadAngina ADMISSION_TYPE  \\\n",
      "55              0          7500.0           0          0      EMERGENCY   \n",
      "40              0         10500.0           1          0      EMERGENCY   \n",
      "\n",
      "   MARITAL_STATUS  AdmissionDayOfWeek  facility_cost  HadDepressiveDisorder  \\\n",
      "55         SINGLE                   5         6000.0                      0   \n",
      "40        WIDOWED                   4        17000.0                      1   \n",
      "\n",
      "    HadAsthma ETHNICITY  Age  HadCOPD  DifficultyWalking  \\\n",
      "55          0     WHITE   67        0                  0   \n",
      "40          1       NaN   83        1                  1   \n",
      "\n",
      "                   DIAGNOSIS LANGUAGE  AdmissionMonth  ChestScan  \\\n",
      "55                 PNEUMONIA     ENGL               8          1   \n",
      "40  CONGESTIVE HEART FAILURE      NaN               1          0   \n",
      "\n",
      "    DeafOrHardOfHearing  HadHeartAttack  medication_cost  AlcoholDrinkers  \\\n",
      "55                    0               0          42000.0                0   \n",
      "40                    0               0         116450.0                0   \n",
      "\n",
      "    HadKidneyDisease                            ECigaretteUsage  \\\n",
      "55                 0  Never used e-cigarettes in my entire life   \n",
      "40                 1  Never used e-cigarettes in my entire life   \n",
      "\n",
      "    DifficultyDressingBathing  total_cost  AdmissionYear  DifficultyErrands  \\\n",
      "55                          0    106400.0           2130                  0   \n",
      "40                          0    228350.0           2180                  1   \n",
      "\n",
      "    CovidPos  lab_test_cost  SmokerStatus  HadArthritis gender HadDiabetes  \\\n",
      "55         1        50900.0  Never smoked             0      F         Yes   \n",
      "40         0        84400.0  Never smoked             1      F          No   \n",
      "\n",
      "    FluVaxLast12    ADMISSION_LOCATION  \\\n",
      "55             0  EMERGENCY ROOM ADMIT   \n",
      "40             0  EMERGENCY ROOM ADMIT   \n",
      "\n",
      "                                    TetanusLast10Tdap  PneumoVaxEver  \n",
      "55  No, did not receive any tetanus shot in the pa...              0  \n",
      "40                                 Yes, received Tdap              0  \n",
      "Shape des nouvelles données: (2, 41)\n",
      "\n",
      "📊 Prédictions pour les nouvelles données : [ 5.90758191 16.12328505]\n",
      "\n",
      "Comparaison Vraie Valeur vs Prédiction:\n",
      "    Vraie Valeur  Prédiction\n",
      "55             6    5.907582\n",
      "40            17   16.123285\n",
      "\n",
      "🏁 Script terminé.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propreté de la sortie\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None # Désactiver avertissement pour copie\n",
    "\n",
    "# --- 1. Chargement des Données Brutes ---\n",
    "# REMPLACE CECI par le chemin correct vers ton fichier\n",
    "file_path = 'datasejour.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"✅ Données chargées depuis '{file_path}'. Shape: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erreur: Le fichier '{file_path}' n'a pas été trouvé.\")\n",
    "    # Tu pourrais ajouter exit() ici ou un exemple de données pour continuer\n",
    "    # Création de données exemples très basiques si fichier non trouvé\n",
    "    print(\"Création de données exemples...\")\n",
    "    data = pd.DataFrame({\n",
    "        'dob': ['1965-03-10', '1980-11-22', '1950-01-15', None, '1972-07-01'],\n",
    "        'AdmissionDate': ['2023-04-15', '2023-05-01', '2023-05-10', '2023-05-12', '2023-05-18'],\n",
    "        'AlcoholDrinkers': [True, False, True, False, True],\n",
    "        'HadHeartAttack': [False, False, True, False, False],\n",
    "        'gender': ['M', 'F', 'F', 'M', 'M'],\n",
    "        'ETHNICITY': ['WHITE', 'ASIAN', 'WHITE', 'BLACK/AFRICAN AMERICAN', 'UNKNOWN/NOT SPECIFIED'],\n",
    "        'total_cost': [15000, 25000, 50000, 10000, 30000],\n",
    "        'HeightInMeters': [1.75, 1.62, 1.58, 1.80, 1.70],\n",
    "        'WeightInKilograms': [80.5, 65.0, 75.3, 90.1, 70.0],\n",
    "        'length_of_stay': [5, 10, 15, 3, 8] # Cible\n",
    "    })\n",
    "    # Ajout d'autres colonnes bool et cat pour correspondre aux listes plus bas\n",
    "    data['CovidPos'] = [False]*5\n",
    "    data['HadAngina'] = [False]*5\n",
    "    data['HadStroke'] = [False]*5\n",
    "    data['HadAsthma'] = [False]*5\n",
    "    data['HadSkinCancer'] = [False]*5\n",
    "    data['HadCOPD'] = [False]*5\n",
    "    data['MARITAL_STATUS'] = ['MARRIED', 'SINGLE', 'WIDOWED', 'SINGLE', 'MARRIED']\n",
    "    data['DIAGNOSIS'] = ['PNEUMONIA', 'CHF', 'STROKE', 'SEPSIS', 'FRACTURE']\n",
    "    data['ADMISSION_LOCATION'] = ['EMERGENCY ROOM ADMIT', 'PHYS REFERRAL/NORMAL DELI', 'EMERGENCY ROOM ADMIT', 'TRANSFER FROM HOSP/EXTRAM', 'EMERGENCY ROOM ADMIT']\n",
    "    data['ADMISSION_TYPE'] = ['EMERGENCY', 'URGENT', 'EMERGENCY', 'EMERGENCY', 'URGENT']\n",
    "    data['LANGUAGE'] = ['ENGLISH', 'SPANISH', 'ENGLISH', 'ENGLISH', 'OTHER']\n",
    "    data['SmokerStatus'] = ['Former smoker', 'Never smoked', 'Current smoker - now smokes some days', 'Never smoked', 'Former smoker']\n",
    "    data['ECigaretteUsage'] = ['Not at all (right now)']*5\n",
    "    data['HadDiabetes'] = ['No, pre-diabetes or borderline diabetes', 'Yes', 'Yes', 'No, pre-diabetes or borderline diabetes', 'No, pre-diabetes or borderline diabetes']\n",
    "    data['TetanusLast10Tdap'] = ['Yes, received Tdap', 'Yes, received tetanus shot but not sure what type', 'Yes, received Tdap', 'Yes, received tetanus shot, but not Tdap', 'Yes, received Tdap']\n",
    "\n",
    "\n",
    "# --- 2. Feature Engineering (Exemple : Dates) ---\n",
    "# ASSURE-TOI QUE LES NOMS 'dob' ET 'AdmissionDate' SONT CORRECTS\n",
    "date_cols = ['dob', 'AdmissionDate']\n",
    "for col in date_cols:\n",
    "    if col in data.columns:\n",
    "        # Convertir en datetime, ignorer les erreurs pour l'instant (seront traitées par SimpleImputer)\n",
    "        data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# Créer 'Age' et autres features de date si les colonnes existent et sont des datetime\n",
    "if 'AdmissionDate' in data.columns and data['AdmissionDate'].dtype.kind == 'M':\n",
    "    data['AdmissionYear'] = data['AdmissionDate'].dt.year\n",
    "    data['AdmissionMonth'] = data['AdmissionDate'].dt.month\n",
    "    data['AdmissionDayOfWeek'] = data['AdmissionDate'].dt.dayofweek # Lundi=0, Dimanche=6\n",
    "\n",
    "    if 'dob' in data.columns and data['dob'].dtype.kind == 'M':\n",
    "        # Calculer l'âge (peut générer des NaN si dob ou AdmissionDate manquant/invalide)\n",
    "        data['Age'] = data['AdmissionYear'] - data['dob'].dt.year\n",
    "        # Gérer les cas où la date d'admission est avant la date de naissance dans la même année\n",
    "        data.loc[data['AdmissionDate'] < data['dob'], 'Age'] -= 1\n",
    "        print(\"✅ Colonne 'Age' créée.\")\n",
    "    else:\n",
    "         print(\"⚠️ Colonne 'dob' non trouvée ou non convertible en date. 'Age' non créée.\")\n",
    "    print(\"✅ Features 'AdmissionYear', 'AdmissionMonth', 'AdmissionDayOfWeek' créées.\")\n",
    "\n",
    "else:\n",
    "     print(\"⚠️ Colonne 'AdmissionDate' non trouvée ou non convertible en date. Features de date non créées.\")\n",
    "\n",
    "# --- 3. Identification des Colonnes par Type (APRÈS Feature Engineering) ---\n",
    "\n",
    "# Colonne Cible\n",
    "target_col = 'length_of_stay'\n",
    "if target_col not in data.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' n'est pas dans le DataFrame.\")\n",
    "\n",
    "# Colonnes ID à supprimer (Adapte si nécessaire)\n",
    "id_cols_to_drop = ['subject_id', 'HADM_ID']\n",
    "id_cols_to_drop = [col for col in id_cols_to_drop if col in data.columns]\n",
    "\n",
    "# Colonnes booléennes originales (vérifie les noms !)\n",
    "# Ces colonnes doivent contenir True/False ou 1/0 ou 'Yes'/'No' etc. dans le CSV brut\n",
    "bool_cols_original = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                      'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
    "                      'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', # Ces dernières étaient numériques avant ? Si elles sont Oui/Non, elles sont booléennes\n",
    "                      'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating',\n",
    "                      'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands',\n",
    "                      'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] # Idem\n",
    "bool_cols = [col for col in bool_cols_original if col in data.columns]\n",
    "\n",
    "# Colonnes Catégorielles (vérifie les noms !)\n",
    "categorical_cols_original = ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS',\n",
    "                             'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE',\n",
    "                             'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes',\n",
    "                             'TetanusLast10Tdap']\n",
    "categorical_cols = [col for col in categorical_cols_original if col in data.columns]\n",
    "\n",
    "# Colonnes Numériques\n",
    "# Inclut les features créées (Age, etc.) et les features numériques originales\n",
    "# Exclut la cible, les IDs, les booléennes et les catégorielles\n",
    "potential_num_cols = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore').columns\n",
    "numerical_cols = [col for col in potential_num_cols\n",
    "                  if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "print(f\"\\n--- Identification des Colonnes ---\")\n",
    "print(f\"Cible: {target_col}\")\n",
    "print(f\"IDs à dropper: {id_cols_to_drop}\")\n",
    "print(f\"Booléennes traitées: {bool_cols}\")\n",
    "print(f\"Catégorielles traitées: {categorical_cols}\")\n",
    "print(f\"Numériques traitées: {numerical_cols}\")\n",
    "\n",
    "# Vérifier si toutes les colonnes (sauf cible, IDs, dates originales) sont prises en compte\n",
    "all_features = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore').columns\n",
    "processed_features = set(bool_cols + categorical_cols + numerical_cols)\n",
    "unprocessed_cols = [col for col in all_features if col not in processed_features]\n",
    "if unprocessed_cols:\n",
    "    print(f\"⚠️ Attention : Colonnes non traitées (seront ignorées car remainder='drop'): {unprocessed_cols}\")\n",
    "\n",
    "# --- 4. Définition de la Fonction d'Encodage Booléen ---\n",
    "def flexible_bool_to_int(X_bool):\n",
    "    \"\"\"\n",
    "    Convertit diverses représentations de booléens (True/False, 1/0, Yes/No)\n",
    "    en entiers (1/0) et gère les NaN (en les traitant comme 0/False).\n",
    "    \"\"\"\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        # Créer une copie pour éviter SettingWithCopyWarning\n",
    "        X_series = X_bool.copy()\n",
    "        # Convertir explicitement les chaînes courantes en booléens\n",
    "        map_dict = {\n",
    "            'yes': True, 'true': True, '1': True, 1: True, True: True,\n",
    "            'no': False, 'false': False, '0': False, 0: False, False: False,\n",
    "            # Gérer les variantes de casse si nécessaire\n",
    "            'Yes': True, 'True': True,\n",
    "            'No': False, 'False': False\n",
    "        }\n",
    "        # Appliquer le mapping, garder les booléens existants, mettre NaN pour le reste\n",
    "        mapped = X_series.map(map_dict)\n",
    "        # Remplir les NaN et les valeurs non mappées par False, puis convertir en int\n",
    "        return mapped.fillna(False).astype(int)\n",
    "\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        # Appliquer la fonction à chaque colonne\n",
    "        return X_bool.apply(flexible_bool_to_int, axis=0)\n",
    "    else:\n",
    "        # Tenter une conversion directe pour les autres types (ex: numpy array)\n",
    "        try:\n",
    "            return pd.DataFrame(X_bool).fillna(False).astype(int) # Utiliser pandas pour fillna\n",
    "        except: # Si tout échoue, retourner tel quel ou lever une erreur\n",
    "             print(f\"Warning: Type non géré {type(X_bool)} dans flexible_bool_to_int\")\n",
    "             return X_bool\n",
    "\n",
    "\n",
    "# --- 5. Séparation Features / Cible et Train/Test Split ---\n",
    "X = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore')\n",
    "# Assurer que seules les colonnes à traiter sont gardées (si des unprocessed existent)\n",
    "X = X[list(processed_features)] # Garde seulement bool, cat, num\n",
    "y = data[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n--- Dimensions des Données ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# --- 6. Création des Pipelines de Prétraitement ---\n",
    "\n",
    "# Pipeline pour les booléens (imputation implicite dans la fonction)\n",
    "bool_pipeline = Pipeline(steps=[\n",
    "    ('to_int', FunctionTransformer(flexible_bool_to_int, validate=False))\n",
    "    # Pas besoin d'imputer ici car la fonction gère NaN\n",
    "])\n",
    "\n",
    "# Pipeline pour les numériques (imputation + mise à l'échelle)\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Impute les NaN avant scaling\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline pour les catégorielles (imputation + One-Hot Encoding)\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Ou 'constant', fill_value='Missing'\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Ignore les catégories inconnues lors de la prédiction\n",
    "])\n",
    "\n",
    "# --- 7. Création du Préprocesseur Global (ColumnTransformer) ---\n",
    "# Crée le préprocesseur seulement avec les types de colonnes qui existent\n",
    "transformers_list = []\n",
    "if bool_cols:\n",
    "    transformers_list.append(('bool', bool_pipeline, bool_cols))\n",
    "    print(\"Préprocesseur: Pipeline booléen ajouté.\")\n",
    "if numerical_cols:\n",
    "    transformers_list.append(('num', numerical_pipeline, numerical_cols))\n",
    "    print(\"Préprocesseur: Pipeline numérique ajouté.\")\n",
    "if categorical_cols:\n",
    "    transformers_list.append(('cat', categorical_pipeline, categorical_cols))\n",
    "    print(\"Préprocesseur: Pipeline catégoriel ajouté.\")\n",
    "\n",
    "if not transformers_list:\n",
    "    raise ValueError(\"Aucun type de colonne (bool, num, cat) n'a été trouvé pour le prétraitement.\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers_list,\n",
    "    remainder='drop' # Important: Ignorer les colonnes non spécifiées\n",
    ")\n",
    "\n",
    "# --- 8. Création du Pipeline Complet (Préprocesseur + Modèle) ---\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1)) # n_jobs=-1 pour utiliser tous les CPU\n",
    "])\n",
    "\n",
    "print(\"\\n--- Structure du Pipeline Complet ---\")\n",
    "print(full_pipeline)\n",
    "\n",
    "# --- 9. Recherche d'Hyperparamètres (RandomizedSearchCV) ---\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 600),       # Nombre d'arbres\n",
    "    'model__max_depth': randint(5, 40),             # Profondeur max de chaque arbre\n",
    "    'model__min_samples_split': randint(2, 15),     # Nb min d'échantillons pour splitter un noeud\n",
    "    'model__min_samples_leaf': randint(1, 15),      # Nb min d'échantillons dans une feuille\n",
    "    'model__max_features': ['sqrt', 'log2', 0.6, 0.8, None] # % de features à considérer (auto est obsolète) / None = toutes\n",
    "}\n",
    "\n",
    "# Réduire n_iter pour un test rapide, augmenter (ex: 50, 100) pour une recherche sérieuse\n",
    "n_iterations = 20 # Nombre d'itérations de la recherche aléatoire\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    full_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iterations,\n",
    "    cv=5, # 5-fold cross-validation\n",
    "    scoring='neg_root_mean_squared_error', # Optimiser pour minimiser la RMSE (négative car Scikit-learn maximise)\n",
    "    n_jobs=-1, # Utiliser tous les CPU disponibles\n",
    "    random_state=42,\n",
    "    verbose=1 # Afficher la progression\n",
    ")\n",
    "\n",
    "print(f\"\\n🚀 Début de RandomizedSearchCV ({n_iterations} itérations)...\")\n",
    "# Entraîner sur les données d'entraînement BRUTES (le pipeline gère le préproc)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"✅ RandomizedSearchCV terminé.\")\n",
    "\n",
    "# --- 10. Évaluation du Meilleur Modèle ---\n",
    "best_pipeline = random_search.best_estimator_\n",
    "print(f\"\\n🏆 Meilleurs paramètres trouvés : {random_search.best_params_}\")\n",
    "print(f\"Meilleur score CV (Negative RMSE) : {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test BRUT\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Évaluation Finale sur l'Ensemble de Test ---\")\n",
    "print(f\"📉 Erreur Quadratique Moyenne Racine (RMSE) : {final_rmse:.4f}\")\n",
    "print(f\"📈 Score R² : {final_r2:.4f}\")\n",
    "\n",
    "# --- 11. Sauvegarde du Pipeline Complet Entraîné ---\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "try:\n",
    "    joblib.dump(best_pipeline, pipeline_filename)\n",
    "    print(f\"\\n✅ Pipeline complet sauvegardé sous : '{pipeline_filename}'\")\n",
    "except Exception as e:\n",
    "     print(f\"\\n❌ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "\n",
    "\n",
    "# --- 12. Simulation de Déploiement (Chargement et Prédiction sur Données Brutes) ---\n",
    "print(\"\\n--- Simulation de Déploiement ---\")\n",
    "# S'assurer que le fichier existe avant de charger\n",
    "if 'pipeline_filename' in locals() and joblib.os.path.exists(pipeline_filename):\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(\"Pipeline chargé avec succès.\")\n",
    "\n",
    "    # Créer de nouvelles données brutes (doivent avoir les MÊMES colonnes que X_train)\n",
    "    # Utilisons quelques lignes de X_test comme exemple facile\n",
    "    if len(X_test) >= 2:\n",
    "        new_data_raw = X_test.iloc[0:2].copy() # Utilise les données brutes de X_test\n",
    "        print(\"\\nExemple de nouvelles données brutes (2 premières lignes de X_test):\")\n",
    "        # Afficher avec plus de colonnes si possible\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        print(new_data_raw)\n",
    "        pd.reset_option('display.max_columns')\n",
    "        print(f\"Shape des nouvelles données: {new_data_raw.shape}\")\n",
    "\n",
    "        # Faire des prédictions avec le pipeline chargé\n",
    "        # Le pipeline gère TOUT : imputation, encodage bool, OHE, scaling\n",
    "        try:\n",
    "            new_predictions = loaded_pipeline.predict(new_data_raw)\n",
    "            print(f\"\\n📊 Prédictions pour les nouvelles données : {new_predictions}\")\n",
    "\n",
    "            # Afficher les prédictions à côté des vraies valeurs pour comparaison\n",
    "            comparison = pd.DataFrame({'Vraie Valeur': y_test.iloc[0:2], 'Prédiction': new_predictions})\n",
    "            print(\"\\nComparaison Vraie Valeur vs Prédiction:\")\n",
    "            print(comparison)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\n❌ Erreur lors de la prédiction sur les nouvelles données : {e}\")\n",
    "            # Afficher les colonnes attendues vs fournies peut aider au débogage\n",
    "            try:\n",
    "                expected_cols = loaded_pipeline.named_steps['preprocessing']._feature_names_in\n",
    "                print(f\"Colonnes attendues par le préprocesseur: {expected_cols}\")\n",
    "            except AttributeError:\n",
    "                print(\"Impossible de récupérer les noms de colonnes attendues du préprocesseur.\")\n",
    "            print(f\"Colonnes fournies: {new_data_raw.columns.tolist()}\")\n",
    "\n",
    "    else:\n",
    "        print(\"X_test contient moins de 2 lignes, impossible de créer un exemple de données.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Le fichier pipeline '{pipeline_filename}' n'a pas été trouvé ou n'a pas pu être sauvegardé.\")\n",
    "\n",
    "print(\"\\n🏁 Script terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "856c9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline chargé depuis 'sejour_prediction_pipeline_v1.joblib'.\n",
      "\n",
      "Le modèle attend 41 features en entrée.\n",
      "\n",
      "--- Veuillez saisir les valeurs pour le nouveau patient ---\n",
      "Entrez la valeur pour 'DifficultyConcentrating' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadStroke' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'BlindOrVisionDifficulty' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadSkinCancer' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'procedure_cost' (nombre): 3000.0\n",
      "Entrez la valeur pour 'HIVTesting' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAngina' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'ADMISSION_TYPE' (texte, ex: WHITE, MARRIED, EMERGENCY): EMERGENCY\n",
      "Entrez la valeur pour 'MARITAL_STATUS' (texte, ex: WHITE, MARRIED, EMERGENCY): DIVORCED\n",
      "Entrez la valeur pour 'AdmissionDayOfWeek' (nombre): 2\n",
      "Entrez la valeur pour 'facility_cost' (nombre): 8000.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 130\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m      \u001b[38;5;66;03m# Si on n'a pas pu déterminer, on demande juste la valeur\u001b[39;00m\n\u001b[0;32m    127\u001b[0m      prompt_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 130\u001b[0m value_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(prompt_text)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# Gérer les valeurs vides (pourrait être traité comme NaN)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value_str:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split # Nécessaire si on recharge X_test/y_test\n",
    "import warnings\n",
    "from datetime import datetime # Si des dates sont utilisées pour l'âge etc.\n",
    "\n",
    "# Ignorer les avertissements pour la propreté\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes données BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "id_cols_to_drop_original = ['subject_id', 'HADM_ID'] # IDs à ignorer\n",
    "date_cols_original = ['dob', 'AdmissionDate'] # Dates utilisées pour créer des features\n",
    "\n",
    "# --- 2. Charger le Pipeline Entraîné ---\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(f\"✅ Pipeline chargé depuis '{pipeline_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erreur: Le fichier pipeline '{pipeline_filename}' n'a pas été trouvé.\")\n",
    "    print(\"Assure-toi d'avoir exécuté le script d'entraînement et de sauvegarde d'abord.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors du chargement du pipeline: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Obtenir les Noms des Features Attendues par le Pipeline (avant pré-traitement) ---\n",
    "# Normalement, ces features sont les colonnes de X utilisées lors de l'entraînement\n",
    "# Essayons de les récupérer du pipeline si possible, sinon on devra les lister manuellement\n",
    "# (Note: _feature_names_in est disponible dans les versions récentes de Scikit-learn)\n",
    "try:\n",
    "    # Accéder au ColumnTransformer dans le pipeline\n",
    "    preprocessor = loaded_pipeline.named_steps['preprocessing']\n",
    "    # Récupérer les noms de features d'entrée attendus par le préprocesseur\n",
    "    expected_feature_names = preprocessor.feature_names_in_\n",
    "    print(f\"\\nLe modèle attend {len(expected_feature_names)} features en entrée.\")\n",
    "    # print(\"Features attendues:\", expected_feature_names) # Décommente pour voir la liste complète\n",
    "except AttributeError:\n",
    "    print(\"\\n⚠️ Impossible de récupérer automatiquement les noms de features attendus.\")\n",
    "    print(\"   Tu devras t'assurer que les features demandées ci-dessous correspondent\")\n",
    "    print(\"   exactement à celles utilisées lors de l'entraînement (colonnes de X_train).\")\n",
    "    # !! SOLUTION DE REPLI : LISTER MANUELLEMENT LES FEATURES ICI !!\n",
    "    # expected_feature_names = ['Age', 'total_cost', 'gender', 'ETHNICITY', ... ] # Liste complète\n",
    "    print(\"   LE SCRIPT VA CONTINUER, MAIS VÉRIFIE BIEN LES FEATURES DEMANDÉES !\")\n",
    "    # Pour l'exemple, on va essayer de reconstruire X à partir des données brutes\n",
    "    # et prendre ses colonnes comme référence (moins fiable si le script d'entraînement a changé)\n",
    "    try:\n",
    "        temp_data = pd.read_csv(original_data_file)\n",
    "        # Recréer les features de date pour avoir Age etc si nécessaire\n",
    "        for col in date_cols_original:\n",
    "             if col in temp_data.columns:\n",
    "                 temp_data[col] = pd.to_datetime(temp_data[col], errors='coerce')\n",
    "        if 'AdmissionDate' in temp_data.columns and temp_data['AdmissionDate'].dtype.kind == 'M':\n",
    "            temp_data['AdmissionYear'] = temp_data['AdmissionDate'].dt.year\n",
    "            temp_data['AdmissionMonth'] = temp_data['AdmissionDate'].dt.month\n",
    "            temp_data['AdmissionDayOfWeek'] = temp_data['AdmissionDate'].dt.dayofweek\n",
    "            if 'dob' in temp_data.columns and temp_data['dob'].dtype.kind == 'M':\n",
    "                 temp_data['Age'] = temp_data['AdmissionYear'] - temp_data['dob'].dt.year\n",
    "                 temp_data.loc[temp_data['AdmissionDate'] < temp_data['dob'], 'Age'] -= 1\n",
    "\n",
    "        temp_X = temp_data.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "        # Tenter d'identifier les colonnes comme dans le script d'entraînement pour filtrer X\n",
    "        bool_cols = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in temp_X.columns]\n",
    "        categorical_cols = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in temp_X.columns]\n",
    "        potential_num_cols = temp_X.columns\n",
    "        numerical_cols = [col for col in potential_num_cols if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(temp_X[col])]\n",
    "        processed_features_list = bool_cols + categorical_cols + numerical_cols\n",
    "        expected_feature_names = [col for col in temp_X.columns if col in processed_features_list] # Garde l'ordre original\n",
    "        if not expected_feature_names:\n",
    "             print(\"❌ Impossible de déterminer les features attendues. Arrêt.\")\n",
    "             exit()\n",
    "        print(f\"   Utilisation des features déterminées à partir du fichier brut: {len(expected_feature_names)} features.\")\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"❌ Erreur lors de la tentative de détermination des features: {e}\")\n",
    "         exit()\n",
    "\n",
    "\n",
    "# --- 4. Saisie Manuelle des Valeurs des Features ---\n",
    "print(\"\\n--- Veuillez saisir les valeurs pour le nouveau patient ---\")\n",
    "input_data = {}\n",
    "for feature in expected_feature_names:\n",
    "    while True: # Boucle jusqu'à obtenir une entrée valide\n",
    "        try:\n",
    "            # Déterminer le type de la colonne (approximatif basé sur le nom/catégorie connue)\n",
    "            # Idéalement, on aurait les types exacts sauvegardés\n",
    "            prompt_text = f\"Entrez la valeur pour '{feature}'\"\n",
    "\n",
    "            # Identifier le type probable pour adapter le prompt/conversion\n",
    "            col_type = \"unknown\"\n",
    "            # Charger les données originales juste pour vérifier le type si nécessaire (coûteux)\n",
    "            # temp_col_type = X_train[feature].dtype # Nécessiterait X_train ici\n",
    "\n",
    "            # Simplification : demander comme texte, convertir si possible en nombre\n",
    "            # Pour les booléens, demander 'True'/'False' ou '1'/'0' ou 'Yes'/'No'\n",
    "            # Pour les catégorielles, juste le texte\n",
    "            # Pour les numériques, un nombre\n",
    "\n",
    "            # On pourrait essayer d'inférer le type mais c'est risqué.\n",
    "            # Le plus sûr est de demander en texte et laisser le pipeline gérer\n",
    "            # via flexible_bool_to_int, OneHotEncoder (qui prend texte), et StandardScaler (qui échouera si texte non convertible)\n",
    "            # => MAIS StandardScaler a besoin de nombres ! Il faut convertir AVANT.\n",
    "\n",
    "            # Tentative d'inférer le type pour guider l'utilisateur\n",
    "            is_numeric = False\n",
    "            is_boolean = False # Pour notre fonction custom\n",
    "            is_categorical = False\n",
    "\n",
    "            # Utilisons les listes définies dans le script d'entraînement (si on peut les reconstruire)\n",
    "            if 'bool_cols' in locals() and feature in bool_cols:\n",
    "                 is_boolean = True\n",
    "                 prompt_text += \" (ex: True/False, Yes/No, 1/0): \"\n",
    "            elif 'categorical_cols' in locals() and feature in categorical_cols:\n",
    "                 is_categorical = True\n",
    "                 prompt_text += \" (texte, ex: WHITE, MARRIED, EMERGENCY): \"\n",
    "            elif 'numerical_cols' in locals() and feature in numerical_cols:\n",
    "                 is_numeric = True\n",
    "                 prompt_text += \" (nombre): \"\n",
    "            else:\n",
    "                 # Si on n'a pas pu déterminer, on demande juste la valeur\n",
    "                 prompt_text += \": \"\n",
    "\n",
    "\n",
    "            value_str = input(prompt_text).strip()\n",
    "\n",
    "            # Gérer les valeurs vides (pourrait être traité comme NaN)\n",
    "            if not value_str:\n",
    "                 input_data[feature] = np.nan # Le pipeline doit gérer les NaN via Imputer\n",
    "                 print(f\"   -> Valeur manquante (NaN) enregistrée pour {feature}.\")\n",
    "                 break # Sortir de la boucle while pour cette feature\n",
    "\n",
    "            # Conversion de type basée sur l'inférence\n",
    "            if is_numeric:\n",
    "                try:\n",
    "                    input_data[feature] = float(value_str.replace(',', '.')) # Gérer virgule décimale\n",
    "                except ValueError:\n",
    "                    print(\"❌ Erreur: Veuillez entrer un nombre valide.\")\n",
    "                    continue # Redemander la même feature\n",
    "            elif is_boolean:\n",
    "                 # Notre fonction flexible_bool_to_int gère diverses entrées texte/nombre\n",
    "                 # On peut donc stocker la chaîne ou tenter une conversion basique\n",
    "                 input_data[feature] = value_str # Laisser flexible_bool_to_int faire le travail\n",
    "            elif is_categorical:\n",
    "                 input_data[feature] = value_str # Garder comme texte\n",
    "            else: # Cas \"unknown\"\n",
    "                 # Essayer de convertir en nombre, sinon garder comme texte\n",
    "                 try:\n",
    "                      input_data[feature] = float(value_str.replace(',', '.'))\n",
    "                 except ValueError:\n",
    "                      input_data[feature] = value_str\n",
    "\n",
    "            break # Sortir de la boucle while si l'entrée est valide pour le type\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Une erreur inattendue est survenue lors de la saisie: {e}\")\n",
    "            continue # Redemander\n",
    "\n",
    "# Créer un DataFrame pandas avec les données saisies (1 ligne)\n",
    "# S'assurer que l'ordre des colonnes est le même que celui attendu\n",
    "new_patient_df = pd.DataFrame([input_data], columns=expected_feature_names)\n",
    "\n",
    "print(\"\\n--- Données saisies pour la prédiction ---\")\n",
    "pd.set_option('display.max_columns', None) # Afficher toutes les colonnes\n",
    "print(new_patient_df)\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "# Vérifier les types de données (optionnel mais utile pour débogage)\n",
    "# print(\"\\nTypes de données dans le DataFrame avant prédiction:\")\n",
    "# print(new_patient_df.info())\n",
    "\n",
    "# --- 5. Faire la Prédiction ---\n",
    "try:\n",
    "    prediction = loaded_pipeline.predict(new_patient_df)\n",
    "    predicted_stay = prediction[0] # Obtenir la valeur unique prédite\n",
    "    print(\"\\n--- Prédiction ---\")\n",
    "    print(f\"📊 Durée de séjour prédite : {predicted_stay:.2f} jours\")\n",
    "\n",
    "except ValueError as ve:\n",
    "     print(f\"\\n❌ Erreur de valeur lors de la prédiction: {ve}\")\n",
    "     print(\"   Cela peut arriver si une catégorie textuelle saisie n'était pas\")\n",
    "     print(\"   présente dans les données d'entraînement et que handle_unknown='error'\")\n",
    "     print(\"   était utilisé dans OneHotEncoder (vérifiez qu'il est bien sur 'ignore').\")\n",
    "     print(\"   Ou si une valeur non numérique a été passée à StandardScaler.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Erreur lors de la prédiction : {e}\")\n",
    "    # Afficher les détails peut aider\n",
    "    # print(\"\\nDétails des données passées au pipeline:\")\n",
    "    # print(new_patient_df.iloc[0].to_dict())\n",
    "\n",
    "\n",
    "# --- 6. Afficher les Métriques Globales du Modèle (calculées sur le Test Set) ---\n",
    "print(\"\\n--- Performance Globale du Modèle (sur données test originales) ---\")\n",
    "# Pour cela, il nous faut X_test et y_test du split original\n",
    "try:\n",
    "    # Recharger les données brutes et refaire le split avec le même random_state\n",
    "    print(\"Recalcul des métriques sur l'ensemble de test original...\")\n",
    "    data_orig = pd.read_csv(original_data_file)\n",
    "\n",
    "    # --- Réappliquer le Feature Engineering Minimal (Age etc.) ---\n",
    "    for col in date_cols_original:\n",
    "        if col in data_orig.columns:\n",
    "            data_orig[col] = pd.to_datetime(data_orig[col], errors='coerce')\n",
    "    if 'AdmissionDate' in data_orig.columns and data_orig['AdmissionDate'].dtype.kind == 'M':\n",
    "        data_orig['AdmissionYear'] = data_orig['AdmissionDate'].dt.year\n",
    "        data_orig['AdmissionMonth'] = data_orig['AdmissionDate'].dt.month\n",
    "        data_orig['AdmissionDayOfWeek'] = data_orig['AdmissionDate'].dt.dayofweek\n",
    "        if 'dob' in data_orig.columns and data_orig['dob'].dtype.kind == 'M':\n",
    "            data_orig['Age'] = data_orig['AdmissionYear'] - data_orig['dob'].dt.year\n",
    "            data_orig.loc[data_orig['AdmissionDate'] < data_orig['dob'], 'Age'] -= 1\n",
    "\n",
    "    # --- Séparer X et y ---\n",
    "    X_orig = data_orig.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "    # Garder seulement les colonnes qui étaient effectivement utilisées\n",
    "    X_orig = X_orig[expected_feature_names]\n",
    "    y_orig = data_orig[target_column]\n",
    "\n",
    "    # --- Refaire le même split ---\n",
    "    _, X_test_reloaded, _, y_test_reloaded = train_test_split(\n",
    "        X_orig, y_orig, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- Faire les prédictions sur cet ensemble de test ---\n",
    "    y_pred_test = loaded_pipeline.predict(X_test_reloaded)\n",
    "\n",
    "    # --- Calculer et afficher les métriques ---\n",
    "    mse_test = mean_squared_error(y_test_reloaded, y_pred_test)\n",
    "    r2_test = r2_score(y_test_reloaded, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    print(f\"📉 Erreur Quadratique Moyenne (MSE) : {mse_test:.4f}\")\n",
    "    print(f\"   -> Erreur Quadratique Moyenne Racine (RMSE) : {rmse_test:.4f} jours\")\n",
    "    print(f\"📈 Score R² (Coefficient de détermination) : {r2_test:.4f}\")\n",
    "\n",
    "    # Interprétation simple du R² comme \"confiance\"\n",
    "    print(f\"   -> Le modèle explique environ {r2_test*100:.1f}% de la variance de la durée de séjour dans les données de test.\")\n",
    "    print(\"   (Note: R² mesure la qualité de l'ajustement global, pas la certitude d'une prédiction unique)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"   Impossible de recalculer les métriques : fichier de données original non trouvé.\")\n",
    "except Exception as e:\n",
    "    print(f\"   Erreur lors du recalcul des métriques sur le test set: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n🏁 Script de prédiction terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "416d1020",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ml/datasejour.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml/datasejour.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoms des features dans le DataFrame \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatesejour\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(datesejour\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml/datasejour.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"ml/datasejour.csv\")\n",
    "print(\"Noms des features dans le DataFrame 'datesejour':\")\n",
    "print(datesejour.columns.tolist())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b1faa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentative de lecture du fichier : 'datasejour.csv'\n",
      "Fichier 'datasejour.csv' chargé avec succès.\n",
      "Dimensions des données (lignes, colonnes) : (129, 47)\n",
      "\n",
      "--- Colonnes (Features) présentes dans le fichier ---\n",
      "Nombre total de colonnes : 47\n",
      "['subject_id', 'HADM_ID', 'gender', 'dob', 'HeightInMeters', 'WeightInKilograms', 'BMI', 'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos', 'LANGUAGE', 'ETHNICITY', 'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap', 'AdmissionDate', 'AdmissionYear', 'AdmissionDayOfWeek', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'length_of_stay', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Ignorer certains avertissements pour la propreté (optionnel)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Configuration fournie ---\n",
    "# pipeline_filename = 'sejour_prediction_pipeline_v1.joblib' # Non utilisé ici\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes données BRUTES originales\n",
    "# target_column = 'length_of_stay' # Non utilisé ici\n",
    "\n",
    "print(f\"Tentative de lecture du fichier : '{original_data_file}'\")\n",
    "\n",
    "# --- Chargement des données et affichage des colonnes ---\n",
    "try:\n",
    "    # Lire le fichier CSV dans un DataFrame pandas\n",
    "    # On utilise 'data' comme nom générique pour le DataFrame chargé\n",
    "    data = pd.read_csv(original_data_file)\n",
    "    print(f\"Fichier '{original_data_file}' chargé avec succès.\")\n",
    "    print(f\"Dimensions des données (lignes, colonnes) : {data.shape}\")\n",
    "\n",
    "\n",
    "    # Obtenir la liste des noms de colonnes (features + potentiellement la cible)\n",
    "    column_names = data.columns.tolist()\n",
    "\n",
    "    # Afficher la liste des colonnes\n",
    "    print(\"\\n--- Colonnes (Features) présentes dans le fichier ---\")\n",
    "    print(f\"Nombre total de colonnes : {len(column_names)}\")\n",
    "\n",
    "    # Afficher la liste complète :\n",
    "    print(column_names)\n",
    "\n",
    "    # Optionnel : Afficher chaque colonne sur une nouvelle ligne pour lisibilité\n",
    "    # print(\"\\nListe détaillée des colonnes :\")\n",
    "    # for i, col_name in enumerate(column_names):\n",
    "    #    print(f\"{i+1}. {col_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\n❌ ERREUR : Le fichier '{original_data_file}' n'a pas été trouvé.\")\n",
    "    print(\"   Veuillez vérifier que le nom du fichier et son emplacement sont corrects.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"\\n❌ ERREUR : Le fichier '{original_data_file}' est vide.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ ERREUR inattendue lors de la lecture du fichier '{original_data_file}':\")\n",
    "    print(f\"   {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "167358af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Utilisation d'un sous-ensemble de 29 features sélectionnées ---\n",
      "✅ Données brutes chargées depuis 'datasejour.csv'. Shape initial: (129, 47)\n",
      "✅ Données filtrées pour ne garder que les 29 features sélectionnées + cible. Shape filtré: (129, 30)\n",
      "\n",
      "--- Identification des Types (parmi les 29 features sélectionnées) ---\n",
      "Booléennes traitées: ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
      "Catégorielles traitées: ['SmokerStatus', 'ECigaretteUsage', 'MARITAL_STATUS', 'HadDiabetes', 'TetanusLast10Tdap', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE']\n",
      "Numériques traitées: []\n",
      "\n",
      "--- Dimensions des Données (Features Sélectionnées) ---\n",
      "X_train shape: (103, 29)\n",
      "X_test shape: (26, 29)\n",
      "Préprocesseur: Pipeline booléen ajouté.\n",
      "Préprocesseur: Pipeline catégoriel ajouté.\n",
      "\n",
      "--- Structure du Pipeline Complet (pour features sélectionnées) ---\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('bool',\n",
      "                                                  Pipeline(steps=[('to_int',\n",
      "                                                                   FunctionTransformer(func=<function flexible_bool_to_int at 0x000001F17B4B0E00>))]),\n",
      "                                                  ['AlcoholDrinkers',\n",
      "                                                   'CovidPos', 'HadHeartAttack',\n",
      "                                                   'HadAngina', 'HadStroke',\n",
      "                                                   'HadAsthma', 'HadSkinCancer',\n",
      "                                                   'HadCOPD',\n",
      "                                                   'HadDepressiveDisorder',\n",
      "                                                   'HadKidneyDisease',\n",
      "                                                   'HadArthritis',\n",
      "                                                   'Dea...\n",
      "                                                   'PneumoVaxEver']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['SmokerStatus',\n",
      "                                                   'ECigaretteUsage',\n",
      "                                                   'MARITAL_STATUS',\n",
      "                                                   'HadDiabetes',\n",
      "                                                   'TetanusLast10Tdap',\n",
      "                                                   'DIAGNOSIS',\n",
      "                                                   'ADMISSION_LOCATION',\n",
      "                                                   'ADMISSION_TYPE'])])),\n",
      "                ('model', RandomForestRegressor(n_jobs=-1, random_state=42))])\n",
      "\n",
      "🚀 Début de RandomizedSearchCV (20 itérations, sur features sélectionnées)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "✅ RandomizedSearchCV terminé.\n",
      "\n",
      "🏆 Meilleurs paramètres trouvés : {'model__max_depth': 38, 'model__max_features': 'log2', 'model__min_samples_leaf': 14, 'model__min_samples_split': 5, 'model__n_estimators': 369}\n",
      "Meilleur score CV (Negative RMSE) : -11.1444\n",
      "\n",
      "--- Évaluation Finale sur l'Ensemble de Test (Features Sélectionnées) ---\n",
      "📉 Erreur Quadratique Moyenne Racine (RMSE) : 22.9549\n",
      "📈 Score R² : 0.0096\n",
      "\n",
      "✅ Pipeline (entraîné sur features sélectionnées) sauvegardé sous : 'sejour_prediction_pipeline_SELECTED_FEATURES.joblib'\n",
      "\n",
      "🏁 Script d'entraînement (features sélectionnées) terminé.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propreté de la sortie\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None # Désactiver avertissement pour copie\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes données BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "pipeline_filename = 'sejour_prediction_pipeline_SELECTED_FEATURES.joblib' # Nouveau nom pour ce pipeline spécifique\n",
    "\n",
    "# --- !!! LISTE DES FEATURES SÉLECTIONNÉES À UTILISER !!! ---\n",
    "# Basée sur ta liste, en nettoyant les éventuelles virgules en trop\n",
    "selected_features = [\n",
    "    'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos',\n",
    "    'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke',\n",
    "    'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder',\n",
    "    'HadKidneyDisease', 'HadArthritis', 'HadDiabetes', 'DeafOrHardOfHearing',\n",
    "    'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking',\n",
    "    'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting',\n",
    "    'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap', 'DIAGNOSIS',\n",
    "    'ADMISSION_LOCATION', 'ADMISSION_TYPE'\n",
    "]\n",
    "print(f\"--- Utilisation d'un sous-ensemble de {len(selected_features)} features sélectionnées ---\")\n",
    "# print(\"Features utilisées:\", selected_features) # Décommente pour voir la liste\n",
    "\n",
    "# --- 2. Chargement et Filtrage des Données Brutes ---\n",
    "try:\n",
    "    data_full = pd.read_csv(original_data_file)\n",
    "    print(f\"✅ Données brutes chargées depuis '{original_data_file}'. Shape initial: {data_full.shape}\")\n",
    "\n",
    "    # Vérifier si toutes les features sélectionnées et la cible existent\n",
    "    required_cols = selected_features + [target_column]\n",
    "    missing_cols = [col for col in required_cols if col not in data_full.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Les colonnes suivantes sont requises mais manquantes dans le fichier CSV: {missing_cols}\")\n",
    "\n",
    "    # Garder UNIQUEMENT les colonnes sélectionnées + la colonne cible\n",
    "    data = data_full[required_cols].copy()\n",
    "    print(f\"✅ Données filtrées pour ne garder que les {len(selected_features)} features sélectionnées + cible. Shape filtré: {data.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erreur: Le fichier '{original_data_file}' n'a pas été trouvé.\")\n",
    "    exit()\n",
    "except ValueError as ve:\n",
    "    print(f\"❌ Erreur: {ve}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur inattendue lors du chargement/filtrage: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Identification des Colonnes par Type (parmi les features sélectionnées) ---\n",
    "\n",
    "# Séparer X (features sélectionnées) et y (cible)\n",
    "X = data[selected_features]\n",
    "y = data[target_column]\n",
    "\n",
    "# Identifier les types DANS LE SOUS-ENSEMBLE X\n",
    "# Utiliser les listes originales comme référence, mais filtrer par les colonnes de X\n",
    "bool_cols_original_ref = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                      'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
    "                      'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
    "                      'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating',\n",
    "                      'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands',\n",
    "                      'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
    "categorical_cols_original_ref = ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS',\n",
    "                             'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE',\n",
    "                             'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes',\n",
    "                             'TetanusLast10Tdap'] # gender/ETHNICITY/LANGUAGE ne sont pas dans ta liste sélectionnée\n",
    "\n",
    "bool_cols = [col for col in X.columns if col in bool_cols_original_ref]\n",
    "categorical_cols = [col for col in X.columns if col in categorical_cols_original_ref]\n",
    "numerical_cols = [col for col in X.columns if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(X[col])]\n",
    "# NOTE: Dans ta liste, il ne semble pas y avoir de colonnes numériques à part celles qui sont booléennes codées 0/1.\n",
    "# Si des colonnes comme 'total_cost' étaient dans ta liste, elles apparaîtraient ici.\n",
    "\n",
    "print(f\"\\n--- Identification des Types (parmi les {len(X.columns)} features sélectionnées) ---\")\n",
    "print(f\"Booléennes traitées: {bool_cols}\")\n",
    "print(f\"Catégorielles traitées: {categorical_cols}\")\n",
    "print(f\"Numériques traitées: {numerical_cols}\") # Probablement vide basé sur ta liste\n",
    "\n",
    "# Vérifier si toutes les colonnes sélectionnées sont classifiées\n",
    "processed_in_subset = set(bool_cols + categorical_cols + numerical_cols)\n",
    "unprocessed_in_subset = [col for col in X.columns if col not in processed_in_subset]\n",
    "if unprocessed_in_subset:\n",
    "    print(f\"⚠️ Attention : Colonnes sélectionnées non classifiées (seront ignorées): {unprocessed_in_subset}\")\n",
    "\n",
    "\n",
    "# --- 4. Définition de la Fonction d'Encodage Booléen ---\n",
    "# (Identique à avant)\n",
    "def flexible_bool_to_int(X_bool):\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        X_series = X_bool.copy()\n",
    "        map_dict = {\n",
    "            'yes': True, 'true': True, '1': True, 1: True, True: True,\n",
    "            'no': False, 'false': False, '0': False, 0: False, False: False,\n",
    "            'Yes': True, 'True': True, 'No': False, 'False': False\n",
    "        }\n",
    "        mapped = X_series.map(map_dict)\n",
    "        return mapped.fillna(False).astype(int)\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        return X_bool.apply(flexible_bool_to_int, axis=0)\n",
    "    else:\n",
    "        try: return pd.DataFrame(X_bool).fillna(False).astype(int)\n",
    "        except: print(f\"Warning: Type non géré {type(X_bool)}\"); return X_bool\n",
    "\n",
    "\n",
    "# --- 5. Train/Test Split (sur X filtré) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n--- Dimensions des Données (Features Sélectionnées) ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 6. Création des Pipelines de Prétraitement (pour les types présents) ---\n",
    "# (Pipelines identiques, mais ne seront appliqués qu'aux colonnes présentes dans bool_cols, numerical_cols, categorical_cols)\n",
    "\n",
    "bool_pipeline = Pipeline(steps=[('to_int', FunctionTransformer(flexible_bool_to_int, validate=False))])\n",
    "numerical_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "\n",
    "# --- 7. Création du Préprocesseur Global (ColumnTransformer pour le sous-ensemble) ---\n",
    "transformers_list = []\n",
    "if bool_cols:\n",
    "    transformers_list.append(('bool', bool_pipeline, bool_cols))\n",
    "    print(\"Préprocesseur: Pipeline booléen ajouté.\")\n",
    "if numerical_cols: # Probablement vide\n",
    "    transformers_list.append(('num', numerical_pipeline, numerical_cols))\n",
    "    print(\"Préprocesseur: Pipeline numérique ajouté.\")\n",
    "if categorical_cols:\n",
    "    transformers_list.append(('cat', categorical_pipeline, categorical_cols))\n",
    "    print(\"Préprocesseur: Pipeline catégoriel ajouté.\")\n",
    "\n",
    "if not transformers_list:\n",
    "    raise ValueError(\"Aucun type de colonne (bool, num, cat) n'a été trouvé parmi les features sélectionnées.\")\n",
    "\n",
    "# Le préprocesseur ne verra que les colonnes sélectionnées\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers_list,\n",
    "    remainder='drop' # Ignorer les colonnes non classifiées (devrait être vide si tout va bien)\n",
    ")\n",
    "\n",
    "\n",
    "# --- 8. Création du Pipeline Complet (Préprocesseur + Modèle) ---\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"\\n--- Structure du Pipeline Complet (pour features sélectionnées) ---\")\n",
    "print(full_pipeline)\n",
    "\n",
    "\n",
    "# --- 9. Recherche d'Hyperparamètres (RandomizedSearchCV) ---\n",
    "# (Paramètres identiques à avant)\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 600),\n",
    "    'model__max_depth': randint(5, 40),\n",
    "    'model__min_samples_split': randint(2, 15),\n",
    "    'model__min_samples_leaf': randint(1, 15),\n",
    "    'model__max_features': ['sqrt', 'log2', 0.6, 0.8, None]\n",
    "}\n",
    "n_iterations = 20 # Ajuste si besoin\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    full_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iterations,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\n🚀 Début de RandomizedSearchCV ({n_iterations} itérations, sur features sélectionnées)...\")\n",
    "# Entraîner sur X_train (qui ne contient QUE les features sélectionnées)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"✅ RandomizedSearchCV terminé.\")\n",
    "\n",
    "\n",
    "# --- 10. Évaluation du Meilleur Modèle ---\n",
    "best_pipeline = random_search.best_estimator_\n",
    "print(f\"\\n🏆 Meilleurs paramètres trouvés : {random_search.best_params_}\")\n",
    "print(f\"Meilleur score CV (Negative RMSE) : {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Faire des prédictions sur X_test (qui ne contient QUE les features sélectionnées)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les métriques\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Évaluation Finale sur l'Ensemble de Test (Features Sélectionnées) ---\")\n",
    "print(f\"📉 Erreur Quadratique Moyenne Racine (RMSE) : {final_rmse:.4f}\")\n",
    "print(f\"📈 Score R² : {final_r2:.4f}\")\n",
    "\n",
    "\n",
    "# --- 11. Sauvegarde du Pipeline Entraîné (pour features sélectionnées) ---\n",
    "try:\n",
    "    joblib.dump(best_pipeline, pipeline_filename)\n",
    "    print(f\"\\n✅ Pipeline (entraîné sur features sélectionnées) sauvegardé sous : '{pipeline_filename}'\")\n",
    "except Exception as e:\n",
    "     print(f\"\\n❌ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "\n",
    "\n",
    "print(\"\\n🏁 Script d'entraînement (features sélectionnées) terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e6ae701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Pipeline complet (toutes features) chargé depuis 'sejour_prediction_pipeline_v1.joblib'.\n",
      "\n",
      "Le pipeline complet attend 41 features en entrée.\n",
      "\n",
      "Nous allons vous demander de saisir 29 features clés (parmi les 41 attendues par le modèle).\n",
      "\n",
      "--- Veuillez saisir les valeurs pour les features clés du patient ---\n",
      "Entrez la valeur pour 'SmokerStatus' (texte): Former smoker\n",
      "Entrez la valeur pour 'ECigaretteUsage' (texte): Never used e-cigarettes in my entire life\n",
      "Entrez la valeur pour 'AlcoholDrinkers' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'CovidPos' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'MARITAL_STATUS' (texte): DIVORCED\n",
      "Entrez la valeur pour 'HadHeartAttack' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAngina' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadStroke' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAsthma' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadSkinCancer' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadCOPD' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadDepressiveDisorder' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadKidneyDisease' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadArthritis' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'HadDiabetes' (texte): Yes\n",
      "Entrez la valeur pour 'DeafOrHardOfHearing' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'BlindOrVisionDifficulty' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyConcentrating' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyWalking' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyDressingBathing' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyErrands' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'ChestScan' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HIVTesting' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'FluVaxLast12' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'PneumoVaxEver' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'TetanusLast10Tdap' (texte): Yes, received tetanus shot but not sure what type\n",
      "Entrez la valeur pour 'DIAGNOSIS' (texte): HUMERAL FRACTURE\n",
      "Entrez la valeur pour 'ADMISSION_LOCATION' (texte): EMERGENCY ROOM ADMIT\n",
      "Entrez la valeur pour 'ADMISSION_TYPE' (texte): EMERGENCY\n",
      "\n",
      "--- Données COMPLÈTES préparées pour la prédiction (avec NaN pour non-saisies) ---\n",
      "    SmokerStatus                            ECigaretteUsage AlcoholDrinkers  \\\n",
      "0  Former smoker  Never used e-cigarettes in my entire life               0   \n",
      "\n",
      "  CovidPos MARITAL_STATUS HadHeartAttack HadAngina HadStroke HadAsthma  \\\n",
      "0        0       DIVORCED              0         0         0         0   \n",
      "\n",
      "  HadSkinCancer  ... PneumoVaxEver  \\\n",
      "0             0  ...             1   \n",
      "\n",
      "                                   TetanusLast10Tdap         DIAGNOSIS  \\\n",
      "0  Yes, received tetanus shot but not sure what type  HUMERAL FRACTURE   \n",
      "\n",
      "     ADMISSION_LOCATION ADMISSION_TYPE procedure_cost AdmissionDayOfWeek  \\\n",
      "0  EMERGENCY ROOM ADMIT      EMERGENCY            NaN                NaN   \n",
      "\n",
      "  facility_cost ETHNICITY Age  \n",
      "0           NaN       NaN NaN  \n",
      "\n",
      "[1 rows x 34 columns]\n",
      "\n",
      "--- Prédiction ---\n",
      "📊 Durée de séjour prédite (par modèle complet): 7.00 jours\n",
      "   (Basée sur les valeurs saisies et les valeurs imputées par le modèle pour les autres features)\n",
      "\n",
      "--- Performance Globale du Modèle COMPLET (sur données test originales) ---\n",
      "Recalcul des métriques sur l'ensemble de test original...\n",
      "📉 Erreur Quadratique Moyenne (MSE) : 79.3998\n",
      "   -> Erreur Quadratique Moyenne Racine (RMSE) : 8.9107 jours\n",
      "📈 Score R² (Coefficient de détermination) : 0.8508\n",
      "   -> Le modèle explique environ 85.1% de la variance de la durée de séjour dans les données de test.\n",
      "   (Note: R² mesure la qualité de l'ajustement global du modèle chargé)\n",
      "\n",
      "🏁 Script de prédiction terminé.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split # Nécessaire si on recharge X_test/y_test\n",
    "import warnings\n",
    "from datetime import datetime # Si des dates sont utilisées pour l'âge etc.\n",
    "\n",
    "# Ignorer les avertissements pour la propreté\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# ON UTILISE LE PIPELINE ENTRAÎNÉ SUR TOUTES LES FEATURES\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes données BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "id_cols_to_drop_original = ['subject_id', 'HADM_ID'] # IDs à ignorer\n",
    "date_cols_original = ['dob', 'AdmissionDate'] # Dates utilisées pour créer des features DANS LE MODÈLE ORIGINAL\n",
    "\n",
    "# --- 2. Charger le Pipeline Entraîné (Celui avec toutes les features) ---\n",
    "try:\n",
    "    # Charger le pipeline qui donne le meilleur R2\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(f\"✅ Pipeline complet (toutes features) chargé depuis '{pipeline_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Erreur: Le fichier pipeline '{pipeline_filename}' n'a pas été trouvé.\")\n",
    "    print(\"   Assure-toi d'avoir exécuté le script d'entraînement COMPLET et de sauvegarde d'abord.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"❌ Erreur lors du chargement du pipeline: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Obtenir les Noms de TOUTES les Features Attendues par CE Pipeline ---\n",
    "try:\n",
    "    preprocessor = loaded_pipeline.named_steps['preprocessing']\n",
    "    all_expected_feature_names = preprocessor.feature_names_in_\n",
    "    print(f\"\\nLe pipeline complet attend {len(all_expected_feature_names)} features en entrée.\")\n",
    "    # print(\"Features attendues par le pipeline complet:\", list(all_expected_feature_names)) # Décommente pour vérifier\n",
    "except AttributeError:\n",
    "    print(\"\\n⚠️ Impossible de récupérer automatiquement les noms de features attendus du pipeline.\")\n",
    "    # Tenter de les reconstruire comme dans le script d'entraînement ORIGINAL\n",
    "    try:\n",
    "        print(\"   Tentative de reconstruction des features attendues à partir du fichier brut...\")\n",
    "        temp_data = pd.read_csv(original_data_file)\n",
    "        # REFAIRE LE FEATURE ENGINEERING DU SCRIPT ORIGINAL\n",
    "        for col in date_cols_original:\n",
    "             if col in temp_data.columns: temp_data[col] = pd.to_datetime(temp_data[col], errors='coerce')\n",
    "        if 'AdmissionDate' in temp_data.columns and temp_data['AdmissionDate'].dtype.kind == 'M':\n",
    "            temp_data['AdmissionYear'] = temp_data['AdmissionDate'].dt.year\n",
    "            temp_data['AdmissionMonth'] = temp_data['AdmissionDate'].dt.month\n",
    "            temp_data['AdmissionDayOfWeek'] = temp_data['AdmissionDate'].dt.dayofweek\n",
    "            if 'dob' in temp_data.columns and temp_data['dob'].dtype.kind == 'M':\n",
    "                 temp_data['Age'] = temp_data['AdmissionYear'] - temp_data['dob'].dt.year\n",
    "                 temp_data.loc[temp_data['AdmissionDate'] < temp_data['dob'], 'Age'] -= 1\n",
    "        # RE-IDENTIFIER LES TYPES COMME DANS LE SCRIPT ORIGINAL\n",
    "        temp_X = temp_data.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "        bool_cols_inf = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in temp_X.columns]\n",
    "        categorical_cols_inf = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in temp_X.columns]\n",
    "        potential_num_cols = temp_X.columns\n",
    "        numerical_cols_inf = [col for col in potential_num_cols if col not in bool_cols_inf and col not in categorical_cols_inf and pd.api.types.is_numeric_dtype(temp_X[col])]\n",
    "        processed_features_list = bool_cols_inf + categorical_cols_inf + numerical_cols_inf\n",
    "        all_expected_feature_names = [col for col in temp_X.columns if col in processed_features_list] # Garde l'ordre original\n",
    "        if not all_expected_feature_names:\n",
    "             print(\"❌ Impossible de déterminer les features attendues. Arrêt.\")\n",
    "             exit()\n",
    "        print(f\"   Utilisation des features déterminées à partir du fichier brut: {len(all_expected_feature_names)} features.\")\n",
    "    except Exception as e:\n",
    "         print(f\"❌ Erreur lors de la tentative de détermination des features: {e}\")\n",
    "         exit()\n",
    "\n",
    "# --- 4. Définir le Sous-Ensemble de Features à Demander (TA LISTE) ---\n",
    "# Nettoyage de la liste fournie (enlève virgule en trop, espaces)\n",
    "features_to_ask_user_raw = [\n",
    "    'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos', 'MARITAL_STATUS',\n",
    "    'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer',\n",
    "    'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
    "    'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
    "    'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing',\n",
    "    'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12',\n",
    "    'PneumoVaxEver', 'TetanusLast10Tdap', 'DIAGNOSIS', 'ADMISSION_LOCATION',\n",
    "    'ADMISSION_TYPE'\n",
    "]\n",
    "# Assurer que chaque feature demandée existe bien dans celles attendues par le pipeline\n",
    "features_to_ask_user = [f for f in features_to_ask_user_raw if f in all_expected_feature_names]\n",
    "missing_asked_features = set(features_to_ask_user_raw) - set(features_to_ask_user)\n",
    "if missing_asked_features:\n",
    "    print(f\"\\n⚠️ Attention: Les features suivantes de ta liste n'existent pas dans le modèle chargé et ne seront pas demandées: {missing_asked_features}\")\n",
    "\n",
    "if not features_to_ask_user:\n",
    "     print(\"❌ Aucune des features que tu as listées n'est attendue par le modèle chargé ! Vérifie ta liste et le modèle.\")\n",
    "     exit()\n",
    "\n",
    "print(f\"\\nNous allons vous demander de saisir {len(features_to_ask_user)} features clés (parmi les {len(all_expected_feature_names)} attendues par le modèle).\")\n",
    "# print(\"Features qui seront demandées:\", features_to_ask_user) # Décommente pour voir\n",
    "\n",
    "# --- 5. Saisie Manuelle des Valeurs pour les Features Clés ---\n",
    "print(\"\\n--- Veuillez saisir les valeurs pour les features clés du patient ---\")\n",
    "input_data_user = {}\n",
    "\n",
    "# Déterminer les types pour aider à la saisie (basé sur les listes reconstruites ou à inférer)\n",
    "# Réutilisation des listes inférées dans le bloc except ci-dessus si nécessaire\n",
    "if 'bool_cols_inf' not in locals(): # Si la récupération a réussi via feature_names_in_\n",
    "    bool_cols_rec = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in all_expected_feature_names]\n",
    "    categorical_cols_rec = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in all_expected_feature_names]\n",
    "    numerical_cols_rec = [col for col in all_expected_feature_names if col not in bool_cols_rec and col not in categorical_cols_rec]\n",
    "else: # Utiliser les listes du bloc except\n",
    "    bool_cols_rec = bool_cols_inf\n",
    "    categorical_cols_rec = categorical_cols_inf\n",
    "    numerical_cols_rec = numerical_cols_inf\n",
    "\n",
    "for feature in features_to_ask_user:\n",
    "    while True:\n",
    "        try:\n",
    "            prompt_text = f\"Entrez la valeur pour '{feature}'\"\n",
    "            is_numeric = feature in numerical_cols_rec\n",
    "            is_boolean = feature in bool_cols_rec\n",
    "            is_categorical = feature in categorical_cols_rec\n",
    "\n",
    "            if is_numeric: prompt_text += \" (nombre): \"\n",
    "            elif is_boolean: prompt_text += \" (ex: True/False, Yes/No, 1/0): \"\n",
    "            elif is_categorical: prompt_text += \" (texte): \"\n",
    "            else: prompt_text += \": \" # Si non classifié\n",
    "\n",
    "            value_str = input(prompt_text).strip()\n",
    "\n",
    "            if not value_str:\n",
    "                input_data_user[feature] = np.nan\n",
    "                print(f\"   -> Valeur manquante (NaN) enregistrée pour {feature}.\")\n",
    "                break\n",
    "            if is_numeric:\n",
    "                try: input_data_user[feature] = float(value_str.replace(',', '.'))\n",
    "                except ValueError: print(\"❌ Erreur: Veuillez entrer un nombre valide.\"); continue\n",
    "            else: # Pour bool et cat, on stocke la chaîne, le pipeline gérera\n",
    "                input_data_user[feature] = value_str\n",
    "            break\n",
    "        except Exception as e: print(f\"❌ Erreur saisie: {e}\"); continue\n",
    "\n",
    "# --- 6. Préparer le DataFrame COMPLET pour la Prédiction ---\n",
    "# Initialiser avec NaN pour TOUTES les features attendues par le pipeline complet\n",
    "input_data_full = {feature: np.nan for feature in all_expected_feature_names}\n",
    "\n",
    "# Remplacer les NaN par les valeurs saisies par l'utilisateur pour les features clés\n",
    "for feature, value in input_data_user.items():\n",
    "    if feature in input_data_full: # Double vérification\n",
    "        input_data_full[feature] = value\n",
    "\n",
    "# Créer le DataFrame final avec une seule ligne et le bon ordre de colonnes\n",
    "new_patient_df_full = pd.DataFrame([input_data_full], columns=all_expected_feature_names)\n",
    "\n",
    "print(\"\\n--- Données COMPLÈTES préparées pour la prédiction (avec NaN pour non-saisies) ---\")\n",
    "# Afficher seulement les colonnes demandées et quelques autres pour contexte si trop nombreuses\n",
    "if len(all_expected_feature_names) > 20:\n",
    "     cols_to_show = features_to_ask_user + [c for c in all_expected_feature_names if c not in features_to_ask_user][:5] # Montre 5 non demandées\n",
    "     print(new_patient_df_full[cols_to_show])\n",
    "else:\n",
    "     pd.set_option('display.max_columns', None)\n",
    "     print(new_patient_df_full)\n",
    "     pd.reset_option('display.max_columns')\n",
    "\n",
    "# --- 7. Faire la Prédiction avec le Pipeline Complet ---\n",
    "try:\n",
    "    # Le pipeline complet gère les NaN grâce aux SimpleImputer\n",
    "    prediction = loaded_pipeline.predict(new_patient_df_full)\n",
    "    predicted_stay = prediction[0]\n",
    "    print(\"\\n--- Prédiction ---\")\n",
    "    print(f\"📊 Durée de séjour prédite (par modèle complet): {predicted_stay:.2f} jours\")\n",
    "    print(\"   (Basée sur les valeurs saisies et les valeurs imputées par le modèle pour les autres features)\")\n",
    "\n",
    "except ValueError as ve:\n",
    "     print(f\"\\n❌ Erreur de valeur lors de la prédiction: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌ Erreur lors de la prédiction : {e}\")\n",
    "\n",
    "# --- 8. Afficher les Métriques Globales du Modèle COMPLET (calculées sur le Test Set original) ---\n",
    "print(\"\\n--- Performance Globale du Modèle COMPLET (sur données test originales) ---\")\n",
    "try:\n",
    "    print(\"Recalcul des métriques sur l'ensemble de test original...\")\n",
    "    data_orig = pd.read_csv(original_data_file)\n",
    "    # REFAIRE LE FEATURE ENGINEERING DU SCRIPT ORIGINAL\n",
    "    for col in date_cols_original:\n",
    "        if col in data_orig.columns: data_orig[col] = pd.to_datetime(data_orig[col], errors='coerce')\n",
    "    if 'AdmissionDate' in data_orig.columns and data_orig['AdmissionDate'].dtype.kind == 'M':\n",
    "        data_orig['AdmissionYear'] = data_orig['AdmissionDate'].dt.year\n",
    "        data_orig['AdmissionMonth'] = data_orig['AdmissionDate'].dt.month\n",
    "        data_orig['AdmissionDayOfWeek'] = data_orig['AdmissionDate'].dt.dayofweek\n",
    "        if 'dob' in data_orig.columns and data_orig['dob'].dtype.kind == 'M':\n",
    "            data_orig['Age'] = data_orig['AdmissionYear'] - data_orig['dob'].dt.year\n",
    "            data_orig.loc[data_orig['AdmissionDate'] < data_orig['dob'], 'Age'] -= 1\n",
    "    # Séparer X et y originaux\n",
    "    X_orig = data_orig.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "    # S'assurer que X_orig a exactement les colonnes attendues par le pipeline chargé\n",
    "    missing_cols = set(all_expected_feature_names) - set(X_orig.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"❌ Erreur: Les colonnes suivantes attendues par le pipeline manquent dans {original_data_file} lors du rechargement: {missing_cols}\")\n",
    "        raise ValueError(\"Colonnes manquantes pour recalcul métriques\")\n",
    "    X_orig = X_orig[all_expected_feature_names] # Garder seulement celles attendues et dans le bon ordre\n",
    "    y_orig = data_orig[target_column]\n",
    "\n",
    "    # Refaire le même split\n",
    "    _, X_test_reloaded, _, y_test_reloaded = train_test_split(X_orig, y_orig, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Prédire avec le pipeline complet chargé\n",
    "    y_pred_test = loaded_pipeline.predict(X_test_reloaded)\n",
    "\n",
    "    # Calculer les métriques du modèle complet\n",
    "    mse_test = mean_squared_error(y_test_reloaded, y_pred_test)\n",
    "    r2_test = r2_score(y_test_reloaded, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    print(f\"📉 Erreur Quadratique Moyenne (MSE) : {mse_test:.4f}\")\n",
    "    print(f\"   -> Erreur Quadratique Moyenne Racine (RMSE) : {rmse_test:.4f} jours\")\n",
    "    print(f\"📈 Score R² (Coefficient de détermination) : {r2_test:.4f}\")\n",
    "    print(f\"   -> Le modèle explique environ {r2_test*100:.1f}% de la variance de la durée de séjour dans les données de test.\")\n",
    "    print(\"   (Note: R² mesure la qualité de l'ajustement global du modèle chargé)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"   Impossible de recalculer les métriques : fichier de données original non trouvé.\")\n",
    "except ValueError as ve:\n",
    "     print(f\"   Erreur lors de la préparation des données pour le recalcul des métriques: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Erreur lors du recalcul des métriques sur le test set: {e}\")\n",
    "\n",
    "print(\"\\n🏁 Script de prédiction terminé.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa812d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
