{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b450bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b89bbbb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject_id</th>\n",
       "      <th>HADM_ID</th>\n",
       "      <th>gender</th>\n",
       "      <th>dob</th>\n",
       "      <th>HeightInMeters</th>\n",
       "      <th>WeightInKilograms</th>\n",
       "      <th>BMI</th>\n",
       "      <th>SmokerStatus</th>\n",
       "      <th>ECigaretteUsage</th>\n",
       "      <th>AlcoholDrinkers</th>\n",
       "      <th>...</th>\n",
       "      <th>AdmissionDayOfWeek</th>\n",
       "      <th>DIAGNOSIS</th>\n",
       "      <th>ADMISSION_LOCATION</th>\n",
       "      <th>ADMISSION_TYPE</th>\n",
       "      <th>length_of_stay</th>\n",
       "      <th>facility_cost</th>\n",
       "      <th>procedure_cost</th>\n",
       "      <th>medication_cost</th>\n",
       "      <th>lab_test_cost</th>\n",
       "      <th>total_cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10017</td>\n",
       "      <td>199207</td>\n",
       "      <td>F</td>\n",
       "      <td>2075-09-21 00:00:00</td>\n",
       "      <td>1,77999997138977</td>\n",
       "      <td>95,25</td>\n",
       "      <td>30,1299991607666</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>HUMERAL FRACTURE</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>8</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>42000.0</td>\n",
       "      <td>47700.0</td>\n",
       "      <td>100700.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10013</td>\n",
       "      <td>165520</td>\n",
       "      <td>F</td>\n",
       "      <td>2038-09-03 00:00:00</td>\n",
       "      <td>1,77999997138977</td>\n",
       "      <td>71,2099990844727</td>\n",
       "      <td>22,5300006866455</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>2</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>3600.0</td>\n",
       "      <td>14800.0</td>\n",
       "      <td>21900.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10011</td>\n",
       "      <td>105331</td>\n",
       "      <td>F</td>\n",
       "      <td>2090-06-05 00:00:00</td>\n",
       "      <td>1,60000002384186</td>\n",
       "      <td>71,6699981689453</td>\n",
       "      <td>27,9899997711182</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>HEPATITIS B</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>13</td>\n",
       "      <td>13000.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>70000.0</td>\n",
       "      <td>86000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10006</td>\n",
       "      <td>142345</td>\n",
       "      <td>F</td>\n",
       "      <td>2094-03-05 00:00:00</td>\n",
       "      <td>1,62999999523163</td>\n",
       "      <td>84,8199996948242</td>\n",
       "      <td>32,0999984741211</td>\n",
       "      <td>Former smoker</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>SEPSIS</td>\n",
       "      <td>EMERGENCY ROOM ADMIT</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>8</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>10500.0</td>\n",
       "      <td>21600.0</td>\n",
       "      <td>196300.0</td>\n",
       "      <td>236400.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10019</td>\n",
       "      <td>177759</td>\n",
       "      <td>M</td>\n",
       "      <td>2114-06-20 00:00:00</td>\n",
       "      <td>1,67999994754791</td>\n",
       "      <td>78,0199966430664</td>\n",
       "      <td>27,7600002288818</td>\n",
       "      <td>Never smoked</td>\n",
       "      <td>Never used e-cigarettes in my entire life</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>ALCOHOLIC HEPATITIS</td>\n",
       "      <td>TRANSFER FROM HOSP/EXTRAM</td>\n",
       "      <td>EMERGENCY</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28700.0</td>\n",
       "      <td>34700.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   subject_id  HADM_ID gender                  dob    HeightInMeters  \\\n",
       "0       10017   199207      F  2075-09-21 00:00:00  1,77999997138977   \n",
       "1       10013   165520      F  2038-09-03 00:00:00  1,77999997138977   \n",
       "2       10011   105331      F  2090-06-05 00:00:00  1,60000002384186   \n",
       "3       10006   142345      F  2094-03-05 00:00:00  1,62999999523163   \n",
       "4       10019   177759      M  2114-06-20 00:00:00  1,67999994754791   \n",
       "\n",
       "  WeightInKilograms               BMI   SmokerStatus  \\\n",
       "0             95,25  30,1299991607666  Former smoker   \n",
       "1  71,2099990844727  22,5300006866455   Never smoked   \n",
       "2  71,6699981689453  27,9899997711182  Former smoker   \n",
       "3  84,8199996948242  32,0999984741211  Former smoker   \n",
       "4  78,0199966430664  27,7600002288818   Never smoked   \n",
       "\n",
       "                             ECigaretteUsage  AlcoholDrinkers  ...  \\\n",
       "0  Never used e-cigarettes in my entire life                0  ...   \n",
       "1  Never used e-cigarettes in my entire life                1  ...   \n",
       "2  Never used e-cigarettes in my entire life                0  ...   \n",
       "3  Never used e-cigarettes in my entire life                0  ...   \n",
       "4  Never used e-cigarettes in my entire life                0  ...   \n",
       "\n",
       "   AdmissionDayOfWeek            DIAGNOSIS         ADMISSION_LOCATION  \\\n",
       "0                   2     HUMERAL FRACTURE       EMERGENCY ROOM ADMIT   \n",
       "1                   5               SEPSIS  TRANSFER FROM HOSP/EXTRAM   \n",
       "2                   4          HEPATITIS B  TRANSFER FROM HOSP/EXTRAM   \n",
       "3                   3               SEPSIS       EMERGENCY ROOM ADMIT   \n",
       "4                   7  ALCOHOLIC HEPATITIS  TRANSFER FROM HOSP/EXTRAM   \n",
       "\n",
       "  ADMISSION_TYPE  length_of_stay  facility_cost  procedure_cost  \\\n",
       "0      EMERGENCY               8         8000.0          3000.0   \n",
       "1      EMERGENCY               2         2000.0          1500.0   \n",
       "2      EMERGENCY              13        13000.0          3000.0   \n",
       "3      EMERGENCY               8         8000.0         10500.0   \n",
       "4      EMERGENCY               0            0.0          6000.0   \n",
       "\n",
       "   medication_cost  lab_test_cost  total_cost  \n",
       "0          42000.0        47700.0    100700.0  \n",
       "1           3600.0        14800.0     21900.0  \n",
       "2              0.0        70000.0     86000.0  \n",
       "3          21600.0       196300.0    236400.0  \n",
       "4              0.0        28700.0     34700.0  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chargement des donnÃ©es depuis un fichier CSV\n",
    "data = pd.read_csv(\"readmission_des_patients.csv\")\n",
    "\n",
    "# Affichage des premiÃ¨res lignes pour vÃ©rification\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a348b888",
   "metadata": {},
   "source": [
    "b. Traitement des donnÃ©es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc84bb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['subject_id', 'HADM_ID', 'gender', 'dob', 'HeightInMeters',\n",
      "       'WeightInKilograms', 'BMI', 'SmokerStatus', 'ECigaretteUsage',\n",
      "       'AlcoholDrinkers', 'CovidPos', 'LANGUAGE', 'ETHNICITY',\n",
      "       'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke',\n",
      "       'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder',\n",
      "       'HadKidneyDisease', 'HadArthritis', 'HadDiabetes',\n",
      "       'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
      "       'DifficultyConcentrating', 'DifficultyWalking',\n",
      "       'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan',\n",
      "       'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap',\n",
      "       'AdmissionDate', 'AdmissionYear', 'AdmissionDayOfWeek', 'DIAGNOSIS',\n",
      "       'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'length_of_stay',\n",
      "       'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost',\n",
      "       'total_cost'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Afficher les noms des colonnes du DataFrame\n",
    "print(data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c70ef122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 501.85889903115464\n",
      "R-squared: 0.07116092149700881\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SÃ©lection des colonnes pour l'encodage\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "\n",
    "# Encoder les variables catÃ©gorielles (True -> 1, False -> 0)\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# SÃ©lectionner les variables d'entrÃ©e (X) et la variable cible (y)\n",
    "X = data[['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']]  # Exemple d'entrÃ©e\n",
    "y = data['length_of_stay']  # DurÃ©e du sÃ©jour\n",
    "\n",
    "# SÃ©paration des donnÃ©es en train et test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation des donnÃ©es\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# EntraÃ®ner un modÃ¨le de rÃ©gression linÃ©aire\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# PrÃ©dictions sur les donnÃ©es de test\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Ã‰valuer le modÃ¨le\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Afficher les rÃ©sultats\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "print(f'R-squared: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4552648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 484.07\n",
      "R-squared Score: 0.10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Encodage des colonnes catÃ©gorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# SÃ©lection des features (vous pouvez en ajouter selon votre dataset)\n",
    "features = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "            'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "X = data[features]\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# SÃ©paration des donnÃ©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# ModÃ¨le : Gradient Boosting Regressor\n",
    "model = GradientBoostingRegressor(random_state=42)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# PrÃ©dictions\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Ã‰valuation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Affichage des rÃ©sultats\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "abe98e80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 36 candidates, totalling 180 fits\n",
      "Best parameters found: {'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 100, 'subsample': 0.8}\n",
      "Mean Squared Error: 454.20\n",
      "R-squared Score: 0.16\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Encodage des colonnes catÃ©gorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# DÃ©finir les features\n",
    "features = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "            'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "X = data[features]\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# Train/test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# GridSearchCV pour le fine-tuning\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'learning_rate': [0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'subsample': [0.8, 1.0]\n",
    "}\n",
    "\n",
    "gbr = GradientBoostingRegressor(random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=gbr, param_grid=param_grid,\n",
    "                           cv=5, scoring='r2', n_jobs=-1, verbose=1)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Meilleur modÃ¨le\n",
    "best_model = grid_search.best_estimator_\n",
    "\n",
    "# PrÃ©diction\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Ã‰valuation\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# RÃ©sultats\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'R-squared Score: {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbb123b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 48 candidates, totalling 240 fits\n",
      "âœ… Best parameters found: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "ðŸ“‰ Mean Squared Error: 281.53845518822624\n",
      "ðŸ“ˆ R-squared Score: 0.4789293967188296\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "\n",
    "\n",
    "# 2. Encoder les colonnes boolÃ©ennes (True/False)\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# 3. Encoder automatiquement les colonnes catÃ©gorielles (type object)\n",
    "object_cols = data.select_dtypes(include='object').columns\n",
    "data = pd.get_dummies(data, columns=object_cols, drop_first=True)\n",
    "\n",
    "# 4. DÃ©finir les features et la target\n",
    "X = data.drop(columns=['length_of_stay'])  # Variable cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# 5. Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# 7. GridSearchCV\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200],\n",
    "    'max_depth': [5, 10, 15],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'max_features': ['sqrt', 'log2']\n",
    "}\n",
    "\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, \n",
    "                           cv=5, scoring='neg_mean_squared_error', n_jobs=-1, verbose=2)\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# 8. Ã‰valuation\n",
    "best_rf = grid_search.best_estimator_\n",
    "y_pred = best_rf.predict(X_test_scaled)\n",
    "\n",
    "print(\"âœ… Best parameters found:\", grid_search.best_params_)\n",
    "print(\"ðŸ“‰ Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ R-squared Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "30a4ab68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "âœ… Best params: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "ðŸ“‰ MSE: 85.98860516306071\n",
      "ðŸ“ˆ RÂ²: 0.8408525246127863\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from scipy.stats import randint\n",
    "\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"âœ… Best params:\", random_search.best_params_)\n",
    "print(\"ðŸ“‰ MSE:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ RÂ²:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a6b4e38d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "âœ… Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "ðŸ“‰ Mean Squared Error : 85.98860516306071\n",
      "ðŸ“ˆ RÂ² Score: 0.8408525246127863\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# ðŸ”„ Chargement des donnÃ©es (ajoute ton propre chemin si nÃ©cessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# âœ… 1. Encodage des boolÃ©ens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# Encodage des colonnes catÃ©gorielles (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# âœ… 3. Features et Target\n",
    "X = data.drop(columns=['length_of_stay'])\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# âœ… 4. Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… 5. Normalisation\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# âœ… 6. ModÃ¨le de base\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "\n",
    "# âœ… 8. RandomizedSearchCV (plus puissant)\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# âœ… 9. Ã‰valuation finale\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"âœ… Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"ðŸ“‰ Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9dd4096c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "âœ… Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "ðŸ“‰ Mean Squared Error : 85.98860516306071\n",
      "ðŸ“ˆ RÂ² Score: 0.8408525246127863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# ðŸ”„ Charger les donnÃ©es (ajoute ton propre chemin si nÃ©cessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# âœ… 1. Encodage des boolÃ©ens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# âœ… 2. Encodage des colonnes boolÃ©ennes (True/False -> 1/0)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in categorical_cols:\n",
    "    data[col] = data[col].replace({True: 1, False: 0})\n",
    "\n",
    "# âœ… 3. SÃ©lection des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])  # On exclut la colonne 'length_of_stay' qui est notre cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# âœ… 4. Split des donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… 5. Normalisation uniquement sur les features (X)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Normalisation de l'ensemble d'entraÃ®nement\n",
    "X_test_scaled = scaler.transform(X_test)  # Utilisation du mÃªme scaler pour l'ensemble de test\n",
    "\n",
    "# âœ… 6. ModÃ¨le de base - RandomForest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# âœ… 7. ParamÃ¨tres de recherche pour RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# âœ… 8. Recherche alÃ©atoire des meilleurs paramÃ¨tres\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# âœ… 9. Ã‰valuation du modÃ¨le\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# âœ… 10. RÃ©sultats de l'Ã©valuation\n",
    "print(\"âœ… Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"ðŸ“‰ Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# âœ… 11. Sauvegarde du modÃ¨le et du scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "00d69316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "âœ… Best params from RandomizedSearchCV: {'max_depth': 26, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 223}\n",
      "ðŸ“‰ Mean Squared Error : 85.98860516306071\n",
      "ðŸ“ˆ RÂ² Score: 0.8408525246127863\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# ðŸ”„ Charger les donnÃ©es (ajoute ton propre chemin si nÃ©cessaire)\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# âœ… 1. Encodage des boolÃ©ens\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "for col in bool_cols:\n",
    "    if col in data.columns:\n",
    "        data[col] = data[col].astype(int)\n",
    "\n",
    "# âœ… 2. Encodage des colonnes catÃ©gorielles (avec LabelEncoder)\n",
    "categorical_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', \n",
    "                    'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in categorical_cols:\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# âœ… 3. SÃ©lection des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])  # On exclut la colonne 'length_of_stay' qui est notre cible\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# âœ… 4. Split des donnÃ©es en ensembles d'entraÃ®nement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… 5. Normalisation uniquement sur les features (X)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)  # Normalisation de l'ensemble d'entraÃ®nement\n",
    "X_test_scaled = scaler.transform(X_test)  # Utilisation du mÃªme scaler pour l'ensemble de test\n",
    "\n",
    "# âœ… 6. ModÃ¨le de base - RandomForest\n",
    "rf = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# âœ… 7. ParamÃ¨tres de recherche pour RandomizedSearchCV\n",
    "param_dist = {\n",
    "    'n_estimators': randint(100, 500),\n",
    "    'max_depth': randint(5, 30),\n",
    "    'min_samples_split': randint(2, 10),\n",
    "    'min_samples_leaf': randint(1, 10),\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# âœ… 8. Recherche alÃ©atoire des meilleurs paramÃ¨tres\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error', \n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "# âœ… 9. Ã‰valuation du modÃ¨le\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# âœ… 10. RÃ©sultats de l'Ã©valuation\n",
    "print(\"âœ… Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"ðŸ“‰ Mean Squared Error :\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ RÂ² Score:\", r2_score(y_test, y_pred))\n",
    "\n",
    "# âœ… 11. Sauvegarde du modÃ¨le et du scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c197943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "âœ… Best params from RandomizedSearchCV: {'model__max_depth': 26, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 2, 'model__n_estimators': 223}\n",
      "ðŸ“‰ Mean Squared Error: 84.86472527251551\n",
      "ðŸ“ˆ RÂ² Score: 0.8429325984420983\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "\n",
    "# ðŸ”„ Charger les donnÃ©es\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\")\n",
    "\n",
    "# âœ… Liste des colonnes boolÃ©ennes Ã  encoder\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "\n",
    "# âœ… 1. SÃ©paration des features et de la cible\n",
    "X = data.drop(columns=['length_of_stay'])\n",
    "y = data['length_of_stay']\n",
    "\n",
    "# âœ… 2. Pipeline pour l'encodage boolÃ©en (True/False â†’ int)\n",
    "bool_encoder = FunctionTransformer(lambda x: x.astype(int))\n",
    "\n",
    "# âœ… 3. PrÃ©processeur : encodage + standardisation\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    ('bool', bool_encoder, bool_cols),\n",
    "    ('num', StandardScaler(), [col for col in X.columns if col not in bool_cols])\n",
    "])\n",
    "\n",
    "# âœ… 4. Pipeline complet avec RandomForest\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# âœ… 5. Split des donnÃ©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# âœ… 6. Recherche alÃ©atoire de paramÃ¨tres\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 500),\n",
    "    'model__max_depth': randint(5, 30),\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 10),\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
    "                                   n_iter=100, cv=5, scoring='neg_mean_squared_error',\n",
    "                                   n_jobs=-1, random_state=42, verbose=2)\n",
    "\n",
    "# âœ… 7. EntraÃ®nement\n",
    "random_search.fit(X_train, y_train)\n",
    "\n",
    "# âœ… 8. Ã‰valuation\n",
    "best_model = random_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"âœ… Best params from RandomizedSearchCV:\", random_search.best_params_)\n",
    "print(\"ðŸ“‰ Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
    "print(\"ðŸ“ˆ RÂ² Score:\", r2_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "13f60647",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ“‹ Liste des attributs utilisÃ©s dans le modÃ¨le :\n",
      " - subject_id\n",
      " - HADM_ID\n",
      " - AlcoholDrinkers\n",
      " - CovidPos\n",
      " - HadHeartAttack\n",
      " - HadAngina\n",
      " - HadStroke\n",
      " - HadAsthma\n",
      " - HadSkinCancer\n",
      " - HadCOPD\n",
      " - HadDepressiveDisorder\n",
      " - HadKidneyDisease\n",
      " - HadArthritis\n",
      " - DeafOrHardOfHearing\n",
      " - BlindOrVisionDifficulty\n",
      " - DifficultyConcentrating\n",
      " - DifficultyWalking\n",
      " - DifficultyDressingBathing\n",
      " - DifficultyErrands\n",
      " - ChestScan\n",
      " - HIVTesting\n",
      " - FluVaxLast12\n",
      " - PneumoVaxEver\n",
      " - AdmissionYear\n",
      " - AdmissionDayOfWeek\n",
      " - facility_cost\n",
      " - procedure_cost\n",
      " - medication_cost\n",
      " - lab_test_cost\n",
      " - total_cost\n",
      " - gender_M\n",
      " - dob_1846-07-21 00:00:00\n",
      " - dob_1851-09-12 00:00:00\n",
      " - dob_1876-07-14 00:00:00\n",
      " - dob_1878-05-14 00:00:00\n",
      " - dob_1880-02-29 00:00:00\n",
      " - dob_1885-03-24 00:00:00\n",
      " - dob_1895-05-17 00:00:00\n",
      " - dob_2016-12-05 00:00:00\n",
      " - dob_2029-07-09 00:00:00\n",
      " - dob_2029-12-07 00:00:00\n",
      " - dob_2031-05-19 00:00:00\n",
      " - dob_2031-08-12 00:00:00\n",
      " - dob_2035-04-13 00:00:00\n",
      " - dob_2036-03-10 00:00:00\n",
      " - dob_2038-05-10 00:00:00\n",
      " - dob_2038-09-03 00:00:00\n",
      " - dob_2041-05-16 00:00:00\n",
      " - dob_2044-06-27 00:00:00\n",
      " - dob_2045-10-07 00:00:00\n",
      " - dob_2046-02-27 00:00:00\n",
      " - dob_2046-04-18 00:00:00\n",
      " - dob_2046-07-05 00:00:00\n",
      " - dob_2050-02-16 00:00:00\n",
      " - dob_2050-03-29 00:00:00\n",
      " - dob_2051-03-23 00:00:00\n",
      " - dob_2051-03-24 00:00:00\n",
      " - dob_2051-04-21 00:00:00\n",
      " - dob_2051-07-25 00:00:00\n",
      " - dob_2053-04-13 00:00:00\n",
      " - dob_2053-09-08 00:00:00\n",
      " - dob_2055-07-18 00:00:00\n",
      " - dob_2056-01-27 00:00:00\n",
      " - dob_2057-11-15 00:00:00\n",
      " - dob_2058-04-23 00:00:00\n",
      " - dob_2058-08-04 00:00:00\n",
      " - dob_2060-02-12 00:00:00\n",
      " - dob_2061-03-25 00:00:00\n",
      " - dob_2061-04-10 00:00:00\n",
      " - dob_2061-06-13 00:00:00\n",
      " - dob_2061-10-23 00:00:00\n",
      " - dob_2061-12-10 00:00:00\n",
      " - dob_2063-07-05 00:00:00\n",
      " - dob_2068-03-04 00:00:00\n",
      " - dob_2069-05-05 00:00:00\n",
      " - dob_2070-10-11 00:00:00\n",
      " - dob_2071-02-11 00:00:00\n",
      " - dob_2072-05-05 00:00:00\n",
      " - dob_2072-12-03 00:00:00\n",
      " - dob_2073-06-05 00:00:00\n",
      " - dob_2073-08-13 00:00:00\n",
      " - dob_2073-11-22 00:00:00\n",
      " - dob_2074-09-29 00:00:00\n",
      " - dob_2075-09-21 00:00:00\n",
      " - dob_2076-05-06 00:00:00\n",
      " - dob_2078-06-16 00:00:00\n",
      " - dob_2079-01-29 00:00:00\n",
      " - dob_2079-08-17 00:00:00\n",
      " - dob_2081-01-03 00:00:00\n",
      " - dob_2081-12-26 00:00:00\n",
      " - dob_2082-06-27 00:00:00\n",
      " - dob_2083-09-20 00:00:00\n",
      " - dob_2086-02-04 00:00:00\n",
      " - dob_2086-12-16 00:00:00\n",
      " - dob_2088-05-05 00:00:00\n",
      " - dob_2090-06-05 00:00:00\n",
      " - dob_2090-11-16 00:00:00\n",
      " - dob_2094-03-05 00:00:00\n",
      " - dob_2096-02-27 00:00:00\n",
      " - dob_2096-07-25 00:00:00\n",
      " - dob_2097-01-07 00:00:00\n",
      " - dob_2097-01-16 00:00:00\n",
      " - dob_2097-05-16 00:00:00\n",
      " - dob_2097-11-14 00:00:00\n",
      " - dob_2097-12-16 00:00:00\n",
      " - dob_2098-04-29 00:00:00\n",
      " - dob_2099-03-17 00:00:00\n",
      " - dob_2099-09-02 00:00:00\n",
      " - dob_2101-06-10 00:00:00\n",
      " - dob_2103-12-05 00:00:00\n",
      " - dob_2104-02-12 00:00:00\n",
      " - dob_2107-06-27 00:00:00\n",
      " - dob_2108-01-15 00:00:00\n",
      " - dob_2108-12-20 00:00:00\n",
      " - dob_2109-04-07 00:00:00\n",
      " - dob_2109-07-08 00:00:00\n",
      " - dob_2110-03-25 00:00:00\n",
      " - dob_2110-04-02 00:00:00\n",
      " - dob_2111-07-18 00:00:00\n",
      " - dob_2112-01-20 00:00:00\n",
      " - dob_2112-10-22 00:00:00\n",
      " - dob_2114-06-20 00:00:00\n",
      " - dob_2127-06-04 00:00:00\n",
      " - dob_2136-07-28 00:00:00\n",
      " - dob_2136-07-29 00:00:00\n",
      " - dob_2141-03-15 00:00:00\n",
      " - dob_2146-10-23 00:00:00\n",
      " - dob_2150-12-07 00:00:00\n",
      " - dob_2181-04-19 00:00:00\n",
      " - HeightInMeters_1,5\n",
      " - HeightInMeters_1,51999998092651\n",
      " - HeightInMeters_1,54999995231628\n",
      " - HeightInMeters_1,57000005245209\n",
      " - HeightInMeters_1,60000002384186\n",
      " - HeightInMeters_1,62999999523163\n",
      " - HeightInMeters_1,64999997615814\n",
      " - HeightInMeters_1,67999994754791\n",
      " - HeightInMeters_1,70000004768372\n",
      " - HeightInMeters_1,73000001907349\n",
      " - HeightInMeters_1,75\n",
      " - HeightInMeters_1,77999997138977\n",
      " - HeightInMeters_1,79999995231628\n",
      " - HeightInMeters_1,83000004291534\n",
      " - HeightInMeters_1,85000002384186\n",
      " - HeightInMeters_1,87999999523163\n",
      " - HeightInMeters_1,9099999666214\n",
      " - HeightInMeters_1,92999994754791\n",
      " - HeightInMeters_1,98000001907349\n",
      " - WeightInKilograms_104,330001831055\n",
      " - WeightInKilograms_106,589996337891\n",
      " - WeightInKilograms_108,860000610352\n",
      " - WeightInKilograms_113,400001525879\n",
      " - WeightInKilograms_115,669998168945\n",
      " - WeightInKilograms_120,199996948242\n",
      " - WeightInKilograms_122,470001220703\n",
      " - WeightInKilograms_129,270004272461\n",
      " - WeightInKilograms_129,729995727539\n",
      " - WeightInKilograms_204,119995117188\n",
      " - WeightInKilograms_49,9000015258789\n",
      " - WeightInKilograms_52,1599998474121\n",
      " - WeightInKilograms_54,4300003051758\n",
      " - WeightInKilograms_54,8800010681152\n",
      " - WeightInKilograms_57,6100006103516\n",
      " - WeightInKilograms_58,060001373291\n",
      " - WeightInKilograms_58,9700012207031\n",
      " - WeightInKilograms_59,8699989318848\n",
      " - WeightInKilograms_61,2299995422363\n",
      " - WeightInKilograms_62,5999984741211\n",
      " - WeightInKilograms_63,5\n",
      " - WeightInKilograms_64,4100036621094\n",
      " - WeightInKilograms_65,7699966430664\n",
      " - WeightInKilograms_66,2200012207031\n",
      " - WeightInKilograms_67,129997253418\n",
      " - WeightInKilograms_68,0400009155273\n",
      " - WeightInKilograms_69,4000015258789\n",
      " - WeightInKilograms_69,8499984741211\n",
      " - WeightInKilograms_71,2099990844727\n",
      " - WeightInKilograms_71,6699981689453\n",
      " - WeightInKilograms_72,5699996948242\n",
      " - WeightInKilograms_73,4800033569336\n",
      " - WeightInKilograms_74,8399963378906\n",
      " - WeightInKilograms_76,1999969482422\n",
      " - WeightInKilograms_76,6600036621094\n",
      " - WeightInKilograms_78,0199966430664\n",
      " - WeightInKilograms_78,4700012207031\n",
      " - WeightInKilograms_79,379997253418\n",
      " - WeightInKilograms_79,8300018310547\n",
      " - WeightInKilograms_81,6500015258789\n",
      " - WeightInKilograms_83,4599990844727\n",
      " - WeightInKilograms_83,9100036621094\n",
      " - WeightInKilograms_84,8199996948242\n",
      " - WeightInKilograms_86,1800003051758\n",
      " - WeightInKilograms_87,5400009155273\n",
      " - WeightInKilograms_88\n",
      " - WeightInKilograms_88,4499969482422\n",
      " - WeightInKilograms_90,7200012207031\n",
      " - WeightInKilograms_91,1699981689453\n",
      " - WeightInKilograms_92,0800018310547\n",
      " - WeightInKilograms_94,8000030517578\n",
      " - WeightInKilograms_95,25\n",
      " - WeightInKilograms_97,0699996948242\n",
      " - WeightInKilograms_97,5199966430664\n",
      " - WeightInKilograms_99,7900009155273\n",
      " - BMI_19,7900009155273\n",
      " - BMI_19,9699993133545\n",
      " - BMI_20,1399993896484\n",
      " - BMI_20,8099994659424\n",
      " - BMI_20,9200000762939\n",
      " - BMI_20,9799995422363\n",
      " - BMI_21,0300006866455\n",
      " - BMI_21,0599994659424\n",
      " - BMI_21,1299991607666\n",
      " - BMI_21,7700004577637\n",
      " - BMI_22,5300006866455\n",
      " - BMI_22,6000003814697\n",
      " - BMI_22,6700000762939\n",
      " - BMI_23,0100002288818\n",
      " - BMI_23,4400005340576\n",
      " - BMI_23,6299991607666\n",
      " - BMI_23,6900005340576\n",
      " - BMI_24,3299999237061\n",
      " - BMI_24,3700008392334\n",
      " - BMI_24,4500007629395\n",
      " - BMI_24,5499992370605\n",
      " - BMI_24,6900005340576\n",
      " - BMI_24,9400005340576\n",
      " - BMI_25,0599994659424\n",
      " - BMI_25,0900001525879\n",
      " - BMI_25,1100006103516\n",
      " - BMI_25,1499996185303\n",
      " - BMI_25,3700008392334\n",
      " - BMI_25,5400009155273\n",
      " - BMI_25,8400001525879\n",
      " - BMI_26,4300003051758\n",
      " - BMI_26,7000007629395\n",
      " - BMI_26,9400005340576\n",
      " - BMI_27,0699996948242\n",
      " - BMI_27,1200008392334\n",
      " - BMI_27,2000007629395\n",
      " - BMI_27,2600002288818\n",
      " - BMI_27,3400001525879\n",
      " - BMI_27,3899993896484\n",
      " - BMI_27,7600002288818\n",
      " - BMI_27,8099994659424\n",
      " - BMI_27,8899993896484\n",
      " - BMI_27,9899997711182\n",
      " - BMI_28,2800006866455\n",
      " - BMI_28,8400001525879\n",
      " - BMI_28,8899993896484\n",
      " - BMI_29,0499992370605\n",
      " - BMI_29,1499996185303\n",
      " - BMI_29,8400001525879\n",
      " - BMI_29,8600006103516\n",
      " - BMI_29,8799991607666\n",
      " - BMI_30,1299991607666\n",
      " - BMI_30,1800003051758\n",
      " - BMI_30,2299995422363\n",
      " - BMI_30,3400001525879\n",
      " - BMI_30,4099998474121\n",
      " - BMI_30,5599994659424\n",
      " - BMI_30,6800003051758\n",
      " - BMI_31,0100002288818\n",
      " - BMI_31,3199996948242\n",
      " - BMI_31,3799991607666\n",
      " - BMI_31,6599998474121\n",
      " - BMI_31,75\n",
      " - BMI_31,8700008392334\n",
      " - BMI_31,8899993896484\n",
      " - BMI_31,9300003051758\n",
      " - BMI_32,0800018310547\n",
      " - BMI_32,0999984741211\n",
      " - BMI_32,4900016784668\n",
      " - BMI_32,7400016784668\n",
      " - BMI_32,9199981689453\n",
      " - BMI_32,9300003051758\n",
      " - BMI_33,0699996948242\n",
      " - BMI_33,2999992370605\n",
      " - BMI_33,439998626709\n",
      " - BMI_33,8899993896484\n",
      " - BMI_34,7700004577637\n",
      " - BMI_34,9599990844727\n",
      " - BMI_35,1500015258789\n",
      " - BMI_35,7799987792969\n",
      " - BMI_35,8699989318848\n",
      " - BMI_36,6199989318848\n",
      " - BMI_36,7299995422363\n",
      " - BMI_37,7299995422363\n",
      " - BMI_41,1599998474121\n",
      " - BMI_44,2900009155273\n",
      " - BMI_44,9199981689453\n",
      " - BMI_46,8699989318848\n",
      " - BMI_52,1300010681152\n",
      " - BMI_61,0299987792969\n",
      " - SmokerStatus_Current smoker - now smokes some days\n",
      " - SmokerStatus_Former smoker\n",
      " - SmokerStatus_Never smoked\n",
      " - ECigaretteUsage_Not at all (right now)\n",
      " - ECigaretteUsage_Use them every day\n",
      " - ECigaretteUsage_Use them some days\n",
      " - LANGUAGE_MAND\n",
      " - LANGUAGE_POLI\n",
      " - LANGUAGE_RUSS\n",
      " - LANGUAGE_SPAN\n",
      " - ETHNICITY_ASIAN\n",
      " - ETHNICITY_BLACK/AFRICAN AMERICAN\n",
      " - ETHNICITY_HISPANIC OR LATINO\n",
      " - ETHNICITY_HISPANIC/LATINO - PUERTO RICAN\n",
      " - ETHNICITY_OTHER\n",
      " - ETHNICITY_UNABLE TO OBTAIN\n",
      " - ETHNICITY_UNKNOWN/NOT SPECIFIED\n",
      " - ETHNICITY_WHITE\n",
      " - MARITAL_STATUS_MARRIED\n",
      " - MARITAL_STATUS_SEPARATED\n",
      " - MARITAL_STATUS_SINGLE\n",
      " - MARITAL_STATUS_UNKNOWN (DEFAULT)\n",
      " - MARITAL_STATUS_WIDOWED\n",
      " - HadDiabetes_No, pre-diabetes or borderline diabetes\n",
      " - HadDiabetes_Yes\n",
      " - HadDiabetes_Yes, but only during pregnancy (female)\n",
      " - TetanusLast10Tdap_Yes, received Tdap\n",
      " - TetanusLast10Tdap_Yes, received tetanus shot but not sure what type\n",
      " - TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap\n",
      " - AdmissionDate_2104-09-24\n",
      " - AdmissionDate_2104-10-24\n",
      " - AdmissionDate_2105-05-29\n",
      " - AdmissionDate_2106-08-30\n",
      " - AdmissionDate_2107-01-04\n",
      " - AdmissionDate_2107-01-16\n",
      " - AdmissionDate_2107-01-29\n",
      " - AdmissionDate_2107-03-21\n",
      " - AdmissionDate_2107-05-12\n",
      " - AdmissionDate_2110-12-29\n",
      " - AdmissionDate_2112-02-04\n",
      " - AdmissionDate_2112-05-04\n",
      " - AdmissionDate_2112-05-22\n",
      " - AdmissionDate_2112-05-28\n",
      " - AdmissionDate_2115-05-12\n",
      " - AdmissionDate_2117-03-21\n",
      " - AdmissionDate_2117-08-05\n",
      " - AdmissionDate_2117-08-21\n",
      " - AdmissionDate_2118-10-06\n",
      " - AdmissionDate_2119-10-17\n",
      " - AdmissionDate_2120-08-24\n",
      " - AdmissionDate_2121-12-07\n",
      " - AdmissionDate_2123-08-23\n",
      " - AdmissionDate_2123-11-24\n",
      " - AdmissionDate_2124-01-12\n",
      " - AdmissionDate_2125-10-04\n",
      " - AdmissionDate_2126-08-14\n",
      " - AdmissionDate_2127-03-19\n",
      " - AdmissionDate_2127-07-23\n",
      " - AdmissionDate_2127-10-06\n",
      " - AdmissionDate_2128-03-22\n",
      " - AdmissionDate_2128-11-04\n",
      " - AdmissionDate_2129-03-03\n",
      " - AdmissionDate_2129-05-01\n",
      " - AdmissionDate_2129-11-23\n",
      " - AdmissionDate_2130-02-04\n",
      " - AdmissionDate_2130-08-12\n",
      " - AdmissionDate_2130-10-06\n",
      " - AdmissionDate_2131-07-26\n",
      " - AdmissionDate_2132-08-05\n",
      " - AdmissionDate_2132-12-05\n",
      " - AdmissionDate_2135-10-24\n",
      " - AdmissionDate_2138-04-02\n",
      " - AdmissionDate_2138-06-05\n",
      " - AdmissionDate_2138-11-09\n",
      " - AdmissionDate_2139-09-22\n",
      " - AdmissionDate_2141-01-25\n",
      " - AdmissionDate_2142-11-26\n",
      " - AdmissionDate_2144-02-09\n",
      " - AdmissionDate_2144-07-11\n",
      " - AdmissionDate_2144-07-18\n",
      " - AdmissionDate_2144-10-15\n",
      " - AdmissionDate_2144-12-24\n",
      " - AdmissionDate_2145-07-07\n",
      " - AdmissionDate_2145-09-06\n",
      " - AdmissionDate_2145-12-01\n",
      " - AdmissionDate_2146-07-21\n",
      " - AdmissionDate_2147-02-06\n",
      " - AdmissionDate_2147-02-23\n",
      " - AdmissionDate_2147-10-03\n",
      " - AdmissionDate_2148-01-13\n",
      " - AdmissionDate_2149-05-26\n",
      " - AdmissionDate_2150-08-07\n",
      " - AdmissionDate_2150-08-22\n",
      " - AdmissionDate_2151-08-13\n",
      " - AdmissionDate_2151-09-12\n",
      " - AdmissionDate_2152-10-02\n",
      " - AdmissionDate_2152-10-09\n",
      " - AdmissionDate_2155-03-08\n",
      " - AdmissionDate_2155-12-16\n",
      " - AdmissionDate_2159-11-17\n",
      " - AdmissionDate_2160-05-04\n",
      " - AdmissionDate_2160-12-16\n",
      " - AdmissionDate_2160-12-26\n",
      " - AdmissionDate_2161-01-30\n",
      " - AdmissionDate_2161-09-14\n",
      " - AdmissionDate_2162-01-16\n",
      " - AdmissionDate_2163-05-14\n",
      " - AdmissionDate_2163-11-21\n",
      " - AdmissionDate_2164-10-23\n",
      " - AdmissionDate_2165-12-19\n",
      " - AdmissionDate_2166-02-12\n",
      " - AdmissionDate_2167-02-11\n",
      " - AdmissionDate_2169-05-06\n",
      " - AdmissionDate_2170-12-02\n",
      " - AdmissionDate_2170-12-15\n",
      " - AdmissionDate_2171-07-12\n",
      " - AdmissionDate_2171-10-30\n",
      " - AdmissionDate_2173-11-27\n",
      " - AdmissionDate_2175-10-02\n",
      " - AdmissionDate_2176-07-14\n",
      " - AdmissionDate_2178-05-14\n",
      " - AdmissionDate_2179-04-17\n",
      " - AdmissionDate_2180-01-14\n",
      " - AdmissionDate_2180-02-29\n",
      " - AdmissionDate_2180-03-15\n",
      " - AdmissionDate_2180-07-19\n",
      " - AdmissionDate_2184-08-04\n",
      " - AdmissionDate_2185-03-24\n",
      " - AdmissionDate_2185-04-13\n",
      " - AdmissionDate_2186-02-09\n",
      " - AdmissionDate_2186-07-06\n",
      " - AdmissionDate_2188-02-08\n",
      " - AdmissionDate_2189-09-08\n",
      " - AdmissionDate_2190-07-13\n",
      " - AdmissionDate_2192-03-26\n",
      " - AdmissionDate_2192-04-16\n",
      " - AdmissionDate_2192-11-20\n",
      " - AdmissionDate_2193-10-15\n",
      " - AdmissionDate_2194-07-26\n",
      " - AdmissionDate_2195-05-17\n",
      " - AdmissionDate_2198-06-28\n",
      " - AdmissionDate_2198-06-29\n",
      " - AdmissionDate_2198-10-29\n",
      " - AdmissionDate_2199-01-13\n",
      " - AdmissionDate_2199-01-31\n",
      " - AdmissionDate_2200-03-17\n",
      " - AdmissionDate_2200-06-09\n",
      " - AdmissionDate_2200-10-29\n",
      " - AdmissionDate_2201-05-12\n",
      " - AdmissionDate_2201-08-10\n",
      " - AdmissionDate_2201-09-28\n",
      " - AdmissionDate_2201-11-16\n",
      " - AdmissionDate_2201-12-31\n",
      " - AdmissionDate_2202-02-15\n",
      " - AdmissionDate_2202-05-01\n",
      " - AdmissionDate_2202-09-16\n",
      " - AdmissionDate_2202-10-03\n",
      " - DIAGNOSIS_ABDOMINAL PAIN\n",
      " - DIAGNOSIS_ABSCESS\n",
      " - DIAGNOSIS_ACUTE CHOLANGITIS\n",
      " - DIAGNOSIS_ACUTE CHOLECYSTITIS\n",
      " - DIAGNOSIS_ACUTE PULMONARY EMBOLISM\n",
      " - DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE\n",
      " - DIAGNOSIS_ACUTE SUBDURAL HEMATOMA\n",
      " - DIAGNOSIS_ALCOHOLIC HEPATITIS\n",
      " - DIAGNOSIS_ALTERED MENTAL STATUS\n",
      " - DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA\n",
      " - DIAGNOSIS_ASTHMA/COPD FLARE\n",
      " - DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE\n",
      " - DIAGNOSIS_BASAL GANGLIN BLEED\n",
      " - DIAGNOSIS_BRADYCARDIA\n",
      " - DIAGNOSIS_BRAIN METASTASES\n",
      " - DIAGNOSIS_CELLULITIS\n",
      " - DIAGNOSIS_CEREBROVASCULAR ACCIDENT\n",
      " - DIAGNOSIS_CHEST PAIN\n",
      " - DIAGNOSIS_CHEST PAIN/ CATH\n",
      " - DIAGNOSIS_CHOLANGITIS\n",
      " - DIAGNOSIS_CHOLECYSTITIS\n",
      " - DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION\n",
      " - DIAGNOSIS_CONGESTIVE HEART FAILURE\n",
      " - DIAGNOSIS_CORONARY ARTERY DISEASE\\CORONARY ARTERY BYPASS GRAFT /SDA\n",
      " - DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION\n",
      " - DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT\n",
      " - DIAGNOSIS_ESOPHAGEAL CA/SDA\n",
      " - DIAGNOSIS_ESOPHAGEAL CANCER/SDA\n",
      " - DIAGNOSIS_FACIAL NUMBNESS\n",
      " - DIAGNOSIS_FAILURE TO THRIVE\n",
      " - DIAGNOSIS_FEVER\n",
      " - DIAGNOSIS_FEVER;URINARY TRACT INFECTION\n",
      " - DIAGNOSIS_GASTROINTESTINAL BLEED\n",
      " - DIAGNOSIS_HEADACHE\n",
      " - DIAGNOSIS_HEPATIC ENCEP\n",
      " - DIAGNOSIS_HEPATITIS B\n",
      " - DIAGNOSIS_HUMERAL FRACTURE\n",
      " - DIAGNOSIS_HYPOGLYCEMIA\n",
      " - DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION\n",
      " - DIAGNOSIS_HYPOTENSION\n",
      " - DIAGNOSIS_HYPOTENSION, RENAL FAILURE\n",
      " - DIAGNOSIS_HYPOTENSION;TELEMETRY\n",
      " - DIAGNOSIS_HYPOTENSION;UNRESPONSIVE\n",
      " - DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\CATH\n",
      " - DIAGNOSIS_LEFT HIP FRACTURE\n",
      " - DIAGNOSIS_LEFT HIP OA/SDA\n",
      " - DIAGNOSIS_LIVER FAILURE\n",
      " - DIAGNOSIS_LOWER GI BLEED\n",
      " - DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH\n",
      " - DIAGNOSIS_MEDIASTINAL ADENOPATHY\n",
      " - DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS\n",
      " - DIAGNOSIS_METASTIC MELANOMA;ANEMIA\n",
      " - DIAGNOSIS_MI CHF\n",
      " - DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA\n",
      " - DIAGNOSIS_OVERDOSE\n",
      " - DIAGNOSIS_PERICARDIAL EFFUSION\n",
      " - DIAGNOSIS_PLEURAL EFFUSION\n",
      " - DIAGNOSIS_PNEUMONIA\n",
      " - DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE\n",
      " - DIAGNOSIS_PNEUMONIA;TELEMETRY\n",
      " - DIAGNOSIS_PULMONARY EDEMA, MI\n",
      " - DIAGNOSIS_PULMONARY EDEMA\\CATH\n",
      " - DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION\n",
      " - DIAGNOSIS_RENAL CANCER/SDA\n",
      " - DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA\n",
      " - DIAGNOSIS_RESPIRATORY DISTRESS\n",
      " - DIAGNOSIS_RIGHT HUMEROUS FRACTURE\n",
      " - DIAGNOSIS_S/P FALL\n",
      " - DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT\n",
      " - DIAGNOSIS_S/P MOTORCYCLE ACCIDENT\n",
      " - DIAGNOSIS_SEIZURE\n",
      " - DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS\n",
      " - DIAGNOSIS_SEPSIS\n",
      " - DIAGNOSIS_SEPSIS; UTI\n",
      " - DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY\n",
      " - DIAGNOSIS_SEPSIS;TELEMETRY\n",
      " - DIAGNOSIS_SHORTNESS OF BREATH\n",
      " - DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES\n",
      " - DIAGNOSIS_STEMI;\n",
      " - DIAGNOSIS_STROKE/TIA\n",
      " - DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL\n",
      " - DIAGNOSIS_SYNCOPE;TELEMETRY\n",
      " - DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE\n",
      " - DIAGNOSIS_TACHYPNEA;TELEMETRY\n",
      " - DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA\n",
      " - DIAGNOSIS_TRACHEAL STENOSIS\n",
      " - DIAGNOSIS_UNSTABLE ANGINA\n",
      " - DIAGNOSIS_UPPER GI BLEED\n",
      " - DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS\n",
      " - DIAGNOSIS_UROSEPSIS\n",
      " - DIAGNOSIS_UTI/PYELONEPHRITIS\n",
      " - DIAGNOSIS_VARICEAL BLEED\n",
      " - DIAGNOSIS_VF ARREST \n",
      " - DIAGNOSIS_VOLVULUS\n",
      " - ADMISSION_LOCATION_EMERGENCY ROOM ADMIT\n",
      " - ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI\n",
      " - ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM\n",
      " - ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR\n",
      " - ADMISSION_TYPE_EMERGENCY\n",
      " - ADMISSION_TYPE_URGENT\n"
     ]
    }
   ],
   "source": [
    "# âœ… 9. Affichage des attributs utilisÃ©s\n",
    "print(\"\\nðŸ“‹ Liste des attributs utilisÃ©s dans le modÃ¨le :\")\n",
    "for feature in X.columns:\n",
    "    print(f\" - {feature}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47ada14f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# âœ… 9. Sauvegarde du modÃ¨le\n",
    "joblib.dump(best_model, 'best_rf_pipeline.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f9f2814e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.pkl']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# âœ… 10. Exporter le modÃ¨le et le scaler\n",
    "joblib.dump(best_model, 'best_rf_model.pkl')\n",
    "joblib.dump(scaler, 'scaler.pkl')  # Sauvegarde du scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "49a1f993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colonnes de X_train: Index(['subject_id', 'HADM_ID', 'AlcoholDrinkers', 'CovidPos',\n",
      "       'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma',\n",
      "       'HadSkinCancer', 'HadCOPD',\n",
      "       ...\n",
      "       'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED',\n",
      "       'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS',\n",
      "       'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT',\n",
      "       'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR',\n",
      "       'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT'],\n",
      "      dtype='object', length=550)\n",
      "Colonnes de X_test: Index(['subject_id', 'HADM_ID', 'AlcoholDrinkers', 'CovidPos',\n",
      "       'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma',\n",
      "       'HadSkinCancer', 'HadCOPD',\n",
      "       ...\n",
      "       'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED',\n",
      "       'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS',\n",
      "       'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT',\n",
      "       'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM',\n",
      "       'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR',\n",
      "       'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT'],\n",
      "      dtype='object', length=550)\n"
     ]
    }
   ],
   "source": [
    "print(\"Colonnes de X_train:\", X_train.columns)\n",
    "print(\"Colonnes de X_test:\", X_test.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1302a2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "835e94ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Œ Observation 1\n",
      "ðŸ”® PrÃ©diction : 6.01\n",
      "âœ… Intervalle de confiance Ã  95% : [5.37, 6.65]\n",
      "ðŸŽ¯ Valeur rÃ©elle : 6\n",
      "\n",
      "ðŸ“Œ Observation 2\n",
      "ðŸ”® PrÃ©diction : 16.63\n",
      "âœ… Intervalle de confiance Ã  95% : [9.90, 23.36]\n",
      "ðŸŽ¯ Valeur rÃ©elle : 17\n",
      "\n",
      "ðŸ“Œ Observation 3\n",
      "ðŸ”® PrÃ©diction : 9.73\n",
      "âœ… Intervalle de confiance Ã  95% : [7.93, 11.53]\n",
      "ðŸŽ¯ Valeur rÃ©elle : 10\n",
      "\n",
      "ðŸ“Œ Observation 4\n",
      "ðŸ”® PrÃ©diction : 7.92\n",
      "âœ… Intervalle de confiance Ã  95% : [6.93, 8.92]\n",
      "ðŸŽ¯ Valeur rÃ©elle : 8\n",
      "\n",
      "ðŸ“Œ Observation 5\n",
      "ðŸ”® PrÃ©diction : 0.27\n",
      "âœ… Intervalle de confiance Ã  95% : [-0.89, 1.43]\n",
      "ðŸŽ¯ Valeur rÃ©elle : 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… 12. PrÃ©dictions avec estimation de l'incertitude (intervalle de confiance)\n",
    "import numpy as np\n",
    "\n",
    "# Obtenir les prÃ©dictions de chaque arbre\n",
    "all_tree_predictions = np.stack([tree.predict(X_test_scaled) for tree in loaded_model.estimators_], axis=0)\n",
    "\n",
    "# Moyenne des prÃ©dictions (prÃ©diction finale)\n",
    "mean_predictions = np.mean(all_tree_predictions, axis=0)\n",
    "\n",
    "# Ã‰cart-type (incertitude)\n",
    "std_predictions = np.std(all_tree_predictions, axis=0)\n",
    "\n",
    "# Calcul de l'intervalle de confiance Ã  95%\n",
    "lower_bound = mean_predictions - 1.96 * std_predictions\n",
    "upper_bound = mean_predictions + 1.96 * std_predictions\n",
    "\n",
    "# Affichage pour les 5 premiÃ¨res instances\n",
    "for i in range(5):\n",
    "    print(f\"ðŸ“Œ Observation {i+1}\")\n",
    "    print(f\"ðŸ”® PrÃ©diction : {mean_predictions[i]:.2f}\")\n",
    "    print(f\"âœ… Intervalle de confiance Ã  95% : [{lower_bound[i]:.2f}, {upper_bound[i]:.2f}]\")\n",
    "    print(f\"ðŸŽ¯ Valeur rÃ©elle : {y_test.iloc[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35ed32ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilisation des donnÃ©es prÃ©-chargÃ©es.\n",
      "Colonne 'AlcoholDrinkers' convertie en boolÃ©en.\n",
      "Colonne 'CovidPos' convertie en boolÃ©en.\n",
      "Colonne 'HadHeartAttack' convertie en boolÃ©en.\n",
      "Colonne 'HadAngina' convertie en boolÃ©en.\n",
      "Colonne 'HadStroke' convertie en boolÃ©en.\n",
      "Colonne 'HadAsthma' convertie en boolÃ©en.\n",
      "Colonne 'HadSkinCancer' convertie en boolÃ©en.\n",
      "Colonne 'HadCOPD' convertie en boolÃ©en.\n",
      "Colonnes boolÃ©ennes utilisÃ©es : ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
      "Colonnes numÃ©riques utilisÃ©es : ['HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'AdmissionYear', 'AdmissionDayOfWeek', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost', 'gender_M', 'dob_1846-07-21 00:00:00', 'dob_1851-09-12 00:00:00', 'dob_1876-07-14 00:00:00', 'dob_1878-05-14 00:00:00', 'dob_1880-02-29 00:00:00', 'dob_1885-03-24 00:00:00', 'dob_1895-05-17 00:00:00', 'dob_2016-12-05 00:00:00', 'dob_2029-07-09 00:00:00', 'dob_2029-12-07 00:00:00', 'dob_2031-05-19 00:00:00', 'dob_2031-08-12 00:00:00', 'dob_2035-04-13 00:00:00', 'dob_2036-03-10 00:00:00', 'dob_2038-05-10 00:00:00', 'dob_2038-09-03 00:00:00', 'dob_2041-05-16 00:00:00', 'dob_2044-06-27 00:00:00', 'dob_2045-10-07 00:00:00', 'dob_2046-02-27 00:00:00', 'dob_2046-04-18 00:00:00', 'dob_2046-07-05 00:00:00', 'dob_2050-02-16 00:00:00', 'dob_2050-03-29 00:00:00', 'dob_2051-03-23 00:00:00', 'dob_2051-03-24 00:00:00', 'dob_2051-04-21 00:00:00', 'dob_2051-07-25 00:00:00', 'dob_2053-04-13 00:00:00', 'dob_2053-09-08 00:00:00', 'dob_2055-07-18 00:00:00', 'dob_2056-01-27 00:00:00', 'dob_2057-11-15 00:00:00', 'dob_2058-04-23 00:00:00', 'dob_2058-08-04 00:00:00', 'dob_2060-02-12 00:00:00', 'dob_2061-03-25 00:00:00', 'dob_2061-04-10 00:00:00', 'dob_2061-06-13 00:00:00', 'dob_2061-10-23 00:00:00', 'dob_2061-12-10 00:00:00', 'dob_2063-07-05 00:00:00', 'dob_2068-03-04 00:00:00', 'dob_2069-05-05 00:00:00', 'dob_2070-10-11 00:00:00', 'dob_2071-02-11 00:00:00', 'dob_2072-05-05 00:00:00', 'dob_2072-12-03 00:00:00', 'dob_2073-06-05 00:00:00', 'dob_2073-08-13 00:00:00', 'dob_2073-11-22 00:00:00', 'dob_2074-09-29 00:00:00', 'dob_2075-09-21 00:00:00', 'dob_2076-05-06 00:00:00', 'dob_2078-06-16 00:00:00', 'dob_2079-01-29 00:00:00', 'dob_2079-08-17 00:00:00', 'dob_2081-01-03 00:00:00', 'dob_2081-12-26 00:00:00', 'dob_2082-06-27 00:00:00', 'dob_2083-09-20 00:00:00', 'dob_2086-02-04 00:00:00', 'dob_2086-12-16 00:00:00', 'dob_2088-05-05 00:00:00', 'dob_2090-06-05 00:00:00', 'dob_2090-11-16 00:00:00', 'dob_2094-03-05 00:00:00', 'dob_2096-02-27 00:00:00', 'dob_2096-07-25 00:00:00', 'dob_2097-01-07 00:00:00', 'dob_2097-01-16 00:00:00', 'dob_2097-05-16 00:00:00', 'dob_2097-11-14 00:00:00', 'dob_2097-12-16 00:00:00', 'dob_2098-04-29 00:00:00', 'dob_2099-03-17 00:00:00', 'dob_2099-09-02 00:00:00', 'dob_2101-06-10 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2104-02-12 00:00:00', 'dob_2107-06-27 00:00:00', 'dob_2108-01-15 00:00:00', 'dob_2108-12-20 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_2109-07-08 00:00:00', 'dob_2110-03-25 00:00:00', 'dob_2110-04-02 00:00:00', 'dob_2111-07-18 00:00:00', 'dob_2112-01-20 00:00:00', 'dob_2112-10-22 00:00:00', 'dob_2114-06-20 00:00:00', 'dob_2127-06-04 00:00:00', 'dob_2136-07-28 00:00:00', 'dob_2136-07-29 00:00:00', 'dob_2141-03-15 00:00:00', 'dob_2146-10-23 00:00:00', 'dob_2150-12-07 00:00:00', 'dob_2181-04-19 00:00:00', 'HeightInMeters_1,5', 'HeightInMeters_1,51999998092651', 'HeightInMeters_1,54999995231628', 'HeightInMeters_1,57000005245209', 'HeightInMeters_1,60000002384186', 'HeightInMeters_1,62999999523163', 'HeightInMeters_1,64999997615814', 'HeightInMeters_1,67999994754791', 'HeightInMeters_1,70000004768372', 'HeightInMeters_1,73000001907349', 'HeightInMeters_1,75', 'HeightInMeters_1,77999997138977', 'HeightInMeters_1,79999995231628', 'HeightInMeters_1,83000004291534', 'HeightInMeters_1,85000002384186', 'HeightInMeters_1,87999999523163', 'HeightInMeters_1,9099999666214', 'HeightInMeters_1,92999994754791', 'HeightInMeters_1,98000001907349', 'WeightInKilograms_104,330001831055', 'WeightInKilograms_106,589996337891', 'WeightInKilograms_108,860000610352', 'WeightInKilograms_113,400001525879', 'WeightInKilograms_115,669998168945', 'WeightInKilograms_120,199996948242', 'WeightInKilograms_122,470001220703', 'WeightInKilograms_129,270004272461', 'WeightInKilograms_129,729995727539', 'WeightInKilograms_204,119995117188', 'WeightInKilograms_49,9000015258789', 'WeightInKilograms_52,1599998474121', 'WeightInKilograms_54,4300003051758', 'WeightInKilograms_54,8800010681152', 'WeightInKilograms_57,6100006103516', 'WeightInKilograms_58,060001373291', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_59,8699989318848', 'WeightInKilograms_61,2299995422363', 'WeightInKilograms_62,5999984741211', 'WeightInKilograms_63,5', 'WeightInKilograms_64,4100036621094', 'WeightInKilograms_65,7699966430664', 'WeightInKilograms_66,2200012207031', 'WeightInKilograms_67,129997253418', 'WeightInKilograms_68,0400009155273', 'WeightInKilograms_69,4000015258789', 'WeightInKilograms_69,8499984741211', 'WeightInKilograms_71,2099990844727', 'WeightInKilograms_71,6699981689453', 'WeightInKilograms_72,5699996948242', 'WeightInKilograms_73,4800033569336', 'WeightInKilograms_74,8399963378906', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_76,6600036621094', 'WeightInKilograms_78,0199966430664', 'WeightInKilograms_78,4700012207031', 'WeightInKilograms_79,379997253418', 'WeightInKilograms_79,8300018310547', 'WeightInKilograms_81,6500015258789', 'WeightInKilograms_83,4599990844727', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_84,8199996948242', 'WeightInKilograms_86,1800003051758', 'WeightInKilograms_87,5400009155273', 'WeightInKilograms_88', 'WeightInKilograms_88,4499969482422', 'WeightInKilograms_90,7200012207031', 'WeightInKilograms_91,1699981689453', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_94,8000030517578', 'WeightInKilograms_95,25', 'WeightInKilograms_97,0699996948242', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_99,7900009155273', 'BMI_19,7900009155273', 'BMI_19,9699993133545', 'BMI_20,1399993896484', 'BMI_20,8099994659424', 'BMI_20,9200000762939', 'BMI_20,9799995422363', 'BMI_21,0300006866455', 'BMI_21,0599994659424', 'BMI_21,1299991607666', 'BMI_21,7700004577637', 'BMI_22,5300006866455', 'BMI_22,6000003814697', 'BMI_22,6700000762939', 'BMI_23,0100002288818', 'BMI_23,4400005340576', 'BMI_23,6299991607666', 'BMI_23,6900005340576', 'BMI_24,3299999237061', 'BMI_24,3700008392334', 'BMI_24,4500007629395', 'BMI_24,5499992370605', 'BMI_24,6900005340576', 'BMI_24,9400005340576', 'BMI_25,0599994659424', 'BMI_25,0900001525879', 'BMI_25,1100006103516', 'BMI_25,1499996185303', 'BMI_25,3700008392334', 'BMI_25,5400009155273', 'BMI_25,8400001525879', 'BMI_26,4300003051758', 'BMI_26,7000007629395', 'BMI_26,9400005340576', 'BMI_27,0699996948242', 'BMI_27,1200008392334', 'BMI_27,2000007629395', 'BMI_27,2600002288818', 'BMI_27,3400001525879', 'BMI_27,3899993896484', 'BMI_27,7600002288818', 'BMI_27,8099994659424', 'BMI_27,8899993896484', 'BMI_27,9899997711182', 'BMI_28,2800006866455', 'BMI_28,8400001525879', 'BMI_28,8899993896484', 'BMI_29,0499992370605', 'BMI_29,1499996185303', 'BMI_29,8400001525879', 'BMI_29,8600006103516', 'BMI_29,8799991607666', 'BMI_30,1299991607666', 'BMI_30,1800003051758', 'BMI_30,2299995422363', 'BMI_30,3400001525879', 'BMI_30,4099998474121', 'BMI_30,5599994659424', 'BMI_30,6800003051758', 'BMI_31,0100002288818', 'BMI_31,3199996948242', 'BMI_31,3799991607666', 'BMI_31,6599998474121', 'BMI_31,75', 'BMI_31,8700008392334', 'BMI_31,8899993896484', 'BMI_31,9300003051758', 'BMI_32,0800018310547', 'BMI_32,0999984741211', 'BMI_32,4900016784668', 'BMI_32,7400016784668', 'BMI_32,9199981689453', 'BMI_32,9300003051758', 'BMI_33,0699996948242', 'BMI_33,2999992370605', 'BMI_33,439998626709', 'BMI_33,8899993896484', 'BMI_34,7700004577637', 'BMI_34,9599990844727', 'BMI_35,1500015258789', 'BMI_35,7799987792969', 'BMI_35,8699989318848', 'BMI_36,6199989318848', 'BMI_36,7299995422363', 'BMI_37,7299995422363', 'BMI_41,1599998474121', 'BMI_44,2900009155273', 'BMI_44,9199981689453', 'BMI_46,8699989318848', 'BMI_52,1300010681152', 'BMI_61,0299987792969', 'SmokerStatus_Current smoker - now smokes some days', 'SmokerStatus_Former smoker', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Not at all (right now)', 'ECigaretteUsage_Use them every day', 'ECigaretteUsage_Use them some days', 'LANGUAGE_MAND', 'LANGUAGE_POLI', 'LANGUAGE_RUSS', 'LANGUAGE_SPAN', 'ETHNICITY_ASIAN', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'ETHNICITY_HISPANIC OR LATINO', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'ETHNICITY_OTHER', 'ETHNICITY_UNABLE TO OBTAIN', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'ETHNICITY_WHITE', 'MARITAL_STATUS_MARRIED', 'MARITAL_STATUS_SEPARATED', 'MARITAL_STATUS_SINGLE', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'MARITAL_STATUS_WIDOWED', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'HadDiabetes_Yes', 'HadDiabetes_Yes, but only during pregnancy (female)', 'TetanusLast10Tdap_Yes, received Tdap', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'AdmissionDate_2104-09-24', 'AdmissionDate_2104-10-24', 'AdmissionDate_2105-05-29', 'AdmissionDate_2106-08-30', 'AdmissionDate_2107-01-04', 'AdmissionDate_2107-01-16', 'AdmissionDate_2107-01-29', 'AdmissionDate_2107-03-21', 'AdmissionDate_2107-05-12', 'AdmissionDate_2110-12-29', 'AdmissionDate_2112-02-04', 'AdmissionDate_2112-05-04', 'AdmissionDate_2112-05-22', 'AdmissionDate_2112-05-28', 'AdmissionDate_2115-05-12', 'AdmissionDate_2117-03-21', 'AdmissionDate_2117-08-05', 'AdmissionDate_2117-08-21', 'AdmissionDate_2118-10-06', 'AdmissionDate_2119-10-17', 'AdmissionDate_2120-08-24', 'AdmissionDate_2121-12-07', 'AdmissionDate_2123-08-23', 'AdmissionDate_2123-11-24', 'AdmissionDate_2124-01-12', 'AdmissionDate_2125-10-04', 'AdmissionDate_2126-08-14', 'AdmissionDate_2127-03-19', 'AdmissionDate_2127-07-23', 'AdmissionDate_2127-10-06', 'AdmissionDate_2128-03-22', 'AdmissionDate_2128-11-04', 'AdmissionDate_2129-03-03', 'AdmissionDate_2129-05-01', 'AdmissionDate_2129-11-23', 'AdmissionDate_2130-02-04', 'AdmissionDate_2130-08-12', 'AdmissionDate_2130-10-06', 'AdmissionDate_2131-07-26', 'AdmissionDate_2132-08-05', 'AdmissionDate_2132-12-05', 'AdmissionDate_2135-10-24', 'AdmissionDate_2138-04-02', 'AdmissionDate_2138-06-05', 'AdmissionDate_2138-11-09', 'AdmissionDate_2139-09-22', 'AdmissionDate_2141-01-25', 'AdmissionDate_2142-11-26', 'AdmissionDate_2144-02-09', 'AdmissionDate_2144-07-11', 'AdmissionDate_2144-07-18', 'AdmissionDate_2144-10-15', 'AdmissionDate_2144-12-24', 'AdmissionDate_2145-07-07', 'AdmissionDate_2145-09-06', 'AdmissionDate_2145-12-01', 'AdmissionDate_2146-07-21', 'AdmissionDate_2147-02-06', 'AdmissionDate_2147-02-23', 'AdmissionDate_2147-10-03', 'AdmissionDate_2148-01-13', 'AdmissionDate_2149-05-26', 'AdmissionDate_2150-08-07', 'AdmissionDate_2150-08-22', 'AdmissionDate_2151-08-13', 'AdmissionDate_2151-09-12', 'AdmissionDate_2152-10-02', 'AdmissionDate_2152-10-09', 'AdmissionDate_2155-03-08', 'AdmissionDate_2155-12-16', 'AdmissionDate_2159-11-17', 'AdmissionDate_2160-05-04', 'AdmissionDate_2160-12-16', 'AdmissionDate_2160-12-26', 'AdmissionDate_2161-01-30', 'AdmissionDate_2161-09-14', 'AdmissionDate_2162-01-16', 'AdmissionDate_2163-05-14', 'AdmissionDate_2163-11-21', 'AdmissionDate_2164-10-23', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'AdmissionDate_2167-02-11', 'AdmissionDate_2169-05-06', 'AdmissionDate_2170-12-02', 'AdmissionDate_2170-12-15', 'AdmissionDate_2171-07-12', 'AdmissionDate_2171-10-30', 'AdmissionDate_2173-11-27', 'AdmissionDate_2175-10-02', 'AdmissionDate_2176-07-14', 'AdmissionDate_2178-05-14', 'AdmissionDate_2179-04-17', 'AdmissionDate_2180-01-14', 'AdmissionDate_2180-02-29', 'AdmissionDate_2180-03-15', 'AdmissionDate_2180-07-19', 'AdmissionDate_2184-08-04', 'AdmissionDate_2185-03-24', 'AdmissionDate_2185-04-13', 'AdmissionDate_2186-02-09', 'AdmissionDate_2186-07-06', 'AdmissionDate_2188-02-08', 'AdmissionDate_2189-09-08', 'AdmissionDate_2190-07-13', 'AdmissionDate_2192-03-26', 'AdmissionDate_2192-04-16', 'AdmissionDate_2192-11-20', 'AdmissionDate_2193-10-15', 'AdmissionDate_2194-07-26', 'AdmissionDate_2195-05-17', 'AdmissionDate_2198-06-28', 'AdmissionDate_2198-06-29', 'AdmissionDate_2198-10-29', 'AdmissionDate_2199-01-13', 'AdmissionDate_2199-01-31', 'AdmissionDate_2200-03-17', 'AdmissionDate_2200-06-09', 'AdmissionDate_2200-10-29', 'AdmissionDate_2201-05-12', 'AdmissionDate_2201-08-10', 'AdmissionDate_2201-09-28', 'AdmissionDate_2201-11-16', 'AdmissionDate_2201-12-31', 'AdmissionDate_2202-02-15', 'AdmissionDate_2202-05-01', 'AdmissionDate_2202-09-16', 'AdmissionDate_2202-10-03', 'DIAGNOSIS_ABDOMINAL PAIN', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_BRAIN METASTASES', 'DIAGNOSIS_CELLULITIS', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'DIAGNOSIS_CHEST PAIN', 'DIAGNOSIS_CHEST PAIN/ CATH', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'DIAGNOSIS_FACIAL NUMBNESS', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'DIAGNOSIS_HEADACHE', 'DIAGNOSIS_HEPATIC ENCEP', 'DIAGNOSIS_HEPATITIS B', 'DIAGNOSIS_HUMERAL FRACTURE', 'DIAGNOSIS_HYPOGLYCEMIA', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_HYPOTENSION', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_LEFT HIP FRACTURE', 'DIAGNOSIS_LEFT HIP OA/SDA', 'DIAGNOSIS_LIVER FAILURE', 'DIAGNOSIS_LOWER GI BLEED', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'DIAGNOSIS_MI CHF', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'DIAGNOSIS_OVERDOSE', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'DIAGNOSIS_RENAL CANCER/SDA', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'DIAGNOSIS_S/P FALL', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_SEIZURE', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'DIAGNOSIS_SEPSIS', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'DIAGNOSIS_SHORTNESS OF BREATH', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'DIAGNOSIS_STEMI;', 'DIAGNOSIS_STROKE/TIA', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'DIAGNOSIS_TRACHEAL STENOSIS', 'DIAGNOSIS_UNSTABLE ANGINA', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'DIAGNOSIS_VARICEAL BLEED', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_VOLVULUS', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'ADMISSION_TYPE_EMERGENCY', 'ADMISSION_TYPE_URGENT']\n",
      "\n",
      "Types de donnÃ©es dans X_train AVANT le pipeline :\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 103 entries, 70 to 102\n",
      "Columns: 548 entries, AlcoholDrinkers to ADMISSION_TYPE_URGENT\n",
      "dtypes: bool(528), float64(5), int64(15)\n",
      "memory usage: 70.0 KB\n",
      "None\n",
      "\n",
      "ðŸš€ DÃ©but de l'entraÃ®nement et de la recherche d'hyperparamÃ¨tres...\n",
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "âœ… EntraÃ®nement terminÃ©.\n",
      "\n",
      "--- Ã‰valuation du Meilleur ModÃ¨le ---\n",
      "Meilleurs paramÃ¨tres trouvÃ©s : {'model__max_depth': 8, 'model__max_features': 'sqrt', 'model__min_samples_leaf': 2, 'model__min_samples_split': 3, 'model__n_estimators': 364}\n",
      "ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : 16.2090\n",
      "ðŸ“ˆ Score RÂ² : 0.5137\n",
      "\n",
      "âœ… Pipeline complet sauvegardÃ© sous : random_forest_length_stay_pipeline.joblib\n",
      "\n",
      "--- Simulation de DÃ©ploiement ---\n",
      "Pipeline chargÃ©.\n",
      "\n",
      "Nouvelles donnÃ©es brutes (format entrÃ©e attendu) :\n",
      "   AlcoholDrinkers  CovidPos  HadHeartAttack  HadAngina  HadStroke  HadAsthma  \\\n",
      "0             True      True            True       True       True       True   \n",
      "1            False     False           False      False      False      False   \n",
      "\n",
      "   HadSkinCancer  HadCOPD  HadDepressiveDisorder  HadKidneyDisease  ...  \\\n",
      "0           True     True               0.139535          0.162791  ...   \n",
      "1          False    False               0.000000          0.000000  ...   \n",
      "\n",
      "   HIVTesting  FluVaxLast12  PneumoVaxEver  AdmissionYear  AdmissionDayOfWeek  \\\n",
      "0    0.232558      0.612403       0.472868    2153.744186            3.968992   \n",
      "1    0.000000      1.000000       0.000000    2150.000000            4.000000   \n",
      "\n",
      "   facility_cost  procedure_cost  medication_cost  lab_test_cost  \\\n",
      "0    9837.209302     15232.55814    181448.062016  125726.356589   \n",
      "1    7000.000000      6000.00000     30400.000000   61600.000000   \n",
      "\n",
      "      total_cost  \n",
      "0  332244.186047  \n",
      "1  116050.000000  \n",
      "\n",
      "[2 rows x 28 columns]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "columns are missing: {'BMI_30,1800003051758', 'dob_2068-03-04 00:00:00', 'dob_2150-12-07 00:00:00', 'BMI_19,9699993133545', 'AdmissionDate_2185-04-13', 'AdmissionDate_2198-06-28', 'AdmissionDate_2127-07-23', 'AdmissionDate_2201-12-31', 'dob_2046-07-05 00:00:00', 'HeightInMeters_1,79999995231628', 'AdmissionDate_2115-05-12', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'WeightInKilograms_63,5', 'AdmissionDate_2170-12-02', 'AdmissionDate_2105-05-29', 'ETHNICITY_UNABLE TO OBTAIN', 'dob_2111-07-18 00:00:00', 'dob_2061-06-13 00:00:00', 'BMI_21,0599994659424', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'BMI_21,0300006866455', 'AdmissionDate_2194-07-26', 'BMI_25,0599994659424', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'BMI_25,1100006103516', 'dob_2114-06-20 00:00:00', 'dob_2098-04-29 00:00:00', 'BMI_23,6299991607666', 'BMI_32,7400016784668', 'WeightInKilograms_78,0199966430664', 'dob_2071-02-11 00:00:00', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'MARITAL_STATUS_SINGLE', 'DIAGNOSIS_SEIZURE', 'dob_2090-06-05 00:00:00', 'BMI_35,7799987792969', 'AdmissionDate_2152-10-02', 'WeightInKilograms_69,4000015258789', 'BMI_35,8699989318848', 'BMI_30,1299991607666', 'AdmissionDate_2198-06-29', 'ECigaretteUsage_Use them every day', 'WeightInKilograms_91,1699981689453', 'BMI_27,3400001525879', 'HeightInMeters_1,85000002384186', 'dob_2031-05-19 00:00:00', 'AdmissionDate_2127-10-06', 'WeightInKilograms_90,7200012207031', 'ETHNICITY_WHITE', 'dob_2094-03-05 00:00:00', 'AdmissionDate_2147-10-03', 'BMI_34,9599990844727', 'dob_2061-10-23 00:00:00', 'AdmissionDate_2200-06-09', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'HeightInMeters_1,64999997615814', 'AdmissionDate_2135-10-24', 'AdmissionDate_2201-11-16', 'WeightInKilograms_106,589996337891', 'dob_2053-09-08 00:00:00', 'AdmissionDate_2126-08-14', 'AdmissionDate_2144-07-18', 'dob_2016-12-05 00:00:00', 'AdmissionDate_2163-11-21', 'BMI_33,439998626709', 'AdmissionDate_2141-01-25', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'BMI_27,8099994659424', 'DIAGNOSIS_TRACHEAL STENOSIS', 'dob_2097-05-16 00:00:00', 'dob_2090-11-16 00:00:00', 'AdmissionDate_2129-11-23', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'AdmissionDate_2160-12-16', 'dob_2104-02-12 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_1878-05-14 00:00:00', 'AdmissionDate_2163-05-14', 'BMI_31,9300003051758', 'AdmissionDate_2144-10-15', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Use them some days', 'dob_2081-12-26 00:00:00', 'LANGUAGE_SPAN', 'dob_2073-08-13 00:00:00', 'BMI_24,6900005340576', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'AdmissionDate_2180-03-15', 'WeightInKilograms_62,5999984741211', 'AdmissionDate_2117-03-21', 'HeightInMeters_1,75', 'BMI_32,0800018310547', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CELLULITIS', 'WeightInKilograms_129,270004272461', 'BMI_24,5499992370605', 'BMI_26,9400005340576', 'AdmissionDate_2107-03-21', 'AdmissionDate_2119-10-17', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'dob_2029-12-07 00:00:00', 'DIAGNOSIS_STEMI;', 'dob_2107-06-27 00:00:00', 'BMI_24,9400005340576', 'DIAGNOSIS_STROKE/TIA', 'HeightInMeters_1,83000004291534', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'BMI_27,9899997711182', 'AdmissionDate_2112-05-22', 'dob_2069-05-05 00:00:00', 'MARITAL_STATUS_SEPARATED', 'dob_2075-09-21 00:00:00', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'AdmissionDate_2193-10-15', 'AdmissionDate_2129-03-03', 'DIAGNOSIS_LOWER GI BLEED', 'dob_2051-03-24 00:00:00', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_73,4800033569336', 'dob_1885-03-24 00:00:00', 'AdmissionDate_2201-09-28', 'BMI_29,8600006103516', 'AdmissionDate_2164-10-23', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'BMI_32,9300003051758', 'BMI_27,2600002288818', 'BMI_34,7700004577637', 'AdmissionDate_2123-11-24', 'AdmissionDate_2150-08-07', 'AdmissionDate_2132-12-05', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'BMI_27,7600002288818', 'DIAGNOSIS_SHORTNESS OF BREATH', 'AdmissionDate_2192-04-16', 'AdmissionDate_2161-01-30', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'BMI_30,5599994659424', 'AdmissionDate_2152-10-09', 'AdmissionDate_2138-11-09', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'WeightInKilograms_94,8000030517578', 'dob_2046-02-27 00:00:00', 'BMI_26,7000007629395', 'AdmissionDate_2176-07-14', 'dob_2097-01-16 00:00:00', 'AdmissionDate_2171-10-30', 'AdmissionDate_2171-07-12', 'DIAGNOSIS_HUMERAL FRACTURE', 'dob_2072-05-05 00:00:00', 'dob_2050-03-29 00:00:00', 'AdmissionDate_2161-09-14', 'AdmissionDate_2138-04-02', 'HeightInMeters_1,5', 'WeightInKilograms_97,0699996948242', 'BMI_33,8899993896484', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'WeightInKilograms_86,1800003051758', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_VOLVULUS', 'AdmissionDate_2195-05-17', 'BMI_23,6900005340576', 'ADMISSION_TYPE_URGENT', 'dob_2058-04-23 00:00:00', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'BMI_25,8400001525879', 'BMI_61,0299987792969', 'AdmissionDate_2192-03-26', 'dob_2112-01-20 00:00:00', 'dob_2181-04-19 00:00:00', 'AdmissionDate_2120-08-24', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'dob_2109-07-08 00:00:00', 'dob_2036-03-10 00:00:00', 'AdmissionDate_2199-01-13', 'BMI_29,8400001525879', 'AdmissionDate_2162-01-16', 'DIAGNOSIS_MI CHF', 'dob_2096-02-27 00:00:00', 'WeightInKilograms_87,5400009155273', 'AdmissionDate_2147-02-06', 'WeightInKilograms_74,8399963378906', 'AdmissionDate_2170-12-15', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'dob_2099-03-17 00:00:00', 'HeightInMeters_1,98000001907349', 'AdmissionDate_2150-08-22', 'dob_2060-02-12 00:00:00', 'BMI_25,5400009155273', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'dob_2141-03-15 00:00:00', 'AdmissionDate_2107-01-16', 'BMI_25,1499996185303', 'MARITAL_STATUS_MARRIED', 'WeightInKilograms_108,860000610352', 'HeightInMeters_1,57000005245209', 'dob_2038-05-10 00:00:00', 'WeightInKilograms_76,6600036621094', 'AdmissionDate_2117-08-05', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'AdmissionDate_2145-09-06', 'AdmissionDate_2151-08-13', 'WeightInKilograms_78,4700012207031', 'dob_2108-01-15 00:00:00', 'WeightInKilograms_66,2200012207031', 'DIAGNOSIS_FACIAL NUMBNESS', 'dob_2044-06-27 00:00:00', 'BMI_30,6800003051758', 'AdmissionDate_2144-07-11', 'AdmissionDate_2147-02-23', 'AdmissionDate_2107-01-29', 'AdmissionDate_2112-05-04', 'AdmissionDate_2179-04-17', 'BMI_29,8799991607666', 'BMI_20,9200000762939', 'AdmissionDate_2173-11-27', 'WeightInKilograms_67,129997253418', 'dob_1876-07-14 00:00:00', 'DIAGNOSIS_CHEST PAIN', 'dob_2136-07-29 00:00:00', 'WeightInKilograms_52,1599998474121', 'AdmissionDate_2129-05-01', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'AdmissionDate_2107-05-12', 'AdmissionDate_2180-01-14', 'HadDiabetes_Yes', 'dob_2050-02-16 00:00:00', 'BMI_32,9199981689453', 'HeightInMeters_1,54999995231628', 'WeightInKilograms_88,4499969482422', 'BMI_41,1599998474121', 'DIAGNOSIS_HEPATIC ENCEP', 'AdmissionDate_2148-01-13', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'AdmissionDate_2125-10-04', 'AdmissionDate_2202-09-16', 'AdmissionDate_2145-07-07', 'AdmissionDate_2186-02-09', 'AdmissionDate_2201-05-12', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_84,8199996948242', 'dob_2057-11-15 00:00:00', 'WeightInKilograms_71,6699981689453', 'HadDiabetes_Yes, but only during pregnancy (female)', 'AdmissionDate_2142-11-26', 'BMI_23,0100002288818', 'HeightInMeters_1,62999999523163', 'dob_2035-04-13 00:00:00', 'dob_1851-09-12 00:00:00', 'AdmissionDate_2104-09-24', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_BRAIN METASTASES', 'AdmissionDate_2184-08-04', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'WeightInKilograms_79,8300018310547', 'DIAGNOSIS_LEFT HIP FRACTURE', 'dob_2136-07-28 00:00:00', 'AdmissionDate_2107-01-04', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'HeightInMeters_1,73000001907349', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'BMI_36,6199989318848', 'WeightInKilograms_72,5699996948242', 'dob_1846-07-21 00:00:00', 'TetanusLast10Tdap_Yes, received Tdap', 'AdmissionDate_2198-10-29', 'DIAGNOSIS_OVERDOSE', 'dob_2051-04-21 00:00:00', 'AdmissionDate_2149-05-26', 'BMI_24,3299999237061', 'BMI_44,9199981689453', 'AdmissionDate_2180-07-19', 'DIAGNOSIS_LIVER FAILURE', 'WeightInKilograms_58,060001373291', 'AdmissionDate_2199-01-31', 'DIAGNOSIS_LEFT HIP OA/SDA', 'dob_2079-01-29 00:00:00', 'BMI_26,4300003051758', 'AdmissionDate_2106-08-30', 'AdmissionDate_2130-08-12', 'dob_2099-09-02 00:00:00', 'BMI_31,3799991607666', 'BMI_28,8400001525879', 'WeightInKilograms_129,729995727539', 'DIAGNOSIS_HEPATITIS B', 'dob_2086-12-16 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2074-09-29 00:00:00', 'BMI_22,5300006866455', 'dob_2051-07-25 00:00:00', 'LANGUAGE_POLI', 'AdmissionDate_2112-02-04', 'dob_2110-03-25 00:00:00', 'BMI_27,1200008392334', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'dob_2086-02-04 00:00:00', 'WeightInKilograms_68,0400009155273', 'BMI_31,8700008392334', 'SmokerStatus_Former smoker', 'LANGUAGE_RUSS', 'dob_2051-03-23 00:00:00', 'AdmissionDate_2121-12-07', 'AdmissionDate_2104-10-24', 'BMI_33,2999992370605', 'WeightInKilograms_65,7699966430664', 'AdmissionDate_2144-12-24', 'ADMISSION_TYPE_EMERGENCY', 'AdmissionDate_2190-07-13', 'AdmissionDate_2139-09-22', 'BMI_32,4900016784668', 'AdmissionDate_2202-10-03', 'dob_2046-04-18 00:00:00', 'dob_2061-12-10 00:00:00', 'WeightInKilograms_64,4100036621094', 'AdmissionDate_2160-12-26', 'DIAGNOSIS_ABDOMINAL PAIN', 'HeightInMeters_1,77999997138977', 'BMI_31,0100002288818', 'BMI_30,3400001525879', 'WeightInKilograms_113,400001525879', 'BMI_30,2299995422363', 'dob_2058-08-04 00:00:00', 'dob_2045-10-07 00:00:00', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'WeightInKilograms_59,8699989318848', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'BMI_30,4099998474121', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'AdmissionDate_2159-11-17', 'dob_2070-10-11 00:00:00', 'dob_2146-10-23 00:00:00', 'BMI_20,1399993896484', 'dob_2076-05-06 00:00:00', 'BMI_27,8899993896484', 'WeightInKilograms_88', 'WeightInKilograms_54,8800010681152', 'BMI_44,2900009155273', 'WeightInKilograms_122,470001220703', 'dob_2031-08-12 00:00:00', 'dob_2029-07-09 00:00:00', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'HeightInMeters_1,67999994754791', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_104,330001831055', 'dob_1895-05-17 00:00:00', 'AdmissionDate_2202-05-01', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'dob_2112-10-22 00:00:00', 'WeightInKilograms_69,8499984741211', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'AdmissionDate_2167-02-11', 'ETHNICITY_OTHER', 'AdmissionDate_2155-03-08', 'DIAGNOSIS_SEPSIS', 'dob_2061-03-25 00:00:00', 'BMI_28,8899993896484', 'BMI_20,9799995422363', 'BMI_27,2000007629395', 'dob_2101-06-10 00:00:00', 'dob_2078-06-16 00:00:00', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'BMI_52,1300010681152', 'BMI_19,7900009155273', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'BMI_33,0699996948242', 'AdmissionDate_2117-08-21', 'BMI_20,8099994659424', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'dob_2096-07-25 00:00:00', 'BMI_25,3700008392334', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'WeightInKilograms_79,379997253418', 'BMI_32,0999984741211', 'AdmissionDate_2138-06-05', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'AdmissionDate_2155-12-16', 'AdmissionDate_2192-11-20', 'BMI_21,7700004577637', 'BMI_31,8899993896484', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'AdmissionDate_2128-03-22', 'AdmissionDate_2127-03-19', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'AdmissionDate_2151-09-12', 'ECigaretteUsage_Not at all (right now)', 'BMI_37,7299995422363', 'dob_2072-12-03 00:00:00', 'AdmissionDate_2128-11-04', 'AdmissionDate_2146-07-21', 'WeightInKilograms_57,6100006103516', 'BMI_24,4500007629395', 'HeightInMeters_1,51999998092651', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_RENAL CANCER/SDA', 'AdmissionDate_2130-10-06', 'ETHNICITY_ASIAN', 'AdmissionDate_2169-05-06', 'dob_2088-05-05 00:00:00', 'dob_2056-01-27 00:00:00', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_61,2299995422363', 'BMI_21,1299991607666', 'dob_2053-04-13 00:00:00', 'dob_2041-05-16 00:00:00', 'HeightInMeters_1,92999994754791', 'AdmissionDate_2131-07-26', 'AdmissionDate_2200-03-17', 'dob_2061-04-10 00:00:00', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'BMI_46,8699989318848', 'dob_2082-06-27 00:00:00', 'HeightInMeters_1,60000002384186', 'dob_2097-01-07 00:00:00', 'AdmissionDate_2118-10-06', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'WeightInKilograms_71,2099990844727', 'DIAGNOSIS_UNSTABLE ANGINA', 'dob_2079-08-17 00:00:00', 'AdmissionDate_2188-02-08', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'WeightInKilograms_99,7900009155273', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'dob_2127-06-04 00:00:00', 'dob_2097-11-14 00:00:00', 'DIAGNOSIS_VARICEAL BLEED', 'dob_2081-01-03 00:00:00', 'WeightInKilograms_95,25', 'BMI_35,1500015258789', 'AdmissionDate_2185-03-24', 'DIAGNOSIS_S/P FALL', 'dob_2110-04-02 00:00:00', 'AdmissionDate_2201-08-10', 'AdmissionDate_2145-12-01', 'AdmissionDate_2130-02-04', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_HYPOTENSION', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'WeightInKilograms_204,119995117188', 'BMI_31,6599998474121', 'WeightInKilograms_49,9000015258789', 'BMI_25,0900001525879', 'SmokerStatus_Current smoker - now smokes some days', 'AdmissionDate_2132-08-05', 'AdmissionDate_2202-02-15', 'dob_2073-11-22 00:00:00', 'AdmissionDate_2189-09-08', 'BMI_28,2800006866455', 'AdmissionDate_2178-05-14', 'AdmissionDate_2186-07-06', 'dob_2055-07-18 00:00:00', 'BMI_29,1499996185303', 'dob_2073-06-05 00:00:00', 'BMI_36,7299995422363', 'WeightInKilograms_120,199996948242', 'BMI_31,3199996948242', 'BMI_27,3899993896484', 'dob_2097-12-16 00:00:00', 'dob_2108-12-20 00:00:00', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_HYPOGLYCEMIA', 'AdmissionDate_2180-02-29', 'BMI_29,0499992370605', 'AdmissionDate_2123-08-23', 'DIAGNOSIS_CHEST PAIN/ CATH', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ETHNICITY_HISPANIC OR LATINO', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'BMI_31,75', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'dob_2083-09-20 00:00:00', 'BMI_22,6000003814697', 'BMI_23,4400005340576', 'AdmissionDate_2144-02-09', 'BMI_22,6700000762939', 'WeightInKilograms_81,6500015258789', 'gender_M', 'AdmissionDate_2112-05-28', 'BMI_24,3700008392334', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'HeightInMeters_1,87999999523163', 'DIAGNOSIS_HEADACHE', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'AdmissionDate_2175-10-02', 'HeightInMeters_1,70000004768372', 'dob_1880-02-29 00:00:00', 'WeightInKilograms_54,4300003051758', 'MARITAL_STATUS_WIDOWED', 'AdmissionDate_2200-10-29', 'WeightInKilograms_115,669998168945', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'LANGUAGE_MAND', 'AdmissionDate_2110-12-29', 'dob_2063-07-05 00:00:00', 'HeightInMeters_1,9099999666214', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_83,4599990844727', 'BMI_27,0699996948242', 'AdmissionDate_2124-01-12', 'dob_2038-09-03 00:00:00', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'AdmissionDate_2160-05-04'}",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[67], line 235\u001b[0m\n\u001b[0;32m    228\u001b[0m     \u001b[38;5;28mprint\u001b[39m(new_data)\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;66;03m#print(\"\\nTypes de donnÃ©es des nouvelles donnÃ©es:\")\u001b[39;00m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m#print(new_data.info())\u001b[39;00m\n\u001b[0;32m    231\u001b[0m \n\u001b[0;32m    232\u001b[0m \n\u001b[0;32m    233\u001b[0m     \u001b[38;5;66;03m# Faire des prÃ©dictions avec le pipeline chargÃ©\u001b[39;00m\n\u001b[0;32m    234\u001b[0m     \u001b[38;5;66;03m# Le pipeline gÃ¨re l'encodage et la standardisation automatiquement !\u001b[39;00m\n\u001b[1;32m--> 235\u001b[0m     new_predictions \u001b[38;5;241m=\u001b[39m loaded_pipeline\u001b[38;5;241m.\u001b[39mpredict(new_data)\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPrÃ©dictions pour les nouvelles donnÃ©es : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnew_predictions\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\pipeline.py:787\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m    785\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[0;32m    786\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m--> 787\u001b[0m         Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[0;32m    788\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams)\n\u001b[0;32m    790\u001b[0m \u001b[38;5;66;03m# metadata routing enabled\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\utils\\_set_output.py:319\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 319\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    320\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    322\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    323\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    324\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    325\u001b[0m         )\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\compose\\_column_transformer.py:1090\u001b[0m, in \u001b[0;36mColumnTransformer.transform\u001b[1;34m(self, X, **params)\u001b[0m\n\u001b[0;32m   1088\u001b[0m     diff \u001b[38;5;241m=\u001b[39m all_names \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mset\u001b[39m(column_names)\n\u001b[0;32m   1089\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m diff:\n\u001b[1;32m-> 1090\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns are missing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdiff\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1091\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1092\u001b[0m     \u001b[38;5;66;03m# ndarray was used for fitting or transforming, thus we only\u001b[39;00m\n\u001b[0;32m   1093\u001b[0m     \u001b[38;5;66;03m# check that n_features_in_ is consistent\u001b[39;00m\n\u001b[0;32m   1094\u001b[0m     _check_n_features(\u001b[38;5;28mself\u001b[39m, X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mValueError\u001b[0m: columns are missing: {'BMI_30,1800003051758', 'dob_2068-03-04 00:00:00', 'dob_2150-12-07 00:00:00', 'BMI_19,9699993133545', 'AdmissionDate_2185-04-13', 'AdmissionDate_2198-06-28', 'AdmissionDate_2127-07-23', 'AdmissionDate_2201-12-31', 'dob_2046-07-05 00:00:00', 'HeightInMeters_1,79999995231628', 'AdmissionDate_2115-05-12', 'DIAGNOSIS_ALTERED MENTAL STATUS', 'WeightInKilograms_63,5', 'AdmissionDate_2170-12-02', 'AdmissionDate_2105-05-29', 'ETHNICITY_UNABLE TO OBTAIN', 'dob_2111-07-18 00:00:00', 'dob_2061-06-13 00:00:00', 'BMI_21,0599994659424', 'DIAGNOSIS_ACUTE PULMONARY EMBOLISM', 'BMI_21,0300006866455', 'AdmissionDate_2194-07-26', 'BMI_25,0599994659424', 'DIAGNOSIS_HYPONATREMIA;URINARY TRACT INFECTION', 'DIAGNOSIS_PNEUMONIA', 'DIAGNOSIS_ESOPHAGEAL CANCER/SDA', 'BMI_25,1100006103516', 'dob_2114-06-20 00:00:00', 'dob_2098-04-29 00:00:00', 'BMI_23,6299991607666', 'BMI_32,7400016784668', 'WeightInKilograms_78,0199966430664', 'dob_2071-02-11 00:00:00', 'AdmissionDate_2165-12-19', 'AdmissionDate_2166-02-12', 'MARITAL_STATUS_SINGLE', 'DIAGNOSIS_SEIZURE', 'dob_2090-06-05 00:00:00', 'BMI_35,7799987792969', 'AdmissionDate_2152-10-02', 'WeightInKilograms_69,4000015258789', 'BMI_35,8699989318848', 'BMI_30,1299991607666', 'AdmissionDate_2198-06-29', 'ECigaretteUsage_Use them every day', 'WeightInKilograms_91,1699981689453', 'BMI_27,3400001525879', 'HeightInMeters_1,85000002384186', 'dob_2031-05-19 00:00:00', 'AdmissionDate_2127-10-06', 'WeightInKilograms_90,7200012207031', 'ETHNICITY_WHITE', 'dob_2094-03-05 00:00:00', 'AdmissionDate_2147-10-03', 'BMI_34,9599990844727', 'dob_2061-10-23 00:00:00', 'AdmissionDate_2200-06-09', 'DIAGNOSIS_AROMEGLEY;BURKITTS LYMPHOMA', 'HeightInMeters_1,64999997615814', 'AdmissionDate_2135-10-24', 'AdmissionDate_2201-11-16', 'WeightInKilograms_106,589996337891', 'dob_2053-09-08 00:00:00', 'AdmissionDate_2126-08-14', 'AdmissionDate_2144-07-18', 'dob_2016-12-05 00:00:00', 'AdmissionDate_2163-11-21', 'BMI_33,439998626709', 'AdmissionDate_2141-01-25', 'TetanusLast10Tdap_Yes, received tetanus shot but not sure what type', 'BMI_27,8099994659424', 'DIAGNOSIS_TRACHEAL STENOSIS', 'dob_2097-05-16 00:00:00', 'dob_2090-11-16 00:00:00', 'AdmissionDate_2129-11-23', 'DIAGNOSIS_CHRONIC MYELOGENOUS LEUKEMIA;TRANSFUSION REACTION', 'AdmissionDate_2160-12-16', 'dob_2104-02-12 00:00:00', 'dob_2109-04-07 00:00:00', 'dob_1878-05-14 00:00:00', 'AdmissionDate_2163-05-14', 'BMI_31,9300003051758', 'AdmissionDate_2144-10-15', 'SmokerStatus_Never smoked', 'ECigaretteUsage_Use them some days', 'dob_2081-12-26 00:00:00', 'LANGUAGE_SPAN', 'dob_2073-08-13 00:00:00', 'BMI_24,6900005340576', 'DIAGNOSIS_URINARY TRACT INFECTION;PYELONEPHRITIS', 'DIAGNOSIS_GASTROINTESTINAL BLEED', 'AdmissionDate_2180-03-15', 'WeightInKilograms_62,5999984741211', 'AdmissionDate_2117-03-21', 'HeightInMeters_1,75', 'BMI_32,0800018310547', 'DIAGNOSIS_CHOLANGITIS', 'DIAGNOSIS_CELLULITIS', 'WeightInKilograms_129,270004272461', 'BMI_24,5499992370605', 'BMI_26,9400005340576', 'AdmissionDate_2107-03-21', 'AdmissionDate_2119-10-17', 'DIAGNOSIS_PULMONARY EDEMA\\\\CATH', 'dob_2029-12-07 00:00:00', 'DIAGNOSIS_STEMI;', 'dob_2107-06-27 00:00:00', 'BMI_24,9400005340576', 'DIAGNOSIS_STROKE/TIA', 'HeightInMeters_1,83000004291534', 'DIAGNOSIS_FEVER;URINARY TRACT INFECTION', 'BMI_27,9899997711182', 'AdmissionDate_2112-05-22', 'dob_2069-05-05 00:00:00', 'MARITAL_STATUS_SEPARATED', 'dob_2075-09-21 00:00:00', 'ADMISSION_LOCATION_TRANSFER FROM SKILLED NUR', 'AdmissionDate_2193-10-15', 'AdmissionDate_2129-03-03', 'DIAGNOSIS_LOWER GI BLEED', 'dob_2051-03-24 00:00:00', 'WeightInKilograms_83,9100036621094', 'WeightInKilograms_73,4800033569336', 'dob_1885-03-24 00:00:00', 'AdmissionDate_2201-09-28', 'BMI_29,8600006103516', 'AdmissionDate_2164-10-23', 'DIAGNOSIS_PNEUMONIA;TELEMETRY', 'DIAGNOSIS_SEPSIS;TELEMETRY', 'BMI_32,9300003051758', 'BMI_27,2600002288818', 'BMI_34,7700004577637', 'AdmissionDate_2123-11-24', 'AdmissionDate_2150-08-07', 'AdmissionDate_2132-12-05', 'HadDiabetes_No, pre-diabetes or borderline diabetes', 'DIAGNOSIS_CRITICAL AORTIC STENOSIS/HYPOTENSION', 'BMI_27,7600002288818', 'DIAGNOSIS_SHORTNESS OF BREATH', 'AdmissionDate_2192-04-16', 'AdmissionDate_2161-01-30', 'DIAGNOSIS_UROSEPSIS', 'DIAGNOSIS_HYPOTENSION;TELEMETRY', 'BMI_30,5599994659424', 'AdmissionDate_2152-10-09', 'AdmissionDate_2138-11-09', 'DIAGNOSIS_ABSCESS', 'DIAGNOSIS_CONGESTIVE HEART FAILURE', 'WeightInKilograms_94,8000030517578', 'dob_2046-02-27 00:00:00', 'BMI_26,7000007629395', 'AdmissionDate_2176-07-14', 'dob_2097-01-16 00:00:00', 'AdmissionDate_2171-10-30', 'AdmissionDate_2171-07-12', 'DIAGNOSIS_HUMERAL FRACTURE', 'dob_2072-05-05 00:00:00', 'dob_2050-03-29 00:00:00', 'AdmissionDate_2161-09-14', 'AdmissionDate_2138-04-02', 'HeightInMeters_1,5', 'WeightInKilograms_97,0699996948242', 'BMI_33,8899993896484', 'DIAGNOSIS_CHOLECYSTITIS', 'DIAGNOSIS_HYPOTENSION;UNRESPONSIVE', 'WeightInKilograms_86,1800003051758', 'DIAGNOSIS_S/P MOTORCYCLE ACCIDENT', 'DIAGNOSIS_VOLVULUS', 'AdmissionDate_2195-05-17', 'BMI_23,6900005340576', 'ADMISSION_TYPE_URGENT', 'dob_2058-04-23 00:00:00', 'DIAGNOSIS_UPPER GI BLEED', 'DIAGNOSIS_PNEUMONIA/HYPOGLCEMIA/SYNCOPE', 'DIAGNOSIS_METASTIC MELANOMA;ANEMIA', 'BMI_25,8400001525879', 'BMI_61,0299987792969', 'AdmissionDate_2192-03-26', 'dob_2112-01-20 00:00:00', 'dob_2181-04-19 00:00:00', 'AdmissionDate_2120-08-24', 'DIAGNOSIS_RESPIRATORY DISTRESS', 'DIAGNOSIS_SEPSIS;PNEUMONIA;TELEMETRY', 'dob_2109-07-08 00:00:00', 'dob_2036-03-10 00:00:00', 'AdmissionDate_2199-01-13', 'BMI_29,8400001525879', 'AdmissionDate_2162-01-16', 'DIAGNOSIS_MI CHF', 'dob_2096-02-27 00:00:00', 'WeightInKilograms_87,5400009155273', 'AdmissionDate_2147-02-06', 'WeightInKilograms_74,8399963378906', 'AdmissionDate_2170-12-15', 'DIAGNOSIS_ASTHMA;CHRONIC OBST PULM DISEASE', 'dob_2099-03-17 00:00:00', 'HeightInMeters_1,98000001907349', 'AdmissionDate_2150-08-22', 'dob_2060-02-12 00:00:00', 'BMI_25,5400009155273', 'DIAGNOSIS_SYNCOPE;TELEMETRY', 'dob_2141-03-15 00:00:00', 'AdmissionDate_2107-01-16', 'BMI_25,1499996185303', 'MARITAL_STATUS_MARRIED', 'WeightInKilograms_108,860000610352', 'HeightInMeters_1,57000005245209', 'dob_2038-05-10 00:00:00', 'WeightInKilograms_76,6600036621094', 'AdmissionDate_2117-08-05', 'ETHNICITY_BLACK/AFRICAN AMERICAN', 'AdmissionDate_2145-09-06', 'AdmissionDate_2151-08-13', 'WeightInKilograms_78,4700012207031', 'dob_2108-01-15 00:00:00', 'WeightInKilograms_66,2200012207031', 'DIAGNOSIS_FACIAL NUMBNESS', 'dob_2044-06-27 00:00:00', 'BMI_30,6800003051758', 'AdmissionDate_2144-07-11', 'AdmissionDate_2147-02-23', 'AdmissionDate_2107-01-29', 'AdmissionDate_2112-05-04', 'AdmissionDate_2179-04-17', 'BMI_29,8799991607666', 'BMI_20,9200000762939', 'AdmissionDate_2173-11-27', 'WeightInKilograms_67,129997253418', 'dob_1876-07-14 00:00:00', 'DIAGNOSIS_CHEST PAIN', 'dob_2136-07-29 00:00:00', 'WeightInKilograms_52,1599998474121', 'AdmissionDate_2129-05-01', 'DIAGNOSIS_LUNG CANCER;SHORTNESS OF BREATH', 'AdmissionDate_2107-05-12', 'AdmissionDate_2180-01-14', 'HadDiabetes_Yes', 'dob_2050-02-16 00:00:00', 'BMI_32,9199981689453', 'HeightInMeters_1,54999995231628', 'WeightInKilograms_88,4499969482422', 'BMI_41,1599998474121', 'DIAGNOSIS_HEPATIC ENCEP', 'AdmissionDate_2148-01-13', 'DIAGNOSIS_RIGHT HUMEROUS FRACTURE', 'AdmissionDate_2125-10-04', 'AdmissionDate_2202-09-16', 'AdmissionDate_2145-07-07', 'AdmissionDate_2186-02-09', 'AdmissionDate_2201-05-12', 'WeightInKilograms_97,5199966430664', 'WeightInKilograms_84,8199996948242', 'dob_2057-11-15 00:00:00', 'WeightInKilograms_71,6699981689453', 'HadDiabetes_Yes, but only during pregnancy (female)', 'AdmissionDate_2142-11-26', 'BMI_23,0100002288818', 'HeightInMeters_1,62999999523163', 'dob_2035-04-13 00:00:00', 'dob_1851-09-12 00:00:00', 'AdmissionDate_2104-09-24', 'DIAGNOSIS_CORONARY ARTERY DISEASE\\\\CORONARY ARTERY BYPASS GRAFT /SDA', 'DIAGNOSIS_BRAIN METASTASES', 'AdmissionDate_2184-08-04', 'DIAGNOSIS_ALCOHOLIC HEPATITIS', 'WeightInKilograms_79,8300018310547', 'DIAGNOSIS_LEFT HIP FRACTURE', 'dob_2136-07-28 00:00:00', 'AdmissionDate_2107-01-04', 'DIAGNOSIS_S/P MOTOR VEHICLE ACCIDENT', 'HeightInMeters_1,73000001907349', 'DIAGNOSIS_ACUTE RESPIRATORY DISTRESS SYNDROME;ACUTE RENAL FAILURE', 'BMI_36,6199989318848', 'WeightInKilograms_72,5699996948242', 'dob_1846-07-21 00:00:00', 'TetanusLast10Tdap_Yes, received Tdap', 'AdmissionDate_2198-10-29', 'DIAGNOSIS_OVERDOSE', 'dob_2051-04-21 00:00:00', 'AdmissionDate_2149-05-26', 'BMI_24,3299999237061', 'BMI_44,9199981689453', 'AdmissionDate_2180-07-19', 'DIAGNOSIS_LIVER FAILURE', 'WeightInKilograms_58,060001373291', 'AdmissionDate_2199-01-31', 'DIAGNOSIS_LEFT HIP OA/SDA', 'dob_2079-01-29 00:00:00', 'BMI_26,4300003051758', 'AdmissionDate_2106-08-30', 'AdmissionDate_2130-08-12', 'dob_2099-09-02 00:00:00', 'BMI_31,3799991607666', 'BMI_28,8400001525879', 'WeightInKilograms_129,729995727539', 'DIAGNOSIS_HEPATITIS B', 'dob_2086-12-16 00:00:00', 'dob_2103-12-05 00:00:00', 'dob_2074-09-29 00:00:00', 'BMI_22,5300006866455', 'dob_2051-07-25 00:00:00', 'LANGUAGE_POLI', 'AdmissionDate_2112-02-04', 'dob_2110-03-25 00:00:00', 'BMI_27,1200008392334', 'DIAGNOSIS_ELEVATED LIVER FUNCTIONS;S/P LIVER TRANSPLANT', 'DIAGNOSIS_INFERIOR MYOCARDIAL INFARCTION\\\\CATH', 'DIAGNOSIS_ACUTE CHOLECYSTITIS', 'dob_2086-02-04 00:00:00', 'WeightInKilograms_68,0400009155273', 'BMI_31,8700008392334', 'SmokerStatus_Former smoker', 'LANGUAGE_RUSS', 'dob_2051-03-23 00:00:00', 'AdmissionDate_2121-12-07', 'AdmissionDate_2104-10-24', 'BMI_33,2999992370605', 'WeightInKilograms_65,7699966430664', 'AdmissionDate_2144-12-24', 'ADMISSION_TYPE_EMERGENCY', 'AdmissionDate_2190-07-13', 'AdmissionDate_2139-09-22', 'BMI_32,4900016784668', 'AdmissionDate_2202-10-03', 'dob_2046-04-18 00:00:00', 'dob_2061-12-10 00:00:00', 'WeightInKilograms_64,4100036621094', 'AdmissionDate_2160-12-26', 'DIAGNOSIS_ABDOMINAL PAIN', 'HeightInMeters_1,77999997138977', 'BMI_31,0100002288818', 'BMI_30,3400001525879', 'WeightInKilograms_113,400001525879', 'BMI_30,2299995422363', 'dob_2058-08-04 00:00:00', 'dob_2045-10-07 00:00:00', 'DIAGNOSIS_HYPOTENSION, RENAL FAILURE', 'WeightInKilograms_59,8699989318848', 'DIAGNOSIS_FEVER', 'DIAGNOSIS_ACUTE CHOLANGITIS', 'BMI_30,4099998474121', 'DIAGNOSIS_TRACHEAL ESOPHAGEAL FISTULA', 'AdmissionDate_2159-11-17', 'dob_2070-10-11 00:00:00', 'dob_2146-10-23 00:00:00', 'BMI_20,1399993896484', 'dob_2076-05-06 00:00:00', 'BMI_27,8899993896484', 'WeightInKilograms_88', 'WeightInKilograms_54,8800010681152', 'BMI_44,2900009155273', 'WeightInKilograms_122,470001220703', 'dob_2031-08-12 00:00:00', 'dob_2029-07-09 00:00:00', 'DIAGNOSIS_MEDIASTINAL ADENOPATHY', 'HeightInMeters_1,67999994754791', 'WeightInKilograms_92,0800018310547', 'WeightInKilograms_104,330001831055', 'dob_1895-05-17 00:00:00', 'AdmissionDate_2202-05-01', 'DIAGNOSIS_SYNCOPE;TELEMETRY;INTRACRANIAL HEMORRHAGE', 'dob_2112-10-22 00:00:00', 'WeightInKilograms_69,8499984741211', 'ADMISSION_LOCATION_TRANSFER FROM HOSP/EXTRAM', 'AdmissionDate_2167-02-11', 'ETHNICITY_OTHER', 'AdmissionDate_2155-03-08', 'DIAGNOSIS_SEPSIS', 'dob_2061-03-25 00:00:00', 'BMI_28,8899993896484', 'BMI_20,9799995422363', 'BMI_27,2000007629395', 'dob_2101-06-10 00:00:00', 'dob_2078-06-16 00:00:00', 'DIAGNOSIS_BASAL GANGLIN BLEED', 'DIAGNOSIS_PULMONARY EDEMA, MI', 'BMI_52,1300010681152', 'BMI_19,7900009155273', 'DIAGNOSIS_METASTATIC MELANOMA;BRAIN METASTASIS', 'BMI_33,0699996948242', 'AdmissionDate_2117-08-21', 'BMI_20,8099994659424', 'ETHNICITY_UNKNOWN/NOT SPECIFIED', 'dob_2096-07-25 00:00:00', 'BMI_25,3700008392334', 'DIAGNOSIS_RECURRENT LEFT CAROTID STENOSIS,PRE HYDRATION', 'WeightInKilograms_79,379997253418', 'BMI_32,0999984741211', 'AdmissionDate_2138-06-05', 'DIAGNOSIS_SEPSIS; UTI', 'DIAGNOSIS_CEREBROVASCULAR ACCIDENT', 'AdmissionDate_2155-12-16', 'AdmissionDate_2192-11-20', 'BMI_21,7700004577637', 'BMI_31,8899993896484', 'DIAGNOSIS_ACUTE SUBDURAL HEMATOMA', 'AdmissionDate_2128-03-22', 'AdmissionDate_2127-03-19', 'ADMISSION_LOCATION_PHYS REFERRAL/NORMAL DELI', 'AdmissionDate_2151-09-12', 'ECigaretteUsage_Not at all (right now)', 'BMI_37,7299995422363', 'dob_2072-12-03 00:00:00', 'AdmissionDate_2128-11-04', 'AdmissionDate_2146-07-21', 'WeightInKilograms_57,6100006103516', 'BMI_24,4500007629395', 'HeightInMeters_1,51999998092651', 'DIAGNOSIS_BRADYCARDIA', 'DIAGNOSIS_RENAL CANCER/SDA', 'AdmissionDate_2130-10-06', 'ETHNICITY_ASIAN', 'AdmissionDate_2169-05-06', 'dob_2088-05-05 00:00:00', 'dob_2056-01-27 00:00:00', 'WeightInKilograms_76,1999969482422', 'WeightInKilograms_61,2299995422363', 'BMI_21,1299991607666', 'dob_2053-04-13 00:00:00', 'dob_2041-05-16 00:00:00', 'HeightInMeters_1,92999994754791', 'AdmissionDate_2131-07-26', 'AdmissionDate_2200-03-17', 'dob_2061-04-10 00:00:00', 'DIAGNOSIS_SEIZURE;STATUS EPILEPTICUS', 'BMI_46,8699989318848', 'dob_2082-06-27 00:00:00', 'HeightInMeters_1,60000002384186', 'dob_2097-01-07 00:00:00', 'AdmissionDate_2118-10-06', 'DIAGNOSIS_UTI/PYELONEPHRITIS', 'WeightInKilograms_71,2099990844727', 'DIAGNOSIS_UNSTABLE ANGINA', 'dob_2079-08-17 00:00:00', 'AdmissionDate_2188-02-08', 'TetanusLast10Tdap_Yes, received tetanus shot, but not Tdap', 'WeightInKilograms_99,7900009155273', 'DIAGNOSIS_FAILURE TO THRIVE', 'DIAGNOSIS_NON SMALL CELL CANCER;HYPOXIA', 'dob_2127-06-04 00:00:00', 'dob_2097-11-14 00:00:00', 'DIAGNOSIS_VARICEAL BLEED', 'dob_2081-01-03 00:00:00', 'WeightInKilograms_95,25', 'BMI_35,1500015258789', 'AdmissionDate_2185-03-24', 'DIAGNOSIS_S/P FALL', 'dob_2110-04-02 00:00:00', 'AdmissionDate_2201-08-10', 'AdmissionDate_2145-12-01', 'AdmissionDate_2130-02-04', 'DIAGNOSIS_VF ARREST ', 'DIAGNOSIS_HYPOTENSION', 'MARITAL_STATUS_UNKNOWN (DEFAULT)', 'WeightInKilograms_204,119995117188', 'BMI_31,6599998474121', 'WeightInKilograms_49,9000015258789', 'BMI_25,0900001525879', 'SmokerStatus_Current smoker - now smokes some days', 'AdmissionDate_2132-08-05', 'AdmissionDate_2202-02-15', 'dob_2073-11-22 00:00:00', 'AdmissionDate_2189-09-08', 'BMI_28,2800006866455', 'AdmissionDate_2178-05-14', 'AdmissionDate_2186-07-06', 'dob_2055-07-18 00:00:00', 'BMI_29,1499996185303', 'dob_2073-06-05 00:00:00', 'BMI_36,7299995422363', 'WeightInKilograms_120,199996948242', 'BMI_31,3199996948242', 'BMI_27,3899993896484', 'dob_2097-12-16 00:00:00', 'dob_2108-12-20 00:00:00', 'DIAGNOSIS_PLEURAL EFFUSION', 'DIAGNOSIS_HYPOGLYCEMIA', 'AdmissionDate_2180-02-29', 'BMI_29,0499992370605', 'AdmissionDate_2123-08-23', 'DIAGNOSIS_CHEST PAIN/ CATH', 'ADMISSION_LOCATION_EMERGENCY ROOM ADMIT', 'ETHNICITY_HISPANIC OR LATINO', 'DIAGNOSIS_RENAL FAILIURE-SYNCOPE-HYPERKALEMIA', 'BMI_31,75', 'DIAGNOSIS_TACHYPNEA;TELEMETRY', 'DIAGNOSIS_STATUS POST MOTOR VEHICLE ACCIDENT WITH INJURIES', 'dob_2083-09-20 00:00:00', 'BMI_22,6000003814697', 'BMI_23,4400005340576', 'AdmissionDate_2144-02-09', 'BMI_22,6700000762939', 'WeightInKilograms_81,6500015258789', 'gender_M', 'AdmissionDate_2112-05-28', 'BMI_24,3700008392334', 'DIAGNOSIS_SUBDURAL HEMATOMA/S/P FALL', 'HeightInMeters_1,87999999523163', 'DIAGNOSIS_HEADACHE', 'ETHNICITY_HISPANIC/LATINO - PUERTO RICAN', 'AdmissionDate_2175-10-02', 'HeightInMeters_1,70000004768372', 'dob_1880-02-29 00:00:00', 'WeightInKilograms_54,4300003051758', 'MARITAL_STATUS_WIDOWED', 'AdmissionDate_2200-10-29', 'WeightInKilograms_115,669998168945', 'DIAGNOSIS_ESOPHAGEAL CA/SDA', 'LANGUAGE_MAND', 'AdmissionDate_2110-12-29', 'dob_2063-07-05 00:00:00', 'HeightInMeters_1,9099999666214', 'DIAGNOSIS_ASTHMA/COPD FLARE', 'WeightInKilograms_58,9700012207031', 'WeightInKilograms_83,4599990844727', 'BMI_27,0699996948242', 'AdmissionDate_2124-01-12', 'dob_2038-09-03 00:00:00', 'DIAGNOSIS_PERICARDIAL EFFUSION', 'AdmissionDate_2160-05-04'}"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propretÃ© de la sortie (optionnel)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Simulation de donnÃ©es si aucun fichier n'est chargÃ© ---\n",
    "# REMPLACE CECI PAR TON CHARGEMENT DE DONNÃ‰ES RÃ‰EL\n",
    "try:\n",
    "    # Essaie de charger les donnÃ©es si la variable 'data' existe dÃ©jÃ \n",
    "    # (Adapte cette logique si nÃ©cessaire pour recharger Ã  chaque fois)\n",
    "    if 'data' in locals() or 'data' in globals():\n",
    "        print(\"Utilisation des donnÃ©es prÃ©-chargÃ©es.\")\n",
    "        # Assure-toi que les boolÃ©ens sont bien boolÃ©ens aprÃ¨s le chargement initial si besoin\n",
    "        bool_cols_check = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                           'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "        for col in bool_cols_check:\n",
    "             if col in data.columns and data[col].dtype != bool :\n",
    "                 try:\n",
    "                     # Tentative de conversion flexible (gÃ¨re True/False, 1/0, 'Yes'/'No', etc.)\n",
    "                     map_dict = {True: True, 1: True, 'True': True, 'true': True, 'Yes': True, 'yes': True,\n",
    "                                 False: False, 0: False, 'False': False, 'false': False, 'No': False, 'no': False}\n",
    "                     data[col] = data[col].map(map_dict).fillna(False).astype(bool) # Remplace NaN par False par dÃ©faut\n",
    "                     print(f\"Colonne '{col}' convertie en boolÃ©en.\")\n",
    "                 except Exception as e:\n",
    "                     print(f\"Attention : impossible de convertir la colonne '{col}' en boolÃ©en de maniÃ¨re fiable. Erreur: {e}\")\n",
    "\n",
    "    else:\n",
    "        raise NameError # Force l'exÃ©cution du bloc except\n",
    "except NameError:\n",
    "    print(\"CrÃ©ation de donnÃ©es exemples car 'data' n'est pas dÃ©fini.\")\n",
    "    # ... (garder la crÃ©ation de donnÃ©es exemples si nÃ©cessaire) ...\n",
    "    data = pd.DataFrame({ # Version simplifiÃ©e pour l'exemple\n",
    "        'Age': np.random.randint(20, 85, size=500),\n",
    "        'BMI': np.random.uniform(18, 40, size=500),\n",
    "        'SeverityScore': np.random.uniform(1, 10, size=500),\n",
    "        'AlcoholDrinkers': np.random.choice([True, False], size=500, p=[0.6, 0.4]),\n",
    "        'CovidPos': np.random.choice([True, False], size=500, p=[0.2, 0.8]),\n",
    "        'HadHeartAttack': np.random.choice([True, False], size=500, p=[0.1, 0.9]),\n",
    "        'HadAngina': np.random.choice([True, False], size=500, p=[0.08, 0.92]),\n",
    "        'HadStroke': np.random.choice([True, False], size=500, p=[0.05, 0.95]),\n",
    "        'HadAsthma': np.random.choice([True, False], size=500, p=[0.15, 0.85]),\n",
    "        'HadSkinCancer': np.random.choice([True, False], size=500, p=[0.07, 0.93]),\n",
    "        'HadCOPD': np.random.choice([True, False], size=500, p=[0.06, 0.94]),\n",
    "        'length_of_stay': np.random.poisson(lam=5, size=500) + 1 # Cible (ex: jours)\n",
    "    })\n",
    "    for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']:\n",
    "        data[col] = data[col].astype(bool)\n",
    "\n",
    "# data = pd.read_csv(\"chemin/vers/ton_fichier.csv\") # DÃ©commente pour charger ton fichier\n",
    "\n",
    "# ========= DÃ‰FINITION DE LA FONCTION POUR L'ENCODAGE =========\n",
    "def bool_to_int(X_bool):\n",
    "    \"\"\"\n",
    "    Convertit un DataFrame ou une SÃ©rie de boolÃ©ens en entiers (0 ou 1).\n",
    "    GÃ¨re les Ã©ventuelles valeurs manquantes en les traitant comme False (0).\n",
    "    \"\"\"\n",
    "    # S'assurer que l'entrÃ©e est traitÃ©e correctement (pourrait Ãªtre Series ou DataFrame)\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        return X_bool.fillna(False).astype(int)\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        return X_bool.fillna(False).astype(int)\n",
    "    else: # Si c'est dÃ©jÃ  un array numpy par exemple\n",
    "        return X_bool.astype(int)\n",
    "# ==============================================================\n",
    "\n",
    "# âœ… Liste des colonnes boolÃ©ennes Ã  encoder (assure-toi qu'elles existent)\n",
    "bool_cols = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "             'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD']\n",
    "# VÃ©rifie que toutes les colonnes boolÃ©ennes sont prÃ©sentes dans les donnÃ©es\n",
    "bool_cols = [col for col in bool_cols if col in data.columns]\n",
    "print(f\"Colonnes boolÃ©ennes utilisÃ©es : {bool_cols}\")\n",
    "\n",
    "# == Identification des colonnes numÃ©riques et autres ==\n",
    "target_col = 'length_of_stay'\n",
    "if target_col not in data.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' n'est pas dans le DataFrame.\")\n",
    "\n",
    "# Exclure explicitement les identifiants s'ils ne sont pas des features utiles\n",
    "id_cols = ['subject_id', 'HADM_ID'] # Adapte si nÃ©cessaire\n",
    "cols_to_drop_from_features = [target_col] + [id for id in id_cols if id in data.columns]\n",
    "\n",
    "X = data.drop(columns=cols_to_drop_from_features)\n",
    "y = data[target_col]\n",
    "\n",
    "# Recalculer les colonnes numÃ©riques aprÃ¨s avoir potentiellement retirÃ© les IDs\n",
    "numerical_cols = [col for col in X.columns if col not in bool_cols and pd.api.types.is_numeric_dtype(X[col])]\n",
    "print(f\"Colonnes numÃ©riques utilisÃ©es : {numerical_cols}\")\n",
    "\n",
    "# VÃ©rifier s'il reste des colonnes non traitÃ©es\n",
    "processed_cols = set(bool_cols + numerical_cols)\n",
    "other_cols = [col for col in X.columns if col not in processed_cols]\n",
    "if other_cols:\n",
    "    print(f\"âš ï¸ Attention : Colonnes potentiellement non traitÃ©es par le prÃ©processeur : {other_cols}\")\n",
    "    # DÃ©cide quoi faire : les ignorer ('remainder='drop'') ou les passer ('passthrough')\n",
    "    # Si elles sont catÃ©gorielles et non boolÃ©ennes, il faudrait ajouter un OneHotEncoder etc.\n",
    "\n",
    "# âœ… 2. Pipeline pour l'encodage boolÃ©en (utilisant la fonction dÃ©finie)\n",
    "# Utiliser la fonction nommÃ©e ici ! validate=False est souvent utile avec pandas\n",
    "bool_encoder = FunctionTransformer(bool_to_int, validate=False)\n",
    "\n",
    "# âœ… 3. PrÃ©processeur : encodage boolÃ©en + standardisation numÃ©rique\n",
    "transformers = []\n",
    "if bool_cols:\n",
    "    transformers.append(('bool', bool_encoder, bool_cols))\n",
    "if numerical_cols:\n",
    "    # S'assurer qu'il n'y a pas de boolÃ©ens par erreur dans les numÃ©riques\n",
    "    numerical_cols_strict = [c for c in numerical_cols if X[c].dtype != bool]\n",
    "    if numerical_cols_strict:\n",
    "         transformers.append(('num', StandardScaler(), numerical_cols_strict))\n",
    "    else:\n",
    "        print(\"Aucune colonne numÃ©rique stricte trouvÃ©e pour StandardScaler.\")\n",
    "else:\n",
    "    print(\"Aucune colonne numÃ©rique trouvÃ©e pour StandardScaler.\")\n",
    "\n",
    "\n",
    "if not transformers:\n",
    "     raise ValueError(\"Aucune transformation dÃ©finie (ni boolÃ©enne, ni numÃ©rique). VÃ©rifiez vos types de colonnes.\")\n",
    "\n",
    "# Choisir comment gÃ©rer les colonnes restantes ('other_cols')\n",
    "# 'drop' : les ignorer\n",
    "# 'passthrough' : les garder telles quelles (peut causer des erreurs si le modÃ¨le ne les gÃ¨re pas)\n",
    "remainder_strategy = 'drop' if other_cols else 'passthrough'\n",
    "if other_cols:\n",
    "    print(f\"Les colonnes {other_cols} seront ignorÃ©es (remainder='drop').\")\n",
    "\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers,\n",
    "    remainder=remainder_strategy # Ignorer les colonnes non spÃ©cifiÃ©es\n",
    ")\n",
    "\n",
    "# âœ… 4. Pipeline complet avec RandomForest\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "# âœ… 5. Split des donnÃ©es\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Afficher les types de donnÃ©es AVANT l'entraÃ®nement pour vÃ©rifier\n",
    "print(\"\\nTypes de donnÃ©es dans X_train AVANT le pipeline :\")\n",
    "print(X_train.info()) # Devrait montrer des boolÃ©ens et des numÃ©riques/objets bruts\n",
    "\n",
    "# âœ… 6. Recherche alÃ©atoire de paramÃ¨tres\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 500),\n",
    "    'model__max_depth': randint(5, 30),\n",
    "    'model__min_samples_split': randint(2, 10),\n",
    "    'model__min_samples_leaf': randint(1, 10),\n",
    "    # max_features='auto' est obsolÃ¨te, utiliser 'sqrt' ou None (ou un float)\n",
    "    'model__max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions=param_dist,\n",
    "                                   n_iter=10, # RÃ©duit pour l'exemple, augmente pour une vraie recherche\n",
    "                                   cv=5,\n",
    "                                   scoring='neg_mean_squared_error', # MÃ©trique pour l'optimisation\n",
    "                                   n_jobs=-1,\n",
    "                                   random_state=42,\n",
    "                                   verbose=1 # RÃ©duit la verbositÃ© pour l'exemple\n",
    "                                  )\n",
    "\n",
    "print(\"\\nðŸš€ DÃ©but de l'entraÃ®nement et de la recherche d'hyperparamÃ¨tres...\")\n",
    "# âœ… 7. EntraÃ®nement\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"âœ… EntraÃ®nement terminÃ©.\")\n",
    "\n",
    "# âœ… 8. Ã‰valuation\n",
    "best_model = random_search.best_estimator_ # C'est le *pipeline complet* entraÃ®nÃ©\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"\\n--- Ã‰valuation du Meilleur ModÃ¨le ---\")\n",
    "print(f\"Meilleurs paramÃ¨tres trouvÃ©s : {random_search.best_params_}\")\n",
    "# Utiliser np.sqrt pour obtenir la RMSE (Root Mean Squared Error), souvent plus interprÃ©table\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : {rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ Score RÂ² : {r2_score(y_test, y_pred):.4f}\")\n",
    "\n",
    "# âœ… 9. Sauvegarde du pipeline complet pour le dÃ©ploiement\n",
    "model_filename = 'random_forest_length_stay_pipeline.joblib'\n",
    "try:\n",
    "    joblib.dump(best_model, model_filename)\n",
    "    print(f\"\\nâœ… Pipeline complet sauvegardÃ© sous : {model_filename}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "    print(\"   VÃ©rifiez les Ã©tapes du pipeline et les objets qu'il contient.\")\n",
    "\n",
    "\n",
    "# --- Exemple de chargement et prÃ©diction (Simulation de dÃ©ploiement) ---\n",
    "print(\"\\n--- Simulation de DÃ©ploiement ---\")\n",
    "# Charger le pipeline sauvegardÃ© (seulement si la sauvegarde a rÃ©ussi)\n",
    "if 'model_filename' in locals() and joblib.os.path.exists(model_filename):\n",
    "    loaded_pipeline = joblib.load(model_filename)\n",
    "    print(\"Pipeline chargÃ©.\")\n",
    "\n",
    "    # CrÃ©er de nouvelles donnÃ©es brutes (format attendu par le pipeline)\n",
    "    # Doit avoir les MÃŠMES colonnes que X_train (sauf la cible et les IDs exclus)\n",
    "    # Utilise les colonnes de X pour crÃ©er l'exemple\n",
    "    example_data_dict = {}\n",
    "    for col in X.columns:\n",
    "        if col in bool_cols:\n",
    "            example_data_dict[col] = [True, False] # Exemple boolÃ©en\n",
    "        elif col in numerical_cols_strict: # Utilise la liste des numÃ©riques traitÃ©s\n",
    "             # Prend des valeurs exemples (moyenne, mÃ©diane, ou juste des valeurs plausibles)\n",
    "             example_data_dict[col] = [X[col].mean(), X[col].median()]\n",
    "        # Les colonnes 'other_cols' sont ignorÃ©es si remainder='drop'\n",
    "\n",
    "    new_data = pd.DataFrame(example_data_dict)\n",
    "\n",
    "    # Assurer les bons types boolÃ©ens pour les colonnes boolÃ©ennes\n",
    "    for col in bool_cols:\n",
    "        if col in new_data.columns:\n",
    "             new_data[col] = new_data[col].astype(bool)\n",
    "\n",
    "    print(\"\\nNouvelles donnÃ©es brutes (format entrÃ©e attendu) :\")\n",
    "    print(new_data)\n",
    "    #print(\"\\nTypes de donnÃ©es des nouvelles donnÃ©es:\")\n",
    "    #print(new_data.info())\n",
    "\n",
    "\n",
    "    # Faire des prÃ©dictions avec le pipeline chargÃ©\n",
    "    # Le pipeline gÃ¨re l'encodage et la standardisation automatiquement !\n",
    "    new_predictions = loaded_pipeline.predict(new_data)\n",
    "    print(f\"\\nPrÃ©dictions pour les nouvelles donnÃ©es : {new_predictions}\")\n",
    "else:\n",
    "    print(\"Le fichier du pipeline n'a pas Ã©tÃ© trouvÃ© ou n'a pas pu Ãªtre sauvegardÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c55a923a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = joblib.load('best_rf_model.pkl')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3a37f7f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… DonnÃ©es chargÃ©es depuis 'datasejour.csv'. Shape: (129, 47)\n",
      "âœ… Colonne 'Age' crÃ©Ã©e.\n",
      "âœ… Features 'AdmissionYear', 'AdmissionMonth', 'AdmissionDayOfWeek' crÃ©Ã©es.\n",
      "\n",
      "--- Identification des Colonnes ---\n",
      "Cible: length_of_stay\n",
      "IDs Ã  dropper: ['subject_id', 'HADM_ID']\n",
      "BoolÃ©ennes traitÃ©es: ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
      "CatÃ©gorielles traitÃ©es: ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE', 'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes', 'TetanusLast10Tdap']\n",
      "NumÃ©riques traitÃ©es: ['AdmissionYear', 'AdmissionDayOfWeek', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost', 'AdmissionMonth', 'Age']\n",
      "âš ï¸ Attention : Colonnes non traitÃ©es (seront ignorÃ©es car remainder='drop'): ['HeightInMeters', 'WeightInKilograms', 'BMI']\n",
      "\n",
      "--- Dimensions des DonnÃ©es ---\n",
      "X_train shape: (103, 41)\n",
      "X_test shape: (26, 41)\n",
      "y_train shape: (103,)\n",
      "y_test shape: (26,)\n",
      "PrÃ©processeur: Pipeline boolÃ©en ajoutÃ©.\n",
      "PrÃ©processeur: Pipeline numÃ©rique ajoutÃ©.\n",
      "PrÃ©processeur: Pipeline catÃ©goriel ajoutÃ©.\n",
      "\n",
      "--- Structure du Pipeline Complet ---\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('bool',\n",
      "                                                  Pipeline(steps=[('to_int',\n",
      "                                                                   FunctionTransformer(func=<function flexible_bool_to_int at 0x000001F17B74FB00>))]),\n",
      "                                                  ['AlcoholDrinkers',\n",
      "                                                   'CovidPos', 'HadHeartAttack',\n",
      "                                                   'HadAngina', 'HadStroke',\n",
      "                                                   'HadAsthma', 'HadSkinCancer',\n",
      "                                                   'HadCOPD',\n",
      "                                                   'HadDepressiveDisorder',\n",
      "                                                   'HadKidneyDisease',\n",
      "                                                   'HadArthritis',\n",
      "                                                   'Dea...\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['gender', 'ETHNICITY',\n",
      "                                                   'MARITAL_STATUS',\n",
      "                                                   'DIAGNOSIS',\n",
      "                                                   'ADMISSION_LOCATION',\n",
      "                                                   'ADMISSION_TYPE', 'LANGUAGE',\n",
      "                                                   'SmokerStatus',\n",
      "                                                   'ECigaretteUsage',\n",
      "                                                   'HadDiabetes',\n",
      "                                                   'TetanusLast10Tdap'])])),\n",
      "                ('model', RandomForestRegressor(n_jobs=-1, random_state=42))])\n",
      "\n",
      "ðŸš€ DÃ©but de RandomizedSearchCV (20 itÃ©rations)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "âœ… RandomizedSearchCV terminÃ©.\n",
      "\n",
      "ðŸ† Meilleurs paramÃ¨tres trouvÃ©s : {'model__max_depth': 33, 'model__max_features': None, 'model__min_samples_leaf': 1, 'model__min_samples_split': 10, 'model__n_estimators': 426}\n",
      "Meilleur score CV (Negative RMSE) : -5.2588\n",
      "\n",
      "--- Ã‰valuation Finale sur l'Ensemble de Test ---\n",
      "ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : 8.9107\n",
      "ðŸ“ˆ Score RÂ² : 0.8508\n",
      "\n",
      "âœ… Pipeline complet sauvegardÃ© sous : 'sejour_prediction_pipeline_v1.joblib'\n",
      "\n",
      "--- Simulation de DÃ©ploiement ---\n",
      "Pipeline chargÃ© avec succÃ¨s.\n",
      "\n",
      "Exemple de nouvelles donnÃ©es brutes (2 premiÃ¨res lignes de X_test):\n",
      "    DifficultyConcentrating  HadStroke  BlindOrVisionDifficulty  \\\n",
      "55                        0          0                        0   \n",
      "40                        1          0                        0   \n",
      "\n",
      "    HadSkinCancer  procedure_cost  HIVTesting  HadAngina ADMISSION_TYPE  \\\n",
      "55              0          7500.0           0          0      EMERGENCY   \n",
      "40              0         10500.0           1          0      EMERGENCY   \n",
      "\n",
      "   MARITAL_STATUS  AdmissionDayOfWeek  facility_cost  HadDepressiveDisorder  \\\n",
      "55         SINGLE                   5         6000.0                      0   \n",
      "40        WIDOWED                   4        17000.0                      1   \n",
      "\n",
      "    HadAsthma ETHNICITY  Age  HadCOPD  DifficultyWalking  \\\n",
      "55          0     WHITE   67        0                  0   \n",
      "40          1       NaN   83        1                  1   \n",
      "\n",
      "                   DIAGNOSIS LANGUAGE  AdmissionMonth  ChestScan  \\\n",
      "55                 PNEUMONIA     ENGL               8          1   \n",
      "40  CONGESTIVE HEART FAILURE      NaN               1          0   \n",
      "\n",
      "    DeafOrHardOfHearing  HadHeartAttack  medication_cost  AlcoholDrinkers  \\\n",
      "55                    0               0          42000.0                0   \n",
      "40                    0               0         116450.0                0   \n",
      "\n",
      "    HadKidneyDisease                            ECigaretteUsage  \\\n",
      "55                 0  Never used e-cigarettes in my entire life   \n",
      "40                 1  Never used e-cigarettes in my entire life   \n",
      "\n",
      "    DifficultyDressingBathing  total_cost  AdmissionYear  DifficultyErrands  \\\n",
      "55                          0    106400.0           2130                  0   \n",
      "40                          0    228350.0           2180                  1   \n",
      "\n",
      "    CovidPos  lab_test_cost  SmokerStatus  HadArthritis gender HadDiabetes  \\\n",
      "55         1        50900.0  Never smoked             0      F         Yes   \n",
      "40         0        84400.0  Never smoked             1      F          No   \n",
      "\n",
      "    FluVaxLast12    ADMISSION_LOCATION  \\\n",
      "55             0  EMERGENCY ROOM ADMIT   \n",
      "40             0  EMERGENCY ROOM ADMIT   \n",
      "\n",
      "                                    TetanusLast10Tdap  PneumoVaxEver  \n",
      "55  No, did not receive any tetanus shot in the pa...              0  \n",
      "40                                 Yes, received Tdap              0  \n",
      "Shape des nouvelles donnÃ©es: (2, 41)\n",
      "\n",
      "ðŸ“Š PrÃ©dictions pour les nouvelles donnÃ©es : [ 5.90758191 16.12328505]\n",
      "\n",
      "Comparaison Vraie Valeur vs PrÃ©diction:\n",
      "    Vraie Valeur  PrÃ©diction\n",
      "55             6    5.907582\n",
      "40            17   16.123285\n",
      "\n",
      "ðŸ Script terminÃ©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propretÃ© de la sortie\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None # DÃ©sactiver avertissement pour copie\n",
    "\n",
    "# --- 1. Chargement des DonnÃ©es Brutes ---\n",
    "# REMPLACE CECI par le chemin correct vers ton fichier\n",
    "file_path = 'datasejour.csv'\n",
    "try:\n",
    "    data = pd.read_csv(file_path)\n",
    "    print(f\"âœ… DonnÃ©es chargÃ©es depuis '{file_path}'. Shape: {data.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Erreur: Le fichier '{file_path}' n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "    # Tu pourrais ajouter exit() ici ou un exemple de donnÃ©es pour continuer\n",
    "    # CrÃ©ation de donnÃ©es exemples trÃ¨s basiques si fichier non trouvÃ©\n",
    "    print(\"CrÃ©ation de donnÃ©es exemples...\")\n",
    "    data = pd.DataFrame({\n",
    "        'dob': ['1965-03-10', '1980-11-22', '1950-01-15', None, '1972-07-01'],\n",
    "        'AdmissionDate': ['2023-04-15', '2023-05-01', '2023-05-10', '2023-05-12', '2023-05-18'],\n",
    "        'AlcoholDrinkers': [True, False, True, False, True],\n",
    "        'HadHeartAttack': [False, False, True, False, False],\n",
    "        'gender': ['M', 'F', 'F', 'M', 'M'],\n",
    "        'ETHNICITY': ['WHITE', 'ASIAN', 'WHITE', 'BLACK/AFRICAN AMERICAN', 'UNKNOWN/NOT SPECIFIED'],\n",
    "        'total_cost': [15000, 25000, 50000, 10000, 30000],\n",
    "        'HeightInMeters': [1.75, 1.62, 1.58, 1.80, 1.70],\n",
    "        'WeightInKilograms': [80.5, 65.0, 75.3, 90.1, 70.0],\n",
    "        'length_of_stay': [5, 10, 15, 3, 8] # Cible\n",
    "    })\n",
    "    # Ajout d'autres colonnes bool et cat pour correspondre aux listes plus bas\n",
    "    data['CovidPos'] = [False]*5\n",
    "    data['HadAngina'] = [False]*5\n",
    "    data['HadStroke'] = [False]*5\n",
    "    data['HadAsthma'] = [False]*5\n",
    "    data['HadSkinCancer'] = [False]*5\n",
    "    data['HadCOPD'] = [False]*5\n",
    "    data['MARITAL_STATUS'] = ['MARRIED', 'SINGLE', 'WIDOWED', 'SINGLE', 'MARRIED']\n",
    "    data['DIAGNOSIS'] = ['PNEUMONIA', 'CHF', 'STROKE', 'SEPSIS', 'FRACTURE']\n",
    "    data['ADMISSION_LOCATION'] = ['EMERGENCY ROOM ADMIT', 'PHYS REFERRAL/NORMAL DELI', 'EMERGENCY ROOM ADMIT', 'TRANSFER FROM HOSP/EXTRAM', 'EMERGENCY ROOM ADMIT']\n",
    "    data['ADMISSION_TYPE'] = ['EMERGENCY', 'URGENT', 'EMERGENCY', 'EMERGENCY', 'URGENT']\n",
    "    data['LANGUAGE'] = ['ENGLISH', 'SPANISH', 'ENGLISH', 'ENGLISH', 'OTHER']\n",
    "    data['SmokerStatus'] = ['Former smoker', 'Never smoked', 'Current smoker - now smokes some days', 'Never smoked', 'Former smoker']\n",
    "    data['ECigaretteUsage'] = ['Not at all (right now)']*5\n",
    "    data['HadDiabetes'] = ['No, pre-diabetes or borderline diabetes', 'Yes', 'Yes', 'No, pre-diabetes or borderline diabetes', 'No, pre-diabetes or borderline diabetes']\n",
    "    data['TetanusLast10Tdap'] = ['Yes, received Tdap', 'Yes, received tetanus shot but not sure what type', 'Yes, received Tdap', 'Yes, received tetanus shot, but not Tdap', 'Yes, received Tdap']\n",
    "\n",
    "\n",
    "# --- 2. Feature Engineering (Exemple : Dates) ---\n",
    "# ASSURE-TOI QUE LES NOMS 'dob' ET 'AdmissionDate' SONT CORRECTS\n",
    "date_cols = ['dob', 'AdmissionDate']\n",
    "for col in date_cols:\n",
    "    if col in data.columns:\n",
    "        # Convertir en datetime, ignorer les erreurs pour l'instant (seront traitÃ©es par SimpleImputer)\n",
    "        data[col] = pd.to_datetime(data[col], errors='coerce')\n",
    "\n",
    "# CrÃ©er 'Age' et autres features de date si les colonnes existent et sont des datetime\n",
    "if 'AdmissionDate' in data.columns and data['AdmissionDate'].dtype.kind == 'M':\n",
    "    data['AdmissionYear'] = data['AdmissionDate'].dt.year\n",
    "    data['AdmissionMonth'] = data['AdmissionDate'].dt.month\n",
    "    data['AdmissionDayOfWeek'] = data['AdmissionDate'].dt.dayofweek # Lundi=0, Dimanche=6\n",
    "\n",
    "    if 'dob' in data.columns and data['dob'].dtype.kind == 'M':\n",
    "        # Calculer l'Ã¢ge (peut gÃ©nÃ©rer des NaN si dob ou AdmissionDate manquant/invalide)\n",
    "        data['Age'] = data['AdmissionYear'] - data['dob'].dt.year\n",
    "        # GÃ©rer les cas oÃ¹ la date d'admission est avant la date de naissance dans la mÃªme annÃ©e\n",
    "        data.loc[data['AdmissionDate'] < data['dob'], 'Age'] -= 1\n",
    "        print(\"âœ… Colonne 'Age' crÃ©Ã©e.\")\n",
    "    else:\n",
    "         print(\"âš ï¸ Colonne 'dob' non trouvÃ©e ou non convertible en date. 'Age' non crÃ©Ã©e.\")\n",
    "    print(\"âœ… Features 'AdmissionYear', 'AdmissionMonth', 'AdmissionDayOfWeek' crÃ©Ã©es.\")\n",
    "\n",
    "else:\n",
    "     print(\"âš ï¸ Colonne 'AdmissionDate' non trouvÃ©e ou non convertible en date. Features de date non crÃ©Ã©es.\")\n",
    "\n",
    "# --- 3. Identification des Colonnes par Type (APRÃˆS Feature Engineering) ---\n",
    "\n",
    "# Colonne Cible\n",
    "target_col = 'length_of_stay'\n",
    "if target_col not in data.columns:\n",
    "    raise ValueError(f\"La colonne cible '{target_col}' n'est pas dans le DataFrame.\")\n",
    "\n",
    "# Colonnes ID Ã  supprimer (Adapte si nÃ©cessaire)\n",
    "id_cols_to_drop = ['subject_id', 'HADM_ID']\n",
    "id_cols_to_drop = [col for col in id_cols_to_drop if col in data.columns]\n",
    "\n",
    "# Colonnes boolÃ©ennes originales (vÃ©rifie les noms !)\n",
    "# Ces colonnes doivent contenir True/False ou 1/0 ou 'Yes'/'No' etc. dans le CSV brut\n",
    "bool_cols_original = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                      'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
    "                      'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', # Ces derniÃ¨res Ã©taient numÃ©riques avant ? Si elles sont Oui/Non, elles sont boolÃ©ennes\n",
    "                      'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating',\n",
    "                      'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands',\n",
    "                      'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] # Idem\n",
    "bool_cols = [col for col in bool_cols_original if col in data.columns]\n",
    "\n",
    "# Colonnes CatÃ©gorielles (vÃ©rifie les noms !)\n",
    "categorical_cols_original = ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS',\n",
    "                             'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE',\n",
    "                             'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes',\n",
    "                             'TetanusLast10Tdap']\n",
    "categorical_cols = [col for col in categorical_cols_original if col in data.columns]\n",
    "\n",
    "# Colonnes NumÃ©riques\n",
    "# Inclut les features crÃ©Ã©es (Age, etc.) et les features numÃ©riques originales\n",
    "# Exclut la cible, les IDs, les boolÃ©ennes et les catÃ©gorielles\n",
    "potential_num_cols = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore').columns\n",
    "numerical_cols = [col for col in potential_num_cols\n",
    "                  if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(data[col])]\n",
    "\n",
    "print(f\"\\n--- Identification des Colonnes ---\")\n",
    "print(f\"Cible: {target_col}\")\n",
    "print(f\"IDs Ã  dropper: {id_cols_to_drop}\")\n",
    "print(f\"BoolÃ©ennes traitÃ©es: {bool_cols}\")\n",
    "print(f\"CatÃ©gorielles traitÃ©es: {categorical_cols}\")\n",
    "print(f\"NumÃ©riques traitÃ©es: {numerical_cols}\")\n",
    "\n",
    "# VÃ©rifier si toutes les colonnes (sauf cible, IDs, dates originales) sont prises en compte\n",
    "all_features = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore').columns\n",
    "processed_features = set(bool_cols + categorical_cols + numerical_cols)\n",
    "unprocessed_cols = [col for col in all_features if col not in processed_features]\n",
    "if unprocessed_cols:\n",
    "    print(f\"âš ï¸ Attention : Colonnes non traitÃ©es (seront ignorÃ©es car remainder='drop'): {unprocessed_cols}\")\n",
    "\n",
    "# --- 4. DÃ©finition de la Fonction d'Encodage BoolÃ©en ---\n",
    "def flexible_bool_to_int(X_bool):\n",
    "    \"\"\"\n",
    "    Convertit diverses reprÃ©sentations de boolÃ©ens (True/False, 1/0, Yes/No)\n",
    "    en entiers (1/0) et gÃ¨re les NaN (en les traitant comme 0/False).\n",
    "    \"\"\"\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        # CrÃ©er une copie pour Ã©viter SettingWithCopyWarning\n",
    "        X_series = X_bool.copy()\n",
    "        # Convertir explicitement les chaÃ®nes courantes en boolÃ©ens\n",
    "        map_dict = {\n",
    "            'yes': True, 'true': True, '1': True, 1: True, True: True,\n",
    "            'no': False, 'false': False, '0': False, 0: False, False: False,\n",
    "            # GÃ©rer les variantes de casse si nÃ©cessaire\n",
    "            'Yes': True, 'True': True,\n",
    "            'No': False, 'False': False\n",
    "        }\n",
    "        # Appliquer le mapping, garder les boolÃ©ens existants, mettre NaN pour le reste\n",
    "        mapped = X_series.map(map_dict)\n",
    "        # Remplir les NaN et les valeurs non mappÃ©es par False, puis convertir en int\n",
    "        return mapped.fillna(False).astype(int)\n",
    "\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        # Appliquer la fonction Ã  chaque colonne\n",
    "        return X_bool.apply(flexible_bool_to_int, axis=0)\n",
    "    else:\n",
    "        # Tenter une conversion directe pour les autres types (ex: numpy array)\n",
    "        try:\n",
    "            return pd.DataFrame(X_bool).fillna(False).astype(int) # Utiliser pandas pour fillna\n",
    "        except: # Si tout Ã©choue, retourner tel quel ou lever une erreur\n",
    "             print(f\"Warning: Type non gÃ©rÃ© {type(X_bool)} dans flexible_bool_to_int\")\n",
    "             return X_bool\n",
    "\n",
    "\n",
    "# --- 5. SÃ©paration Features / Cible et Train/Test Split ---\n",
    "X = data.drop(columns=[target_col] + id_cols_to_drop + date_cols, errors='ignore')\n",
    "# Assurer que seules les colonnes Ã  traiter sont gardÃ©es (si des unprocessed existent)\n",
    "X = X[list(processed_features)] # Garde seulement bool, cat, num\n",
    "y = data[target_col]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n--- Dimensions des DonnÃ©es ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")\n",
    "\n",
    "# --- 6. CrÃ©ation des Pipelines de PrÃ©traitement ---\n",
    "\n",
    "# Pipeline pour les boolÃ©ens (imputation implicite dans la fonction)\n",
    "bool_pipeline = Pipeline(steps=[\n",
    "    ('to_int', FunctionTransformer(flexible_bool_to_int, validate=False))\n",
    "    # Pas besoin d'imputer ici car la fonction gÃ¨re NaN\n",
    "])\n",
    "\n",
    "# Pipeline pour les numÃ©riques (imputation + mise Ã  l'Ã©chelle)\n",
    "numerical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')), # Impute les NaN avant scaling\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# Pipeline pour les catÃ©gorielles (imputation + One-Hot Encoding)\n",
    "categorical_pipeline = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')), # Ou 'constant', fill_value='Missing'\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False)) # Ignore les catÃ©gories inconnues lors de la prÃ©diction\n",
    "])\n",
    "\n",
    "# --- 7. CrÃ©ation du PrÃ©processeur Global (ColumnTransformer) ---\n",
    "# CrÃ©e le prÃ©processeur seulement avec les types de colonnes qui existent\n",
    "transformers_list = []\n",
    "if bool_cols:\n",
    "    transformers_list.append(('bool', bool_pipeline, bool_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline boolÃ©en ajoutÃ©.\")\n",
    "if numerical_cols:\n",
    "    transformers_list.append(('num', numerical_pipeline, numerical_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline numÃ©rique ajoutÃ©.\")\n",
    "if categorical_cols:\n",
    "    transformers_list.append(('cat', categorical_pipeline, categorical_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline catÃ©goriel ajoutÃ©.\")\n",
    "\n",
    "if not transformers_list:\n",
    "    raise ValueError(\"Aucun type de colonne (bool, num, cat) n'a Ã©tÃ© trouvÃ© pour le prÃ©traitement.\")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers_list,\n",
    "    remainder='drop' # Important: Ignorer les colonnes non spÃ©cifiÃ©es\n",
    ")\n",
    "\n",
    "# --- 8. CrÃ©ation du Pipeline Complet (PrÃ©processeur + ModÃ¨le) ---\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1)) # n_jobs=-1 pour utiliser tous les CPU\n",
    "])\n",
    "\n",
    "print(\"\\n--- Structure du Pipeline Complet ---\")\n",
    "print(full_pipeline)\n",
    "\n",
    "# --- 9. Recherche d'HyperparamÃ¨tres (RandomizedSearchCV) ---\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 600),       # Nombre d'arbres\n",
    "    'model__max_depth': randint(5, 40),             # Profondeur max de chaque arbre\n",
    "    'model__min_samples_split': randint(2, 15),     # Nb min d'Ã©chantillons pour splitter un noeud\n",
    "    'model__min_samples_leaf': randint(1, 15),      # Nb min d'Ã©chantillons dans une feuille\n",
    "    'model__max_features': ['sqrt', 'log2', 0.6, 0.8, None] # % de features Ã  considÃ©rer (auto est obsolÃ¨te) / None = toutes\n",
    "}\n",
    "\n",
    "# RÃ©duire n_iter pour un test rapide, augmenter (ex: 50, 100) pour une recherche sÃ©rieuse\n",
    "n_iterations = 20 # Nombre d'itÃ©rations de la recherche alÃ©atoire\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    full_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iterations,\n",
    "    cv=5, # 5-fold cross-validation\n",
    "    scoring='neg_root_mean_squared_error', # Optimiser pour minimiser la RMSE (nÃ©gative car Scikit-learn maximise)\n",
    "    n_jobs=-1, # Utiliser tous les CPU disponibles\n",
    "    random_state=42,\n",
    "    verbose=1 # Afficher la progression\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸš€ DÃ©but de RandomizedSearchCV ({n_iterations} itÃ©rations)...\")\n",
    "# EntraÃ®ner sur les donnÃ©es d'entraÃ®nement BRUTES (le pipeline gÃ¨re le prÃ©proc)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"âœ… RandomizedSearchCV terminÃ©.\")\n",
    "\n",
    "# --- 10. Ã‰valuation du Meilleur ModÃ¨le ---\n",
    "best_pipeline = random_search.best_estimator_\n",
    "print(f\"\\nðŸ† Meilleurs paramÃ¨tres trouvÃ©s : {random_search.best_params_}\")\n",
    "print(f\"Meilleur score CV (Negative RMSE) : {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Faire des prÃ©dictions sur l'ensemble de test BRUT\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les mÃ©triques\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Ã‰valuation Finale sur l'Ensemble de Test ---\")\n",
    "print(f\"ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : {final_rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ Score RÂ² : {final_r2:.4f}\")\n",
    "\n",
    "# --- 11. Sauvegarde du Pipeline Complet EntraÃ®nÃ© ---\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "try:\n",
    "    joblib.dump(best_pipeline, pipeline_filename)\n",
    "    print(f\"\\nâœ… Pipeline complet sauvegardÃ© sous : '{pipeline_filename}'\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nâŒ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "\n",
    "\n",
    "# --- 12. Simulation de DÃ©ploiement (Chargement et PrÃ©diction sur DonnÃ©es Brutes) ---\n",
    "print(\"\\n--- Simulation de DÃ©ploiement ---\")\n",
    "# S'assurer que le fichier existe avant de charger\n",
    "if 'pipeline_filename' in locals() and joblib.os.path.exists(pipeline_filename):\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(\"Pipeline chargÃ© avec succÃ¨s.\")\n",
    "\n",
    "    # CrÃ©er de nouvelles donnÃ©es brutes (doivent avoir les MÃŠMES colonnes que X_train)\n",
    "    # Utilisons quelques lignes de X_test comme exemple facile\n",
    "    if len(X_test) >= 2:\n",
    "        new_data_raw = X_test.iloc[0:2].copy() # Utilise les donnÃ©es brutes de X_test\n",
    "        print(\"\\nExemple de nouvelles donnÃ©es brutes (2 premiÃ¨res lignes de X_test):\")\n",
    "        # Afficher avec plus de colonnes si possible\n",
    "        pd.set_option('display.max_columns', None)\n",
    "        print(new_data_raw)\n",
    "        pd.reset_option('display.max_columns')\n",
    "        print(f\"Shape des nouvelles donnÃ©es: {new_data_raw.shape}\")\n",
    "\n",
    "        # Faire des prÃ©dictions avec le pipeline chargÃ©\n",
    "        # Le pipeline gÃ¨re TOUT : imputation, encodage bool, OHE, scaling\n",
    "        try:\n",
    "            new_predictions = loaded_pipeline.predict(new_data_raw)\n",
    "            print(f\"\\nðŸ“Š PrÃ©dictions pour les nouvelles donnÃ©es : {new_predictions}\")\n",
    "\n",
    "            # Afficher les prÃ©dictions Ã  cÃ´tÃ© des vraies valeurs pour comparaison\n",
    "            comparison = pd.DataFrame({'Vraie Valeur': y_test.iloc[0:2], 'PrÃ©diction': new_predictions})\n",
    "            print(\"\\nComparaison Vraie Valeur vs PrÃ©diction:\")\n",
    "            print(comparison)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"\\nâŒ Erreur lors de la prÃ©diction sur les nouvelles donnÃ©es : {e}\")\n",
    "            # Afficher les colonnes attendues vs fournies peut aider au dÃ©bogage\n",
    "            try:\n",
    "                expected_cols = loaded_pipeline.named_steps['preprocessing']._feature_names_in\n",
    "                print(f\"Colonnes attendues par le prÃ©processeur: {expected_cols}\")\n",
    "            except AttributeError:\n",
    "                print(\"Impossible de rÃ©cupÃ©rer les noms de colonnes attendues du prÃ©processeur.\")\n",
    "            print(f\"Colonnes fournies: {new_data_raw.columns.tolist()}\")\n",
    "\n",
    "    else:\n",
    "        print(\"X_test contient moins de 2 lignes, impossible de crÃ©er un exemple de donnÃ©es.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Le fichier pipeline '{pipeline_filename}' n'a pas Ã©tÃ© trouvÃ© ou n'a pas pu Ãªtre sauvegardÃ©.\")\n",
    "\n",
    "print(\"\\nðŸ Script terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "856c9802",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline chargÃ© depuis 'sejour_prediction_pipeline_v1.joblib'.\n",
      "\n",
      "Le modÃ¨le attend 41 features en entrÃ©e.\n",
      "\n",
      "--- Veuillez saisir les valeurs pour le nouveau patient ---\n",
      "Entrez la valeur pour 'DifficultyConcentrating' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadStroke' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'BlindOrVisionDifficulty' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadSkinCancer' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'procedure_cost' (nombre): 3000.0\n",
      "Entrez la valeur pour 'HIVTesting' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAngina' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'ADMISSION_TYPE' (texte, ex: WHITE, MARRIED, EMERGENCY): EMERGENCY\n",
      "Entrez la valeur pour 'MARITAL_STATUS' (texte, ex: WHITE, MARRIED, EMERGENCY): DIVORCED\n",
      "Entrez la valeur pour 'AdmissionDayOfWeek' (nombre): 2\n",
      "Entrez la valeur pour 'facility_cost' (nombre): 8000.0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 130\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    126\u001b[0m      \u001b[38;5;66;03m# Si on n'a pas pu dÃ©terminer, on demande juste la valeur\u001b[39;00m\n\u001b[0;32m    127\u001b[0m      prompt_text \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m--> 130\u001b[0m value_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(prompt_text)\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[0;32m    132\u001b[0m \u001b[38;5;66;03m# GÃ©rer les valeurs vides (pourrait Ãªtre traitÃ© comme NaN)\u001b[39;00m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value_str:\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[0;32m   1203\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[0;32m   1204\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   1205\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1206\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   1207\u001b[0m )\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split # NÃ©cessaire si on recharge X_test/y_test\n",
    "import warnings\n",
    "from datetime import datetime # Si des dates sont utilisÃ©es pour l'Ã¢ge etc.\n",
    "\n",
    "# Ignorer les avertissements pour la propretÃ©\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes donnÃ©es BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "id_cols_to_drop_original = ['subject_id', 'HADM_ID'] # IDs Ã  ignorer\n",
    "date_cols_original = ['dob', 'AdmissionDate'] # Dates utilisÃ©es pour crÃ©er des features\n",
    "\n",
    "# --- 2. Charger le Pipeline EntraÃ®nÃ© ---\n",
    "try:\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(f\"âœ… Pipeline chargÃ© depuis '{pipeline_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Erreur: Le fichier pipeline '{pipeline_filename}' n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "    print(\"Assure-toi d'avoir exÃ©cutÃ© le script d'entraÃ®nement et de sauvegarde d'abord.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors du chargement du pipeline: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Obtenir les Noms des Features Attendues par le Pipeline (avant prÃ©-traitement) ---\n",
    "# Normalement, ces features sont les colonnes de X utilisÃ©es lors de l'entraÃ®nement\n",
    "# Essayons de les rÃ©cupÃ©rer du pipeline si possible, sinon on devra les lister manuellement\n",
    "# (Note: _feature_names_in est disponible dans les versions rÃ©centes de Scikit-learn)\n",
    "try:\n",
    "    # AccÃ©der au ColumnTransformer dans le pipeline\n",
    "    preprocessor = loaded_pipeline.named_steps['preprocessing']\n",
    "    # RÃ©cupÃ©rer les noms de features d'entrÃ©e attendus par le prÃ©processeur\n",
    "    expected_feature_names = preprocessor.feature_names_in_\n",
    "    print(f\"\\nLe modÃ¨le attend {len(expected_feature_names)} features en entrÃ©e.\")\n",
    "    # print(\"Features attendues:\", expected_feature_names) # DÃ©commente pour voir la liste complÃ¨te\n",
    "except AttributeError:\n",
    "    print(\"\\nâš ï¸ Impossible de rÃ©cupÃ©rer automatiquement les noms de features attendus.\")\n",
    "    print(\"   Tu devras t'assurer que les features demandÃ©es ci-dessous correspondent\")\n",
    "    print(\"   exactement Ã  celles utilisÃ©es lors de l'entraÃ®nement (colonnes de X_train).\")\n",
    "    # !! SOLUTION DE REPLI : LISTER MANUELLEMENT LES FEATURES ICI !!\n",
    "    # expected_feature_names = ['Age', 'total_cost', 'gender', 'ETHNICITY', ... ] # Liste complÃ¨te\n",
    "    print(\"   LE SCRIPT VA CONTINUER, MAIS VÃ‰RIFIE BIEN LES FEATURES DEMANDÃ‰ES !\")\n",
    "    # Pour l'exemple, on va essayer de reconstruire X Ã  partir des donnÃ©es brutes\n",
    "    # et prendre ses colonnes comme rÃ©fÃ©rence (moins fiable si le script d'entraÃ®nement a changÃ©)\n",
    "    try:\n",
    "        temp_data = pd.read_csv(original_data_file)\n",
    "        # RecrÃ©er les features de date pour avoir Age etc si nÃ©cessaire\n",
    "        for col in date_cols_original:\n",
    "             if col in temp_data.columns:\n",
    "                 temp_data[col] = pd.to_datetime(temp_data[col], errors='coerce')\n",
    "        if 'AdmissionDate' in temp_data.columns and temp_data['AdmissionDate'].dtype.kind == 'M':\n",
    "            temp_data['AdmissionYear'] = temp_data['AdmissionDate'].dt.year\n",
    "            temp_data['AdmissionMonth'] = temp_data['AdmissionDate'].dt.month\n",
    "            temp_data['AdmissionDayOfWeek'] = temp_data['AdmissionDate'].dt.dayofweek\n",
    "            if 'dob' in temp_data.columns and temp_data['dob'].dtype.kind == 'M':\n",
    "                 temp_data['Age'] = temp_data['AdmissionYear'] - temp_data['dob'].dt.year\n",
    "                 temp_data.loc[temp_data['AdmissionDate'] < temp_data['dob'], 'Age'] -= 1\n",
    "\n",
    "        temp_X = temp_data.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "        # Tenter d'identifier les colonnes comme dans le script d'entraÃ®nement pour filtrer X\n",
    "        bool_cols = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in temp_X.columns]\n",
    "        categorical_cols = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in temp_X.columns]\n",
    "        potential_num_cols = temp_X.columns\n",
    "        numerical_cols = [col for col in potential_num_cols if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(temp_X[col])]\n",
    "        processed_features_list = bool_cols + categorical_cols + numerical_cols\n",
    "        expected_feature_names = [col for col in temp_X.columns if col in processed_features_list] # Garde l'ordre original\n",
    "        if not expected_feature_names:\n",
    "             print(\"âŒ Impossible de dÃ©terminer les features attendues. ArrÃªt.\")\n",
    "             exit()\n",
    "        print(f\"   Utilisation des features dÃ©terminÃ©es Ã  partir du fichier brut: {len(expected_feature_names)} features.\")\n",
    "\n",
    "    except Exception as e:\n",
    "         print(f\"âŒ Erreur lors de la tentative de dÃ©termination des features: {e}\")\n",
    "         exit()\n",
    "\n",
    "\n",
    "# --- 4. Saisie Manuelle des Valeurs des Features ---\n",
    "print(\"\\n--- Veuillez saisir les valeurs pour le nouveau patient ---\")\n",
    "input_data = {}\n",
    "for feature in expected_feature_names:\n",
    "    while True: # Boucle jusqu'Ã  obtenir une entrÃ©e valide\n",
    "        try:\n",
    "            # DÃ©terminer le type de la colonne (approximatif basÃ© sur le nom/catÃ©gorie connue)\n",
    "            # IdÃ©alement, on aurait les types exacts sauvegardÃ©s\n",
    "            prompt_text = f\"Entrez la valeur pour '{feature}'\"\n",
    "\n",
    "            # Identifier le type probable pour adapter le prompt/conversion\n",
    "            col_type = \"unknown\"\n",
    "            # Charger les donnÃ©es originales juste pour vÃ©rifier le type si nÃ©cessaire (coÃ»teux)\n",
    "            # temp_col_type = X_train[feature].dtype # NÃ©cessiterait X_train ici\n",
    "\n",
    "            # Simplification : demander comme texte, convertir si possible en nombre\n",
    "            # Pour les boolÃ©ens, demander 'True'/'False' ou '1'/'0' ou 'Yes'/'No'\n",
    "            # Pour les catÃ©gorielles, juste le texte\n",
    "            # Pour les numÃ©riques, un nombre\n",
    "\n",
    "            # On pourrait essayer d'infÃ©rer le type mais c'est risquÃ©.\n",
    "            # Le plus sÃ»r est de demander en texte et laisser le pipeline gÃ©rer\n",
    "            # via flexible_bool_to_int, OneHotEncoder (qui prend texte), et StandardScaler (qui Ã©chouera si texte non convertible)\n",
    "            # => MAIS StandardScaler a besoin de nombres ! Il faut convertir AVANT.\n",
    "\n",
    "            # Tentative d'infÃ©rer le type pour guider l'utilisateur\n",
    "            is_numeric = False\n",
    "            is_boolean = False # Pour notre fonction custom\n",
    "            is_categorical = False\n",
    "\n",
    "            # Utilisons les listes dÃ©finies dans le script d'entraÃ®nement (si on peut les reconstruire)\n",
    "            if 'bool_cols' in locals() and feature in bool_cols:\n",
    "                 is_boolean = True\n",
    "                 prompt_text += \" (ex: True/False, Yes/No, 1/0): \"\n",
    "            elif 'categorical_cols' in locals() and feature in categorical_cols:\n",
    "                 is_categorical = True\n",
    "                 prompt_text += \" (texte, ex: WHITE, MARRIED, EMERGENCY): \"\n",
    "            elif 'numerical_cols' in locals() and feature in numerical_cols:\n",
    "                 is_numeric = True\n",
    "                 prompt_text += \" (nombre): \"\n",
    "            else:\n",
    "                 # Si on n'a pas pu dÃ©terminer, on demande juste la valeur\n",
    "                 prompt_text += \": \"\n",
    "\n",
    "\n",
    "            value_str = input(prompt_text).strip()\n",
    "\n",
    "            # GÃ©rer les valeurs vides (pourrait Ãªtre traitÃ© comme NaN)\n",
    "            if not value_str:\n",
    "                 input_data[feature] = np.nan # Le pipeline doit gÃ©rer les NaN via Imputer\n",
    "                 print(f\"   -> Valeur manquante (NaN) enregistrÃ©e pour {feature}.\")\n",
    "                 break # Sortir de la boucle while pour cette feature\n",
    "\n",
    "            # Conversion de type basÃ©e sur l'infÃ©rence\n",
    "            if is_numeric:\n",
    "                try:\n",
    "                    input_data[feature] = float(value_str.replace(',', '.')) # GÃ©rer virgule dÃ©cimale\n",
    "                except ValueError:\n",
    "                    print(\"âŒ Erreur: Veuillez entrer un nombre valide.\")\n",
    "                    continue # Redemander la mÃªme feature\n",
    "            elif is_boolean:\n",
    "                 # Notre fonction flexible_bool_to_int gÃ¨re diverses entrÃ©es texte/nombre\n",
    "                 # On peut donc stocker la chaÃ®ne ou tenter une conversion basique\n",
    "                 input_data[feature] = value_str # Laisser flexible_bool_to_int faire le travail\n",
    "            elif is_categorical:\n",
    "                 input_data[feature] = value_str # Garder comme texte\n",
    "            else: # Cas \"unknown\"\n",
    "                 # Essayer de convertir en nombre, sinon garder comme texte\n",
    "                 try:\n",
    "                      input_data[feature] = float(value_str.replace(',', '.'))\n",
    "                 except ValueError:\n",
    "                      input_data[feature] = value_str\n",
    "\n",
    "            break # Sortir de la boucle while si l'entrÃ©e est valide pour le type\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Une erreur inattendue est survenue lors de la saisie: {e}\")\n",
    "            continue # Redemander\n",
    "\n",
    "# CrÃ©er un DataFrame pandas avec les donnÃ©es saisies (1 ligne)\n",
    "# S'assurer que l'ordre des colonnes est le mÃªme que celui attendu\n",
    "new_patient_df = pd.DataFrame([input_data], columns=expected_feature_names)\n",
    "\n",
    "print(\"\\n--- DonnÃ©es saisies pour la prÃ©diction ---\")\n",
    "pd.set_option('display.max_columns', None) # Afficher toutes les colonnes\n",
    "print(new_patient_df)\n",
    "pd.reset_option('display.max_columns')\n",
    "\n",
    "# VÃ©rifier les types de donnÃ©es (optionnel mais utile pour dÃ©bogage)\n",
    "# print(\"\\nTypes de donnÃ©es dans le DataFrame avant prÃ©diction:\")\n",
    "# print(new_patient_df.info())\n",
    "\n",
    "# --- 5. Faire la PrÃ©diction ---\n",
    "try:\n",
    "    prediction = loaded_pipeline.predict(new_patient_df)\n",
    "    predicted_stay = prediction[0] # Obtenir la valeur unique prÃ©dite\n",
    "    print(\"\\n--- PrÃ©diction ---\")\n",
    "    print(f\"ðŸ“Š DurÃ©e de sÃ©jour prÃ©dite : {predicted_stay:.2f} jours\")\n",
    "\n",
    "except ValueError as ve:\n",
    "     print(f\"\\nâŒ Erreur de valeur lors de la prÃ©diction: {ve}\")\n",
    "     print(\"   Cela peut arriver si une catÃ©gorie textuelle saisie n'Ã©tait pas\")\n",
    "     print(\"   prÃ©sente dans les donnÃ©es d'entraÃ®nement et que handle_unknown='error'\")\n",
    "     print(\"   Ã©tait utilisÃ© dans OneHotEncoder (vÃ©rifiez qu'il est bien sur 'ignore').\")\n",
    "     print(\"   Ou si une valeur non numÃ©rique a Ã©tÃ© passÃ©e Ã  StandardScaler.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Erreur lors de la prÃ©diction : {e}\")\n",
    "    # Afficher les dÃ©tails peut aider\n",
    "    # print(\"\\nDÃ©tails des donnÃ©es passÃ©es au pipeline:\")\n",
    "    # print(new_patient_df.iloc[0].to_dict())\n",
    "\n",
    "\n",
    "# --- 6. Afficher les MÃ©triques Globales du ModÃ¨le (calculÃ©es sur le Test Set) ---\n",
    "print(\"\\n--- Performance Globale du ModÃ¨le (sur donnÃ©es test originales) ---\")\n",
    "# Pour cela, il nous faut X_test et y_test du split original\n",
    "try:\n",
    "    # Recharger les donnÃ©es brutes et refaire le split avec le mÃªme random_state\n",
    "    print(\"Recalcul des mÃ©triques sur l'ensemble de test original...\")\n",
    "    data_orig = pd.read_csv(original_data_file)\n",
    "\n",
    "    # --- RÃ©appliquer le Feature Engineering Minimal (Age etc.) ---\n",
    "    for col in date_cols_original:\n",
    "        if col in data_orig.columns:\n",
    "            data_orig[col] = pd.to_datetime(data_orig[col], errors='coerce')\n",
    "    if 'AdmissionDate' in data_orig.columns and data_orig['AdmissionDate'].dtype.kind == 'M':\n",
    "        data_orig['AdmissionYear'] = data_orig['AdmissionDate'].dt.year\n",
    "        data_orig['AdmissionMonth'] = data_orig['AdmissionDate'].dt.month\n",
    "        data_orig['AdmissionDayOfWeek'] = data_orig['AdmissionDate'].dt.dayofweek\n",
    "        if 'dob' in data_orig.columns and data_orig['dob'].dtype.kind == 'M':\n",
    "            data_orig['Age'] = data_orig['AdmissionYear'] - data_orig['dob'].dt.year\n",
    "            data_orig.loc[data_orig['AdmissionDate'] < data_orig['dob'], 'Age'] -= 1\n",
    "\n",
    "    # --- SÃ©parer X et y ---\n",
    "    X_orig = data_orig.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "    # Garder seulement les colonnes qui Ã©taient effectivement utilisÃ©es\n",
    "    X_orig = X_orig[expected_feature_names]\n",
    "    y_orig = data_orig[target_column]\n",
    "\n",
    "    # --- Refaire le mÃªme split ---\n",
    "    _, X_test_reloaded, _, y_test_reloaded = train_test_split(\n",
    "        X_orig, y_orig, test_size=0.2, random_state=42\n",
    "    )\n",
    "\n",
    "    # --- Faire les prÃ©dictions sur cet ensemble de test ---\n",
    "    y_pred_test = loaded_pipeline.predict(X_test_reloaded)\n",
    "\n",
    "    # --- Calculer et afficher les mÃ©triques ---\n",
    "    mse_test = mean_squared_error(y_test_reloaded, y_pred_test)\n",
    "    r2_test = r2_score(y_test_reloaded, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    print(f\"ðŸ“‰ Erreur Quadratique Moyenne (MSE) : {mse_test:.4f}\")\n",
    "    print(f\"   -> Erreur Quadratique Moyenne Racine (RMSE) : {rmse_test:.4f} jours\")\n",
    "    print(f\"ðŸ“ˆ Score RÂ² (Coefficient de dÃ©termination) : {r2_test:.4f}\")\n",
    "\n",
    "    # InterprÃ©tation simple du RÂ² comme \"confiance\"\n",
    "    print(f\"   -> Le modÃ¨le explique environ {r2_test*100:.1f}% de la variance de la durÃ©e de sÃ©jour dans les donnÃ©es de test.\")\n",
    "    print(\"   (Note: RÂ² mesure la qualitÃ© de l'ajustement global, pas la certitude d'une prÃ©diction unique)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"   Impossible de recalculer les mÃ©triques : fichier de donnÃ©es original non trouvÃ©.\")\n",
    "except Exception as e:\n",
    "    print(f\"   Erreur lors du recalcul des mÃ©triques sur le test set: {e}\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ Script de prÃ©diction terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "416d1020",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ml/datasejour.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mml/datasejour.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNoms des features dans le DataFrame \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdatesejour\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(datesejour\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:912\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m    899\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    900\u001b[0m     dialect,\n\u001b[0;32m    901\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    908\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m    909\u001b[0m )\n\u001b[0;32m    910\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 912\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:577\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    574\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    576\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 577\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    579\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    580\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1407\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1404\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1407\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1661\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1659\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1660\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1661\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1662\u001b[0m     f,\n\u001b[0;32m   1663\u001b[0m     mode,\n\u001b[0;32m   1664\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1665\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1666\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1667\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1668\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1669\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1670\u001b[0m )\n\u001b[0;32m   1671\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1672\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mC:\\ProgramData\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:859\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    854\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    855\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    856\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    858\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 859\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    860\u001b[0m             handle,\n\u001b[0;32m    861\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    862\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    863\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    864\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    865\u001b[0m         )\n\u001b[0;32m    866\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    867\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    868\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ml/datasejour.csv'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = pd.read_csv(\"ml/datasejour.csv\")\n",
    "print(\"Noms des features dans le DataFrame 'datesejour':\")\n",
    "print(datesejour.columns.tolist())\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b1faa01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tentative de lecture du fichier : 'datasejour.csv'\n",
      "Fichier 'datasejour.csv' chargÃ© avec succÃ¨s.\n",
      "Dimensions des donnÃ©es (lignes, colonnes) : (129, 47)\n",
      "\n",
      "--- Colonnes (Features) prÃ©sentes dans le fichier ---\n",
      "Nombre total de colonnes : 47\n",
      "['subject_id', 'HADM_ID', 'gender', 'dob', 'HeightInMeters', 'WeightInKilograms', 'BMI', 'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos', 'LANGUAGE', 'ETHNICITY', 'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap', 'AdmissionDate', 'AdmissionYear', 'AdmissionDayOfWeek', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'length_of_stay', 'facility_cost', 'procedure_cost', 'medication_cost', 'lab_test_cost', 'total_cost']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "# Ignorer certains avertissements pour la propretÃ© (optionnel)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# --- Configuration fournie ---\n",
    "# pipeline_filename = 'sejour_prediction_pipeline_v1.joblib' # Non utilisÃ© ici\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes donnÃ©es BRUTES originales\n",
    "# target_column = 'length_of_stay' # Non utilisÃ© ici\n",
    "\n",
    "print(f\"Tentative de lecture du fichier : '{original_data_file}'\")\n",
    "\n",
    "# --- Chargement des donnÃ©es et affichage des colonnes ---\n",
    "try:\n",
    "    # Lire le fichier CSV dans un DataFrame pandas\n",
    "    # On utilise 'data' comme nom gÃ©nÃ©rique pour le DataFrame chargÃ©\n",
    "    data = pd.read_csv(original_data_file)\n",
    "    print(f\"Fichier '{original_data_file}' chargÃ© avec succÃ¨s.\")\n",
    "    print(f\"Dimensions des donnÃ©es (lignes, colonnes) : {data.shape}\")\n",
    "\n",
    "\n",
    "    # Obtenir la liste des noms de colonnes (features + potentiellement la cible)\n",
    "    column_names = data.columns.tolist()\n",
    "\n",
    "    # Afficher la liste des colonnes\n",
    "    print(\"\\n--- Colonnes (Features) prÃ©sentes dans le fichier ---\")\n",
    "    print(f\"Nombre total de colonnes : {len(column_names)}\")\n",
    "\n",
    "    # Afficher la liste complÃ¨te :\n",
    "    print(column_names)\n",
    "\n",
    "    # Optionnel : Afficher chaque colonne sur une nouvelle ligne pour lisibilitÃ©\n",
    "    # print(\"\\nListe dÃ©taillÃ©e des colonnes :\")\n",
    "    # for i, col_name in enumerate(column_names):\n",
    "    #    print(f\"{i+1}. {col_name}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"\\nâŒ ERREUR : Le fichier '{original_data_file}' n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "    print(\"   Veuillez vÃ©rifier que le nom du fichier et son emplacement sont corrects.\")\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(f\"\\nâŒ ERREUR : Le fichier '{original_data_file}' est vide.\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ ERREUR inattendue lors de la lecture du fichier '{original_data_file}':\")\n",
    "    print(f\"   {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "167358af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Utilisation d'un sous-ensemble de 29 features sÃ©lectionnÃ©es ---\n",
      "âœ… DonnÃ©es brutes chargÃ©es depuis 'datasejour.csv'. Shape initial: (129, 47)\n",
      "âœ… DonnÃ©es filtrÃ©es pour ne garder que les 29 features sÃ©lectionnÃ©es + cible. Shape filtrÃ©: (129, 30)\n",
      "\n",
      "--- Identification des Types (parmi les 29 features sÃ©lectionnÃ©es) ---\n",
      "BoolÃ©ennes traitÃ©es: ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
      "CatÃ©gorielles traitÃ©es: ['SmokerStatus', 'ECigaretteUsage', 'MARITAL_STATUS', 'HadDiabetes', 'TetanusLast10Tdap', 'DIAGNOSIS', 'ADMISSION_LOCATION', 'ADMISSION_TYPE']\n",
      "NumÃ©riques traitÃ©es: []\n",
      "\n",
      "--- Dimensions des DonnÃ©es (Features SÃ©lectionnÃ©es) ---\n",
      "X_train shape: (103, 29)\n",
      "X_test shape: (26, 29)\n",
      "PrÃ©processeur: Pipeline boolÃ©en ajoutÃ©.\n",
      "PrÃ©processeur: Pipeline catÃ©goriel ajoutÃ©.\n",
      "\n",
      "--- Structure du Pipeline Complet (pour features sÃ©lectionnÃ©es) ---\n",
      "Pipeline(steps=[('preprocessing',\n",
      "                 ColumnTransformer(transformers=[('bool',\n",
      "                                                  Pipeline(steps=[('to_int',\n",
      "                                                                   FunctionTransformer(func=<function flexible_bool_to_int at 0x000001F17B4B0E00>))]),\n",
      "                                                  ['AlcoholDrinkers',\n",
      "                                                   'CovidPos', 'HadHeartAttack',\n",
      "                                                   'HadAngina', 'HadStroke',\n",
      "                                                   'HadAsthma', 'HadSkinCancer',\n",
      "                                                   'HadCOPD',\n",
      "                                                   'HadDepressiveDisorder',\n",
      "                                                   'HadKidneyDisease',\n",
      "                                                   'HadArthritis',\n",
      "                                                   'Dea...\n",
      "                                                   'PneumoVaxEver']),\n",
      "                                                 ('cat',\n",
      "                                                  Pipeline(steps=[('imputer',\n",
      "                                                                   SimpleImputer(strategy='most_frequent')),\n",
      "                                                                  ('onehot',\n",
      "                                                                   OneHotEncoder(handle_unknown='ignore',\n",
      "                                                                                 sparse_output=False))]),\n",
      "                                                  ['SmokerStatus',\n",
      "                                                   'ECigaretteUsage',\n",
      "                                                   'MARITAL_STATUS',\n",
      "                                                   'HadDiabetes',\n",
      "                                                   'TetanusLast10Tdap',\n",
      "                                                   'DIAGNOSIS',\n",
      "                                                   'ADMISSION_LOCATION',\n",
      "                                                   'ADMISSION_TYPE'])])),\n",
      "                ('model', RandomForestRegressor(n_jobs=-1, random_state=42))])\n",
      "\n",
      "ðŸš€ DÃ©but de RandomizedSearchCV (20 itÃ©rations, sur features sÃ©lectionnÃ©es)...\n",
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "âœ… RandomizedSearchCV terminÃ©.\n",
      "\n",
      "ðŸ† Meilleurs paramÃ¨tres trouvÃ©s : {'model__max_depth': 38, 'model__max_features': 'log2', 'model__min_samples_leaf': 14, 'model__min_samples_split': 5, 'model__n_estimators': 369}\n",
      "Meilleur score CV (Negative RMSE) : -11.1444\n",
      "\n",
      "--- Ã‰valuation Finale sur l'Ensemble de Test (Features SÃ©lectionnÃ©es) ---\n",
      "ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : 22.9549\n",
      "ðŸ“ˆ Score RÂ² : 0.0096\n",
      "\n",
      "âœ… Pipeline (entraÃ®nÃ© sur features sÃ©lectionnÃ©es) sauvegardÃ© sous : 'sejour_prediction_pipeline_SELECTED_FEATURES.joblib'\n",
      "\n",
      "ðŸ Script d'entraÃ®nement (features sÃ©lectionnÃ©es) terminÃ©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from scipy.stats import randint\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "# Ignorer les avertissements futurs pour la propretÃ© de la sortie\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None # DÃ©sactiver avertissement pour copie\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes donnÃ©es BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "pipeline_filename = 'sejour_prediction_pipeline_SELECTED_FEATURES.joblib' # Nouveau nom pour ce pipeline spÃ©cifique\n",
    "\n",
    "# --- !!! LISTE DES FEATURES SÃ‰LECTIONNÃ‰ES Ã€ UTILISER !!! ---\n",
    "# BasÃ©e sur ta liste, en nettoyant les Ã©ventuelles virgules en trop\n",
    "selected_features = [\n",
    "    'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos',\n",
    "    'MARITAL_STATUS', 'HadHeartAttack', 'HadAngina', 'HadStroke',\n",
    "    'HadAsthma', 'HadSkinCancer', 'HadCOPD', 'HadDepressiveDisorder',\n",
    "    'HadKidneyDisease', 'HadArthritis', 'HadDiabetes', 'DeafOrHardOfHearing',\n",
    "    'BlindOrVisionDifficulty', 'DifficultyConcentrating', 'DifficultyWalking',\n",
    "    'DifficultyDressingBathing', 'DifficultyErrands', 'ChestScan', 'HIVTesting',\n",
    "    'FluVaxLast12', 'PneumoVaxEver', 'TetanusLast10Tdap', 'DIAGNOSIS',\n",
    "    'ADMISSION_LOCATION', 'ADMISSION_TYPE'\n",
    "]\n",
    "print(f\"--- Utilisation d'un sous-ensemble de {len(selected_features)} features sÃ©lectionnÃ©es ---\")\n",
    "# print(\"Features utilisÃ©es:\", selected_features) # DÃ©commente pour voir la liste\n",
    "\n",
    "# --- 2. Chargement et Filtrage des DonnÃ©es Brutes ---\n",
    "try:\n",
    "    data_full = pd.read_csv(original_data_file)\n",
    "    print(f\"âœ… DonnÃ©es brutes chargÃ©es depuis '{original_data_file}'. Shape initial: {data_full.shape}\")\n",
    "\n",
    "    # VÃ©rifier si toutes les features sÃ©lectionnÃ©es et la cible existent\n",
    "    required_cols = selected_features + [target_column]\n",
    "    missing_cols = [col for col in required_cols if col not in data_full.columns]\n",
    "    if missing_cols:\n",
    "        raise ValueError(f\"Les colonnes suivantes sont requises mais manquantes dans le fichier CSV: {missing_cols}\")\n",
    "\n",
    "    # Garder UNIQUEMENT les colonnes sÃ©lectionnÃ©es + la colonne cible\n",
    "    data = data_full[required_cols].copy()\n",
    "    print(f\"âœ… DonnÃ©es filtrÃ©es pour ne garder que les {len(selected_features)} features sÃ©lectionnÃ©es + cible. Shape filtrÃ©: {data.shape}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Erreur: Le fichier '{original_data_file}' n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "    exit()\n",
    "except ValueError as ve:\n",
    "    print(f\"âŒ Erreur: {ve}\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur inattendue lors du chargement/filtrage: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Identification des Colonnes par Type (parmi les features sÃ©lectionnÃ©es) ---\n",
    "\n",
    "# SÃ©parer X (features sÃ©lectionnÃ©es) et y (cible)\n",
    "X = data[selected_features]\n",
    "y = data[target_column]\n",
    "\n",
    "# Identifier les types DANS LE SOUS-ENSEMBLE X\n",
    "# Utiliser les listes originales comme rÃ©fÃ©rence, mais filtrer par les colonnes de X\n",
    "bool_cols_original_ref = ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina',\n",
    "                      'HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD',\n",
    "                      'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
    "                      'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating',\n",
    "                      'DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands',\n",
    "                      'ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver']\n",
    "categorical_cols_original_ref = ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS',\n",
    "                             'ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE',\n",
    "                             'SmokerStatus', 'ECigaretteUsage', 'HadDiabetes',\n",
    "                             'TetanusLast10Tdap'] # gender/ETHNICITY/LANGUAGE ne sont pas dans ta liste sÃ©lectionnÃ©e\n",
    "\n",
    "bool_cols = [col for col in X.columns if col in bool_cols_original_ref]\n",
    "categorical_cols = [col for col in X.columns if col in categorical_cols_original_ref]\n",
    "numerical_cols = [col for col in X.columns if col not in bool_cols and col not in categorical_cols and pd.api.types.is_numeric_dtype(X[col])]\n",
    "# NOTE: Dans ta liste, il ne semble pas y avoir de colonnes numÃ©riques Ã  part celles qui sont boolÃ©ennes codÃ©es 0/1.\n",
    "# Si des colonnes comme 'total_cost' Ã©taient dans ta liste, elles apparaÃ®traient ici.\n",
    "\n",
    "print(f\"\\n--- Identification des Types (parmi les {len(X.columns)} features sÃ©lectionnÃ©es) ---\")\n",
    "print(f\"BoolÃ©ennes traitÃ©es: {bool_cols}\")\n",
    "print(f\"CatÃ©gorielles traitÃ©es: {categorical_cols}\")\n",
    "print(f\"NumÃ©riques traitÃ©es: {numerical_cols}\") # Probablement vide basÃ© sur ta liste\n",
    "\n",
    "# VÃ©rifier si toutes les colonnes sÃ©lectionnÃ©es sont classifiÃ©es\n",
    "processed_in_subset = set(bool_cols + categorical_cols + numerical_cols)\n",
    "unprocessed_in_subset = [col for col in X.columns if col not in processed_in_subset]\n",
    "if unprocessed_in_subset:\n",
    "    print(f\"âš ï¸ Attention : Colonnes sÃ©lectionnÃ©es non classifiÃ©es (seront ignorÃ©es): {unprocessed_in_subset}\")\n",
    "\n",
    "\n",
    "# --- 4. DÃ©finition de la Fonction d'Encodage BoolÃ©en ---\n",
    "# (Identique Ã  avant)\n",
    "def flexible_bool_to_int(X_bool):\n",
    "    if isinstance(X_bool, pd.Series):\n",
    "        X_series = X_bool.copy()\n",
    "        map_dict = {\n",
    "            'yes': True, 'true': True, '1': True, 1: True, True: True,\n",
    "            'no': False, 'false': False, '0': False, 0: False, False: False,\n",
    "            'Yes': True, 'True': True, 'No': False, 'False': False\n",
    "        }\n",
    "        mapped = X_series.map(map_dict)\n",
    "        return mapped.fillna(False).astype(int)\n",
    "    elif isinstance(X_bool, pd.DataFrame):\n",
    "        return X_bool.apply(flexible_bool_to_int, axis=0)\n",
    "    else:\n",
    "        try: return pd.DataFrame(X_bool).fillna(False).astype(int)\n",
    "        except: print(f\"Warning: Type non gÃ©rÃ© {type(X_bool)}\"); return X_bool\n",
    "\n",
    "\n",
    "# --- 5. Train/Test Split (sur X filtrÃ©) ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"\\n--- Dimensions des DonnÃ©es (Features SÃ©lectionnÃ©es) ---\")\n",
    "print(f\"X_train shape: {X_train.shape}\")\n",
    "print(f\"X_test shape: {X_test.shape}\")\n",
    "\n",
    "\n",
    "# --- 6. CrÃ©ation des Pipelines de PrÃ©traitement (pour les types prÃ©sents) ---\n",
    "# (Pipelines identiques, mais ne seront appliquÃ©s qu'aux colonnes prÃ©sentes dans bool_cols, numerical_cols, categorical_cols)\n",
    "\n",
    "bool_pipeline = Pipeline(steps=[('to_int', FunctionTransformer(flexible_bool_to_int, validate=False))])\n",
    "numerical_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='median')), ('scaler', StandardScaler())])\n",
    "categorical_pipeline = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')), ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))])\n",
    "\n",
    "\n",
    "# --- 7. CrÃ©ation du PrÃ©processeur Global (ColumnTransformer pour le sous-ensemble) ---\n",
    "transformers_list = []\n",
    "if bool_cols:\n",
    "    transformers_list.append(('bool', bool_pipeline, bool_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline boolÃ©en ajoutÃ©.\")\n",
    "if numerical_cols: # Probablement vide\n",
    "    transformers_list.append(('num', numerical_pipeline, numerical_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline numÃ©rique ajoutÃ©.\")\n",
    "if categorical_cols:\n",
    "    transformers_list.append(('cat', categorical_pipeline, categorical_cols))\n",
    "    print(\"PrÃ©processeur: Pipeline catÃ©goriel ajoutÃ©.\")\n",
    "\n",
    "if not transformers_list:\n",
    "    raise ValueError(\"Aucun type de colonne (bool, num, cat) n'a Ã©tÃ© trouvÃ© parmi les features sÃ©lectionnÃ©es.\")\n",
    "\n",
    "# Le prÃ©processeur ne verra que les colonnes sÃ©lectionnÃ©es\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=transformers_list,\n",
    "    remainder='drop' # Ignorer les colonnes non classifiÃ©es (devrait Ãªtre vide si tout va bien)\n",
    ")\n",
    "\n",
    "\n",
    "# --- 8. CrÃ©ation du Pipeline Complet (PrÃ©processeur + ModÃ¨le) ---\n",
    "full_pipeline = Pipeline(steps=[\n",
    "    ('preprocessing', preprocessor),\n",
    "    ('model', RandomForestRegressor(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "print(\"\\n--- Structure du Pipeline Complet (pour features sÃ©lectionnÃ©es) ---\")\n",
    "print(full_pipeline)\n",
    "\n",
    "\n",
    "# --- 9. Recherche d'HyperparamÃ¨tres (RandomizedSearchCV) ---\n",
    "# (ParamÃ¨tres identiques Ã  avant)\n",
    "param_dist = {\n",
    "    'model__n_estimators': randint(100, 600),\n",
    "    'model__max_depth': randint(5, 40),\n",
    "    'model__min_samples_split': randint(2, 15),\n",
    "    'model__min_samples_leaf': randint(1, 15),\n",
    "    'model__max_features': ['sqrt', 'log2', 0.6, 0.8, None]\n",
    "}\n",
    "n_iterations = 20 # Ajuste si besoin\n",
    "\n",
    "random_search = RandomizedSearchCV(\n",
    "    full_pipeline,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=n_iterations,\n",
    "    cv=5,\n",
    "    scoring='neg_root_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(f\"\\nðŸš€ DÃ©but de RandomizedSearchCV ({n_iterations} itÃ©rations, sur features sÃ©lectionnÃ©es)...\")\n",
    "# EntraÃ®ner sur X_train (qui ne contient QUE les features sÃ©lectionnÃ©es)\n",
    "random_search.fit(X_train, y_train)\n",
    "print(\"âœ… RandomizedSearchCV terminÃ©.\")\n",
    "\n",
    "\n",
    "# --- 10. Ã‰valuation du Meilleur ModÃ¨le ---\n",
    "best_pipeline = random_search.best_estimator_\n",
    "print(f\"\\nðŸ† Meilleurs paramÃ¨tres trouvÃ©s : {random_search.best_params_}\")\n",
    "print(f\"Meilleur score CV (Negative RMSE) : {random_search.best_score_:.4f}\")\n",
    "\n",
    "# Faire des prÃ©dictions sur X_test (qui ne contient QUE les features sÃ©lectionnÃ©es)\n",
    "y_pred = best_pipeline.predict(X_test)\n",
    "\n",
    "# Calculer les mÃ©triques\n",
    "final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "final_r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"\\n--- Ã‰valuation Finale sur l'Ensemble de Test (Features SÃ©lectionnÃ©es) ---\")\n",
    "print(f\"ðŸ“‰ Erreur Quadratique Moyenne Racine (RMSE) : {final_rmse:.4f}\")\n",
    "print(f\"ðŸ“ˆ Score RÂ² : {final_r2:.4f}\")\n",
    "\n",
    "\n",
    "# --- 11. Sauvegarde du Pipeline EntraÃ®nÃ© (pour features sÃ©lectionnÃ©es) ---\n",
    "try:\n",
    "    joblib.dump(best_pipeline, pipeline_filename)\n",
    "    print(f\"\\nâœ… Pipeline (entraÃ®nÃ© sur features sÃ©lectionnÃ©es) sauvegardÃ© sous : '{pipeline_filename}'\")\n",
    "except Exception as e:\n",
    "     print(f\"\\nâŒ Erreur lors de la sauvegarde du pipeline : {e}\")\n",
    "\n",
    "\n",
    "print(\"\\nðŸ Script d'entraÃ®nement (features sÃ©lectionnÃ©es) terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4e6ae701",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Pipeline complet (toutes features) chargÃ© depuis 'sejour_prediction_pipeline_v1.joblib'.\n",
      "\n",
      "Le pipeline complet attend 41 features en entrÃ©e.\n",
      "\n",
      "Nous allons vous demander de saisir 29 features clÃ©s (parmi les 41 attendues par le modÃ¨le).\n",
      "\n",
      "--- Veuillez saisir les valeurs pour les features clÃ©s du patient ---\n",
      "Entrez la valeur pour 'SmokerStatus' (texte): Former smoker\n",
      "Entrez la valeur pour 'ECigaretteUsage' (texte): Never used e-cigarettes in my entire life\n",
      "Entrez la valeur pour 'AlcoholDrinkers' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'CovidPos' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'MARITAL_STATUS' (texte): DIVORCED\n",
      "Entrez la valeur pour 'HadHeartAttack' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAngina' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadStroke' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadAsthma' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadSkinCancer' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadCOPD' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadDepressiveDisorder' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadKidneyDisease' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HadArthritis' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'HadDiabetes' (texte): Yes\n",
      "Entrez la valeur pour 'DeafOrHardOfHearing' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'BlindOrVisionDifficulty' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyConcentrating' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyWalking' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyDressingBathing' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'DifficultyErrands' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'ChestScan' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'HIVTesting' (ex: True/False, Yes/No, 1/0): 0\n",
      "Entrez la valeur pour 'FluVaxLast12' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'PneumoVaxEver' (ex: True/False, Yes/No, 1/0): 1\n",
      "Entrez la valeur pour 'TetanusLast10Tdap' (texte): Yes, received tetanus shot but not sure what type\n",
      "Entrez la valeur pour 'DIAGNOSIS' (texte): HUMERAL FRACTURE\n",
      "Entrez la valeur pour 'ADMISSION_LOCATION' (texte): EMERGENCY ROOM ADMIT\n",
      "Entrez la valeur pour 'ADMISSION_TYPE' (texte): EMERGENCY\n",
      "\n",
      "--- DonnÃ©es COMPLÃˆTES prÃ©parÃ©es pour la prÃ©diction (avec NaN pour non-saisies) ---\n",
      "    SmokerStatus                            ECigaretteUsage AlcoholDrinkers  \\\n",
      "0  Former smoker  Never used e-cigarettes in my entire life               0   \n",
      "\n",
      "  CovidPos MARITAL_STATUS HadHeartAttack HadAngina HadStroke HadAsthma  \\\n",
      "0        0       DIVORCED              0         0         0         0   \n",
      "\n",
      "  HadSkinCancer  ... PneumoVaxEver  \\\n",
      "0             0  ...             1   \n",
      "\n",
      "                                   TetanusLast10Tdap         DIAGNOSIS  \\\n",
      "0  Yes, received tetanus shot but not sure what type  HUMERAL FRACTURE   \n",
      "\n",
      "     ADMISSION_LOCATION ADMISSION_TYPE procedure_cost AdmissionDayOfWeek  \\\n",
      "0  EMERGENCY ROOM ADMIT      EMERGENCY            NaN                NaN   \n",
      "\n",
      "  facility_cost ETHNICITY Age  \n",
      "0           NaN       NaN NaN  \n",
      "\n",
      "[1 rows x 34 columns]\n",
      "\n",
      "--- PrÃ©diction ---\n",
      "ðŸ“Š DurÃ©e de sÃ©jour prÃ©dite (par modÃ¨le complet): 7.00 jours\n",
      "   (BasÃ©e sur les valeurs saisies et les valeurs imputÃ©es par le modÃ¨le pour les autres features)\n",
      "\n",
      "--- Performance Globale du ModÃ¨le COMPLET (sur donnÃ©es test originales) ---\n",
      "Recalcul des mÃ©triques sur l'ensemble de test original...\n",
      "ðŸ“‰ Erreur Quadratique Moyenne (MSE) : 79.3998\n",
      "   -> Erreur Quadratique Moyenne Racine (RMSE) : 8.9107 jours\n",
      "ðŸ“ˆ Score RÂ² (Coefficient de dÃ©termination) : 0.8508\n",
      "   -> Le modÃ¨le explique environ 85.1% de la variance de la durÃ©e de sÃ©jour dans les donnÃ©es de test.\n",
      "   (Note: RÂ² mesure la qualitÃ© de l'ajustement global du modÃ¨le chargÃ©)\n",
      "\n",
      "ðŸ Script de prÃ©diction terminÃ©.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split # NÃ©cessaire si on recharge X_test/y_test\n",
    "import warnings\n",
    "from datetime import datetime # Si des dates sont utilisÃ©es pour l'Ã¢ge etc.\n",
    "\n",
    "# Ignorer les avertissements pour la propretÃ©\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "warnings.filterwarnings('ignore', category=UserWarning, module='sklearn')\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# --- 1. Configuration ---\n",
    "# ON UTILISE LE PIPELINE ENTRAÃŽNÃ‰ SUR TOUTES LES FEATURES\n",
    "pipeline_filename = 'sejour_prediction_pipeline_v1.joblib'\n",
    "original_data_file = 'datasejour.csv' # Chemin vers tes donnÃ©es BRUTES originales\n",
    "target_column = 'length_of_stay'\n",
    "id_cols_to_drop_original = ['subject_id', 'HADM_ID'] # IDs Ã  ignorer\n",
    "date_cols_original = ['dob', 'AdmissionDate'] # Dates utilisÃ©es pour crÃ©er des features DANS LE MODÃˆLE ORIGINAL\n",
    "\n",
    "# --- 2. Charger le Pipeline EntraÃ®nÃ© (Celui avec toutes les features) ---\n",
    "try:\n",
    "    # Charger le pipeline qui donne le meilleur R2\n",
    "    loaded_pipeline = joblib.load(pipeline_filename)\n",
    "    print(f\"âœ… Pipeline complet (toutes features) chargÃ© depuis '{pipeline_filename}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"âŒ Erreur: Le fichier pipeline '{pipeline_filename}' n'a pas Ã©tÃ© trouvÃ©.\")\n",
    "    print(\"   Assure-toi d'avoir exÃ©cutÃ© le script d'entraÃ®nement COMPLET et de sauvegarde d'abord.\")\n",
    "    exit()\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Erreur lors du chargement du pipeline: {e}\")\n",
    "    exit()\n",
    "\n",
    "# --- 3. Obtenir les Noms de TOUTES les Features Attendues par CE Pipeline ---\n",
    "try:\n",
    "    preprocessor = loaded_pipeline.named_steps['preprocessing']\n",
    "    all_expected_feature_names = preprocessor.feature_names_in_\n",
    "    print(f\"\\nLe pipeline complet attend {len(all_expected_feature_names)} features en entrÃ©e.\")\n",
    "    # print(\"Features attendues par le pipeline complet:\", list(all_expected_feature_names)) # DÃ©commente pour vÃ©rifier\n",
    "except AttributeError:\n",
    "    print(\"\\nâš ï¸ Impossible de rÃ©cupÃ©rer automatiquement les noms de features attendus du pipeline.\")\n",
    "    # Tenter de les reconstruire comme dans le script d'entraÃ®nement ORIGINAL\n",
    "    try:\n",
    "        print(\"   Tentative de reconstruction des features attendues Ã  partir du fichier brut...\")\n",
    "        temp_data = pd.read_csv(original_data_file)\n",
    "        # REFAIRE LE FEATURE ENGINEERING DU SCRIPT ORIGINAL\n",
    "        for col in date_cols_original:\n",
    "             if col in temp_data.columns: temp_data[col] = pd.to_datetime(temp_data[col], errors='coerce')\n",
    "        if 'AdmissionDate' in temp_data.columns and temp_data['AdmissionDate'].dtype.kind == 'M':\n",
    "            temp_data['AdmissionYear'] = temp_data['AdmissionDate'].dt.year\n",
    "            temp_data['AdmissionMonth'] = temp_data['AdmissionDate'].dt.month\n",
    "            temp_data['AdmissionDayOfWeek'] = temp_data['AdmissionDate'].dt.dayofweek\n",
    "            if 'dob' in temp_data.columns and temp_data['dob'].dtype.kind == 'M':\n",
    "                 temp_data['Age'] = temp_data['AdmissionYear'] - temp_data['dob'].dt.year\n",
    "                 temp_data.loc[temp_data['AdmissionDate'] < temp_data['dob'], 'Age'] -= 1\n",
    "        # RE-IDENTIFIER LES TYPES COMME DANS LE SCRIPT ORIGINAL\n",
    "        temp_X = temp_data.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "        bool_cols_inf = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in temp_X.columns]\n",
    "        categorical_cols_inf = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in temp_X.columns]\n",
    "        potential_num_cols = temp_X.columns\n",
    "        numerical_cols_inf = [col for col in potential_num_cols if col not in bool_cols_inf and col not in categorical_cols_inf and pd.api.types.is_numeric_dtype(temp_X[col])]\n",
    "        processed_features_list = bool_cols_inf + categorical_cols_inf + numerical_cols_inf\n",
    "        all_expected_feature_names = [col for col in temp_X.columns if col in processed_features_list] # Garde l'ordre original\n",
    "        if not all_expected_feature_names:\n",
    "             print(\"âŒ Impossible de dÃ©terminer les features attendues. ArrÃªt.\")\n",
    "             exit()\n",
    "        print(f\"   Utilisation des features dÃ©terminÃ©es Ã  partir du fichier brut: {len(all_expected_feature_names)} features.\")\n",
    "    except Exception as e:\n",
    "         print(f\"âŒ Erreur lors de la tentative de dÃ©termination des features: {e}\")\n",
    "         exit()\n",
    "\n",
    "# --- 4. DÃ©finir le Sous-Ensemble de Features Ã  Demander (TA LISTE) ---\n",
    "# Nettoyage de la liste fournie (enlÃ¨ve virgule en trop, espaces)\n",
    "features_to_ask_user_raw = [\n",
    "    'SmokerStatus', 'ECigaretteUsage', 'AlcoholDrinkers', 'CovidPos', 'MARITAL_STATUS',\n",
    "    'HadHeartAttack', 'HadAngina', 'HadStroke', 'HadAsthma', 'HadSkinCancer',\n",
    "    'HadCOPD', 'HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis',\n",
    "    'HadDiabetes', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty',\n",
    "    'DifficultyConcentrating', 'DifficultyWalking', 'DifficultyDressingBathing',\n",
    "    'DifficultyErrands', 'ChestScan', 'HIVTesting', 'FluVaxLast12',\n",
    "    'PneumoVaxEver', 'TetanusLast10Tdap', 'DIAGNOSIS', 'ADMISSION_LOCATION',\n",
    "    'ADMISSION_TYPE'\n",
    "]\n",
    "# Assurer que chaque feature demandÃ©e existe bien dans celles attendues par le pipeline\n",
    "features_to_ask_user = [f for f in features_to_ask_user_raw if f in all_expected_feature_names]\n",
    "missing_asked_features = set(features_to_ask_user_raw) - set(features_to_ask_user)\n",
    "if missing_asked_features:\n",
    "    print(f\"\\nâš ï¸ Attention: Les features suivantes de ta liste n'existent pas dans le modÃ¨le chargÃ© et ne seront pas demandÃ©es: {missing_asked_features}\")\n",
    "\n",
    "if not features_to_ask_user:\n",
    "     print(\"âŒ Aucune des features que tu as listÃ©es n'est attendue par le modÃ¨le chargÃ© ! VÃ©rifie ta liste et le modÃ¨le.\")\n",
    "     exit()\n",
    "\n",
    "print(f\"\\nNous allons vous demander de saisir {len(features_to_ask_user)} features clÃ©s (parmi les {len(all_expected_feature_names)} attendues par le modÃ¨le).\")\n",
    "# print(\"Features qui seront demandÃ©es:\", features_to_ask_user) # DÃ©commente pour voir\n",
    "\n",
    "# --- 5. Saisie Manuelle des Valeurs pour les Features ClÃ©s ---\n",
    "print(\"\\n--- Veuillez saisir les valeurs pour les features clÃ©s du patient ---\")\n",
    "input_data_user = {}\n",
    "\n",
    "# DÃ©terminer les types pour aider Ã  la saisie (basÃ© sur les listes reconstruites ou Ã  infÃ©rer)\n",
    "# RÃ©utilisation des listes infÃ©rÃ©es dans le bloc except ci-dessus si nÃ©cessaire\n",
    "if 'bool_cols_inf' not in locals(): # Si la rÃ©cupÃ©ration a rÃ©ussi via feature_names_in_\n",
    "    bool_cols_rec = [col for col in ['AlcoholDrinkers', 'CovidPos', 'HadHeartAttack', 'HadAngina','HadStroke', 'HadAsthma', 'HadSkinCancer', 'HadCOPD','HadDepressiveDisorder', 'HadKidneyDisease', 'HadArthritis', 'DeafOrHardOfHearing', 'BlindOrVisionDifficulty', 'DifficultyConcentrating','DifficultyWalking', 'DifficultyDressingBathing', 'DifficultyErrands','ChestScan', 'HIVTesting', 'FluVaxLast12', 'PneumoVaxEver'] if col in all_expected_feature_names]\n",
    "    categorical_cols_rec = [col for col in ['gender', 'ETHNICITY', 'MARITAL_STATUS', 'DIAGNOSIS','ADMISSION_LOCATION', 'ADMISSION_TYPE', 'LANGUAGE','SmokerStatus', 'ECigaretteUsage', 'HadDiabetes','TetanusLast10Tdap'] if col in all_expected_feature_names]\n",
    "    numerical_cols_rec = [col for col in all_expected_feature_names if col not in bool_cols_rec and col not in categorical_cols_rec]\n",
    "else: # Utiliser les listes du bloc except\n",
    "    bool_cols_rec = bool_cols_inf\n",
    "    categorical_cols_rec = categorical_cols_inf\n",
    "    numerical_cols_rec = numerical_cols_inf\n",
    "\n",
    "for feature in features_to_ask_user:\n",
    "    while True:\n",
    "        try:\n",
    "            prompt_text = f\"Entrez la valeur pour '{feature}'\"\n",
    "            is_numeric = feature in numerical_cols_rec\n",
    "            is_boolean = feature in bool_cols_rec\n",
    "            is_categorical = feature in categorical_cols_rec\n",
    "\n",
    "            if is_numeric: prompt_text += \" (nombre): \"\n",
    "            elif is_boolean: prompt_text += \" (ex: True/False, Yes/No, 1/0): \"\n",
    "            elif is_categorical: prompt_text += \" (texte): \"\n",
    "            else: prompt_text += \": \" # Si non classifiÃ©\n",
    "\n",
    "            value_str = input(prompt_text).strip()\n",
    "\n",
    "            if not value_str:\n",
    "                input_data_user[feature] = np.nan\n",
    "                print(f\"   -> Valeur manquante (NaN) enregistrÃ©e pour {feature}.\")\n",
    "                break\n",
    "            if is_numeric:\n",
    "                try: input_data_user[feature] = float(value_str.replace(',', '.'))\n",
    "                except ValueError: print(\"âŒ Erreur: Veuillez entrer un nombre valide.\"); continue\n",
    "            else: # Pour bool et cat, on stocke la chaÃ®ne, le pipeline gÃ©rera\n",
    "                input_data_user[feature] = value_str\n",
    "            break\n",
    "        except Exception as e: print(f\"âŒ Erreur saisie: {e}\"); continue\n",
    "\n",
    "# --- 6. PrÃ©parer le DataFrame COMPLET pour la PrÃ©diction ---\n",
    "# Initialiser avec NaN pour TOUTES les features attendues par le pipeline complet\n",
    "input_data_full = {feature: np.nan for feature in all_expected_feature_names}\n",
    "\n",
    "# Remplacer les NaN par les valeurs saisies par l'utilisateur pour les features clÃ©s\n",
    "for feature, value in input_data_user.items():\n",
    "    if feature in input_data_full: # Double vÃ©rification\n",
    "        input_data_full[feature] = value\n",
    "\n",
    "# CrÃ©er le DataFrame final avec une seule ligne et le bon ordre de colonnes\n",
    "new_patient_df_full = pd.DataFrame([input_data_full], columns=all_expected_feature_names)\n",
    "\n",
    "print(\"\\n--- DonnÃ©es COMPLÃˆTES prÃ©parÃ©es pour la prÃ©diction (avec NaN pour non-saisies) ---\")\n",
    "# Afficher seulement les colonnes demandÃ©es et quelques autres pour contexte si trop nombreuses\n",
    "if len(all_expected_feature_names) > 20:\n",
    "     cols_to_show = features_to_ask_user + [c for c in all_expected_feature_names if c not in features_to_ask_user][:5] # Montre 5 non demandÃ©es\n",
    "     print(new_patient_df_full[cols_to_show])\n",
    "else:\n",
    "     pd.set_option('display.max_columns', None)\n",
    "     print(new_patient_df_full)\n",
    "     pd.reset_option('display.max_columns')\n",
    "\n",
    "# --- 7. Faire la PrÃ©diction avec le Pipeline Complet ---\n",
    "try:\n",
    "    # Le pipeline complet gÃ¨re les NaN grÃ¢ce aux SimpleImputer\n",
    "    prediction = loaded_pipeline.predict(new_patient_df_full)\n",
    "    predicted_stay = prediction[0]\n",
    "    print(\"\\n--- PrÃ©diction ---\")\n",
    "    print(f\"ðŸ“Š DurÃ©e de sÃ©jour prÃ©dite (par modÃ¨le complet): {predicted_stay:.2f} jours\")\n",
    "    print(\"   (BasÃ©e sur les valeurs saisies et les valeurs imputÃ©es par le modÃ¨le pour les autres features)\")\n",
    "\n",
    "except ValueError as ve:\n",
    "     print(f\"\\nâŒ Erreur de valeur lors de la prÃ©diction: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\nâŒ Erreur lors de la prÃ©diction : {e}\")\n",
    "\n",
    "# --- 8. Afficher les MÃ©triques Globales du ModÃ¨le COMPLET (calculÃ©es sur le Test Set original) ---\n",
    "print(\"\\n--- Performance Globale du ModÃ¨le COMPLET (sur donnÃ©es test originales) ---\")\n",
    "try:\n",
    "    print(\"Recalcul des mÃ©triques sur l'ensemble de test original...\")\n",
    "    data_orig = pd.read_csv(original_data_file)\n",
    "    # REFAIRE LE FEATURE ENGINEERING DU SCRIPT ORIGINAL\n",
    "    for col in date_cols_original:\n",
    "        if col in data_orig.columns: data_orig[col] = pd.to_datetime(data_orig[col], errors='coerce')\n",
    "    if 'AdmissionDate' in data_orig.columns and data_orig['AdmissionDate'].dtype.kind == 'M':\n",
    "        data_orig['AdmissionYear'] = data_orig['AdmissionDate'].dt.year\n",
    "        data_orig['AdmissionMonth'] = data_orig['AdmissionDate'].dt.month\n",
    "        data_orig['AdmissionDayOfWeek'] = data_orig['AdmissionDate'].dt.dayofweek\n",
    "        if 'dob' in data_orig.columns and data_orig['dob'].dtype.kind == 'M':\n",
    "            data_orig['Age'] = data_orig['AdmissionYear'] - data_orig['dob'].dt.year\n",
    "            data_orig.loc[data_orig['AdmissionDate'] < data_orig['dob'], 'Age'] -= 1\n",
    "    # SÃ©parer X et y originaux\n",
    "    X_orig = data_orig.drop(columns=[target_column] + id_cols_to_drop_original + date_cols_original, errors='ignore')\n",
    "    # S'assurer que X_orig a exactement les colonnes attendues par le pipeline chargÃ©\n",
    "    missing_cols = set(all_expected_feature_names) - set(X_orig.columns)\n",
    "    if missing_cols:\n",
    "        print(f\"âŒ Erreur: Les colonnes suivantes attendues par le pipeline manquent dans {original_data_file} lors du rechargement: {missing_cols}\")\n",
    "        raise ValueError(\"Colonnes manquantes pour recalcul mÃ©triques\")\n",
    "    X_orig = X_orig[all_expected_feature_names] # Garder seulement celles attendues et dans le bon ordre\n",
    "    y_orig = data_orig[target_column]\n",
    "\n",
    "    # Refaire le mÃªme split\n",
    "    _, X_test_reloaded, _, y_test_reloaded = train_test_split(X_orig, y_orig, test_size=0.2, random_state=42)\n",
    "\n",
    "    # PrÃ©dire avec le pipeline complet chargÃ©\n",
    "    y_pred_test = loaded_pipeline.predict(X_test_reloaded)\n",
    "\n",
    "    # Calculer les mÃ©triques du modÃ¨le complet\n",
    "    mse_test = mean_squared_error(y_test_reloaded, y_pred_test)\n",
    "    r2_test = r2_score(y_test_reloaded, y_pred_test)\n",
    "    rmse_test = np.sqrt(mse_test)\n",
    "\n",
    "    print(f\"ðŸ“‰ Erreur Quadratique Moyenne (MSE) : {mse_test:.4f}\")\n",
    "    print(f\"   -> Erreur Quadratique Moyenne Racine (RMSE) : {rmse_test:.4f} jours\")\n",
    "    print(f\"ðŸ“ˆ Score RÂ² (Coefficient de dÃ©termination) : {r2_test:.4f}\")\n",
    "    print(f\"   -> Le modÃ¨le explique environ {r2_test*100:.1f}% de la variance de la durÃ©e de sÃ©jour dans les donnÃ©es de test.\")\n",
    "    print(\"   (Note: RÂ² mesure la qualitÃ© de l'ajustement global du modÃ¨le chargÃ©)\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"   Impossible de recalculer les mÃ©triques : fichier de donnÃ©es original non trouvÃ©.\")\n",
    "except ValueError as ve:\n",
    "     print(f\"   Erreur lors de la prÃ©paration des donnÃ©es pour le recalcul des mÃ©triques: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"   Erreur lors du recalcul des mÃ©triques sur le test set: {e}\")\n",
    "\n",
    "print(\"\\nðŸ Script de prÃ©diction terminÃ©.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfa812d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
